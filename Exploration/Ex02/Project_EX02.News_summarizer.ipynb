{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc185764",
   "metadata": {},
   "source": [
    "## Exploration 2. ë‰´ìŠ¤ ìš”ì•½ë´‡ ë§Œë“¤ê¸°\n",
    "\n",
    "# Project 'News Summarizer'\n",
    "- **ë‰´ìŠ¤ê¸°ì‚¬ ìš”ì•½**\n",
    "- ì¶”ìƒì  ìš”ì•½ Abstractive Summarizationê³¼ ì¶”ì¶œì  ìš”ì•½ Extractive Summarizationì„ ëª¨ë‘ í™œìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756ea3cb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**[ì§„í–‰ ê³¼ì •]**\n",
    "1. ë°ì´í„° ìˆ˜ì§‘\n",
    "    - ë‰´ìŠ¤ê¸°ì‚¬ ë°ì´í„° ì‚¬ìš© \n",
    "2. ë°ì´í„° ì „ì²˜ë¦¬(ì¶”ìƒì  ìš”ì•½)\n",
    "    - ë¶ˆìš©ì–´ ì œê±°, ì •ê·œí™”, ì •ìˆ˜ì¸ì½”ë”© ë“±ì˜ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "3. ëª¨ë¸ ì„¤ê³„(ì¶”ìƒì  ìš”ì•½)\n",
    "    - ì¸ì½”ë”, ë””ì½”ë”, ì–´í…ì…˜ ì„¤ê³„í•˜ê³  ì½”ë“œë¡œ êµ¬í˜„\n",
    "4. ëª¨ë¸ í›ˆë ¨(ì¶”ìƒì  ìš”ì•½)\n",
    "    - EarlyStopping ì ìš©í•´ì„œ í›ˆë ¨\n",
    "    1) ì¸í¼ëŸ°ìŠ¤ ëª¨ë¸ êµ¬í˜„\n",
    "        - ì •ìˆ˜ ì¸ë±ìŠ¤ í–‰ë ¬ë¡œ ë‚˜ì˜¨ ê²°ê³¼ê°’ì„ ì‹¤ì œ ë°ì´í„°ë¡œ ë³µì›í•˜ëŠ” ì¸í¼ëŸ°ìŠ¤ ëª¨ë¸ êµ¬í˜„\n",
    "5. ëª¨ë¸ í…ŒìŠ¤íŠ¸(ì¶”ìƒì  ìš”ì•½) \n",
    "    - ëª¨ë¸ì„ í†µí•´ ì–»ì€ ìš”ì•½ë¬¸ê³¼ ì‹¤ì œ ìš”ì•½ë¬¸ ë¹„êµ\n",
    "6. ì¶”ì¶œì  ìš”ì•½\n",
    "    - summa íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•´ì„œ ì¶”ì¶œì  ìš”ì•½ ì‹œë„\n",
    "    \n",
    "**ì°¸ê³  : ì¶”ê°€ë¡œ ì°¾ê±°ë‚˜ ê³µë¶€í•œ ìë£Œì— ëŒ€í•´ì„œëŠ” ğŸ’¡ í‘œì‹œë¥¼ ë¶™ì„**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986d69e1",
   "metadata": {},
   "source": [
    "ğŸ’¡\n",
    "# í…ìŠ¤íŠ¸ ìš”ì•½\n",
    "- ìš”ì•½ ì „í›„ì— ì •ë³´ ì†ì‹¤ ë°œìƒì´ ìµœì†Œí™”ë˜ì–´ì•¼ í•¨ = ì •ë³´ ì••ì¶•\n",
    "\n",
    "**1. ì¶”ì¶œì  ìš”ì•½ Extractive Summarization**\n",
    "\n",
    "- ì „í†µ ë¨¸ì‹ ëŸ¬ë‹ `TextRank` ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©\n",
    "- ì›ë¬¸ì—ì„œ ë¬¸ì¥ ì¶”ì¶œ => ë¬¸ì¥ë¶„ë¥˜(text classification)\n",
    "- ê²°ê³¼ë¡œ ë‚˜ì˜¨ ë¬¸ì¥ë“¤ ê°„ì˜ í˜¸ì‘ì´ ìì—°ìŠ¤ëŸ½ì§€ ì•Šì„ìˆ˜ ìˆìŒ<br>\n",
    "    [ì ìš©]\n",
    "ë„¤ì´ë²„ë‰´ìŠ¤ ìš”ì•½ë´‡\n",
    "\n",
    "**2. ì¶”ìƒì  ìš”ì•½ Abstractive Summarization**\n",
    "\n",
    "- ìƒˆë¡œìš´ ë¬¸ì¥ì„ ìƒì„± => ìì—°ì„œ ìƒì„±(Natural Language Generation, NGL)\n",
    "- RNN í™œìš©\n",
    "\n",
    "---\n",
    "\n",
    "# RNN\n",
    "- Long term dependencies ì¥ê¸°ì˜ì¡´ì„± ë¬¸ì œ => í•´ê²°í•˜ê¸°ìœ„í•´ LSTM -> GRU -> Attention ë“±ì¥\n",
    "\n",
    "**Google Brain team - [Text summarization with TensorFlow](https://research.googleblog.com/2016/08/text-summarization-with-tensorflow.html)**\n",
    "- DistBelief\n",
    "- ì—­ë¬¸ì„œë¹ˆë„ IDF\n",
    "- seq2seq (sequence-to-sequence)\n",
    "\n",
    "---\n",
    "\n",
    "# seq2seq\n",
    "- ë‘ ê°œì˜ RNN ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•´ì„œ ì…ë ¥ì‹œí€€ìŠ¤ë¡œë¶€í„° ì¶œë ¥ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ìì—°ì–´ìƒì„±ëª¨ë¸\n",
    "<a href=\"https://medium.com/dl-for-product-and-service/abstractive-text-summary-with-reinforcement-learning-ab2458ab29d5\"><img src='https://miro.medium.com/v2/resize:fit:1360/format:webp/1*Cu49wPEpWJPoI0a5AV9Q1Q.png' ></a>\n",
    "    1. RNN encoder : ì›ë¬¸ ì…ë ¥ -> í•˜ë‚˜ì˜ ê³ ì •ëœ ë²¡í„°ë¡œ ë³€í™˜\n",
    "        - context vector : ë¬¸ë§¥ì„ ê°€ì§„ ë²¡í„°\n",
    "    2. RNN decoder : ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ ì…ë ¥ë°›ì•„ í•œ ë‹¨ì–´ì”© ìƒì„±í•˜ê³  ìš”ì•½ ë¬¸ì¥ ì™„ì„±\n",
    "\n",
    "\n",
    "- í•™ìŠµì—ì„œëŠ” vanila RNN ëŒ€ì‹  LSTM ì‚¬ìš©\n",
    "<a href='https://colah.github.io/posts/2015-08-Understanding-LSTMs/'><img src='https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png' width=70% height=70%></a>   \n",
    "\n",
    "\n",
    "- ì¸ì½”ë” ë§ˆì§€ë§‰ time stepì˜ hidden stateë¥¼ context vectorë¡œ ì‚¬ìš©\n",
    "\n",
    "\n",
    "\n",
    "## LSTM vs Vanila RNN\n",
    "- ë‹¤ìŒ time step ì…€ì— hidden state(h) + cell state(c)\n",
    "- ì¸ì½”ë”ê°€ ë””ì½”ë”ì— ì „ë‹¬í•˜ëŠ” context vectorì— h, c ë‘˜ë‹¤ ì¡´ì¬\n",
    "\n",
    "\n",
    "## Attentional seq2seq\n",
    "<a href='https://arxiv.org/pdf/1812.02303.pdf'><img src='./img/attention.png' width=60% height=60%></a>\n",
    "- seq2seq + attention mechanism\n",
    "- ì¸ì½”ë”ì˜ **ëª¨ë“  step**ì˜ hidden state ì •ë³´ë¥¼ context vectorë¡œ ì‚¬ìš©\n",
    "- ì¸ì½”ë” hidden state ê°€ì¤‘ì¹˜ëŠ” **ë””ì½”ë”ì˜ í˜„ì¬ ìŠ¤í…ì´ ì–´ë””**ëƒì— ë”°ë¼ ê³„ì† ë‹¬ë¼ì§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7de75fc",
   "metadata": {},
   "source": [
    "# ğŸ‘‰ ì •ë¦¬\n",
    "\n",
    "1. **seq2seq + LSTM + attention ì‚¬ìš©**\n",
    "    - 2ê°œ LSTMì„ ë¶™ì—¬ì„œ ì‚¬ìš©\n",
    "    - encoderì˜ hidden stateì˜ ì¤‘ìš”ë„(ê°€ì¤‘ì¹˜)ë¥¼ ì·¨í•©í•œ context vectorëŠ” decoder ìŠ¤í…ë³„ë¡œ ê³„ì‚°\n",
    "    - ê³„ì‚°ëœ context vectorë¥¼ ì´ìš©í•´ì„œ decoderëŠ” ë‹¤ìŒ ë“±ì¥í•  ë‹¨ì–´ë¥¼ ì˜ˆì¸¡\n",
    "2. **hidden state + cell state ëª¨ë‘ ì‚¬ìš©**\n",
    "    - cell state?\n",
    "3. **decoder ì•: SOS start token / ë’¤ : EOS end token ì¶”ê°€**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "310ba5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5\n",
      "2.6.0\n",
      "1.3.3\n",
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "# library version check\n",
    "from importlib.metadata import version\n",
    "import nltk\n",
    "import tensorflow\n",
    "import summa\n",
    "import pandas\n",
    "\n",
    "print(nltk.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(pandas.__version__)\n",
    "print(version('summa'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695058e6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¡ NLTK\n",
    "- Natural Language Toolkit\n",
    "- ì˜ì–´ ê¸°í˜¸, í†µê³„, ìì—°ì–´ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "\n",
    "`stopwords` \n",
    "- I, my, me, over, ì¡°ì‚¬, ì ‘ë¯¸ì‚¬ ë“± ë¶ˆìš©ì–´ ì •ë¦¬\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2edada6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n"
     ]
    }
   ],
   "source": [
    "# necessary library \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='bs4')\n",
    "\n",
    "print(\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7038726d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# `ì¶”ìƒì  ìš”ì•½ Abstractive Summarization`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3ff1d6",
   "metadata": {},
   "source": [
    "# Step 1. ë°ì´í„° ì¤€ë¹„\n",
    "- ë‰´ìŠ¤ ê¸°ì‚¬ ë°ì´í„° : [news_summary_more.csv](https://github.com/sunnysai12345/News_Summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a472c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb3af040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86639</th>\n",
       "      <td>NASA to launch first-ever mission to study neu...</td>\n",
       "      <td>NASA is launching the world's first mission to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67439</th>\n",
       "      <td>International Chole Bhature Day celebrated on ...</td>\n",
       "      <td>The annual International Chole Bhature Day was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95307</th>\n",
       "      <td>Ayodhya issue cannot be resolved by talks: Mul...</td>\n",
       "      <td>Samajwadi Party Founder Mulayam Singh Yadav ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87925</th>\n",
       "      <td>Russian helicopters' 'Make in India' cost 250%...</td>\n",
       "      <td>The cost of Russian Kamov light-utility choppe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7359</th>\n",
       "      <td>Come on, kill me: Owaisi after BJP leader dare...</td>\n",
       "      <td>After Telangana BJP leader T Raja Singh dared ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>Cow dung thrown at National Award-winning dire...</td>\n",
       "      <td>National Award-winning Malayali filmmaker Priy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>Raise parliamentarians' salary to reduce corru...</td>\n",
       "      <td>BJP MP Harish Dwivedi has urged PM Narendra Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23260</th>\n",
       "      <td>Student sodomised by 6 seniors in Ajmer's Mayo...</td>\n",
       "      <td>A grade 11 student from Ajmer's Mayo College w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95753</th>\n",
       "      <td>Air India body slams promoting pilot who misse...</td>\n",
       "      <td>The Air India pilots' association has proteste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56443</th>\n",
       "      <td>2 teachers suspended for spelling errors in En...</td>\n",
       "      <td>Two Rajasthan government school teachers have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "86639  NASA to launch first-ever mission to study neu...   \n",
       "67439  International Chole Bhature Day celebrated on ...   \n",
       "95307  Ayodhya issue cannot be resolved by talks: Mul...   \n",
       "87925  Russian helicopters' 'Make in India' cost 250%...   \n",
       "7359   Come on, kill me: Owaisi after BJP leader dare...   \n",
       "805    Cow dung thrown at National Award-winning dire...   \n",
       "3124   Raise parliamentarians' salary to reduce corru...   \n",
       "23260  Student sodomised by 6 seniors in Ajmer's Mayo...   \n",
       "95753  Air India body slams promoting pilot who misse...   \n",
       "56443  2 teachers suspended for spelling errors in En...   \n",
       "\n",
       "                                                    text  \n",
       "86639  NASA is launching the world's first mission to...  \n",
       "67439  The annual International Chole Bhature Day was...  \n",
       "95307  Samajwadi Party Founder Mulayam Singh Yadav ha...  \n",
       "87925  The cost of Russian Kamov light-utility choppe...  \n",
       "7359   After Telangana BJP leader T Raja Singh dared ...  \n",
       "805    National Award-winning Malayali filmmaker Priy...  \n",
       "3124   BJP MP Harish Dwivedi has urged PM Narendra Mo...  \n",
       "23260  A grade 11 student from Ajmer's Mayo College w...  \n",
       "95753  The Air India pilots' association has proteste...  \n",
       "56443  Two Rajasthan government school teachers have ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data check\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7cc1f",
   "metadata": {},
   "source": [
    "- ë°ì´í„°ëŠ” `text` `headlines` ë‘ê°€ì§€ ì—´ë¡œ êµ¬ì„±ë˜ì–´ìˆë‹¤\n",
    "- ì¶”ìƒì  ìš”ì•½ì—ì„œëŠ” ì•„ë˜ì™€ ê°™ì´ ë°ì´í„°ë¥¼ í™œìš©\n",
    "    - `text`: ì›ë¬¸\n",
    "    - `headlines`: ìš”ì•½ ë°ì´í„°\n",
    "- ì¶”ì¶œì  ìš”ì•½ì—ì„œëŠ” text ë°ì´í„°ë§Œ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecc0243c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98401"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb289d",
   "metadata": {},
   "source": [
    "- data ì´ 98,401ê°œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8351a6f",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 2. Data preprocessing\n",
    "## 1) Remove duplicate & Null values\n",
    "\n",
    "- `df.nunique()` : ì¤‘ë³µë°ì´í„° ì œì™¸í•œ ë°ì´í„° ìˆ˜ í™•ì¸ \n",
    "- `df.drop_duplicates()` : ì¤‘ë³µë°ì´í„° ì‚­ì œ\n",
    "    - `subset` : íŠ¹ì • ì—´ì— ëŒ€í•œ ì¤‘ë³µë°ì´í„°ë¥¼ ì‚­ì œí•˜ê³  ì‹¶ì„ë•Œ ì„¤ì • \n",
    "    > **subset : column label or sequence of labels, optional**<br>\n",
    "      Only consider certain columns for identifying duplicates, by default use all of the columns. [ref](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html)\n",
    "    - `inplace=True` : ë°ì´í„°í”„ë ˆì„ ë‚´ë¶€ë¥¼ ì§ì ‘ ìˆ˜ì •\n",
    "    \n",
    "\n",
    "- `df.isnull().sum()` : dfì— Null ê°’ì´ ì´ ëª‡ê°œ ìˆëŠ”ì§€ í™•ì¸\n",
    "- `df.dropna()` : ë°ì´í„°í”„ë ˆì„ Null ì œê±°\n",
    "    - `axis=` : ì‚­ì œí•  ë°©í–¥ ì •í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f133873c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text ì—´ì—ì„œ ì¤‘ë³µì„ ë°°ì œí•œ ìœ ì¼í•œ ìƒ˜í”Œì˜ ìˆ˜ : 98360\n",
      "headlines ì—´ì—ì„œ ì¤‘ë³µì„ ë°°ì œí•œ ìœ ì¼í•œ ìƒ˜í”Œì˜ ìˆ˜ : 98280\n"
     ]
    }
   ],
   "source": [
    "print('text ì—´ì—ì„œ ì¤‘ë³µì„ ë°°ì œí•œ ìœ ì¼í•œ ìƒ˜í”Œì˜ ìˆ˜ :', data['text'].nunique())\n",
    "print('headlines ì—´ì—ì„œ ì¤‘ë³µì„ ë°°ì œí•œ ìœ ì¼í•œ ìƒ˜í”Œì˜ ìˆ˜ :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c146b378",
   "metadata": {},
   "source": [
    "- ì´ ë°ì´í„° ìˆ˜ëŠ” 98401ì´ë¼ ê° ì—´ì— ì¤‘ë³µëœ ë°ì´í„°ë“¤ì´ ìˆëŠ”ê±¸ í™•ì¸í• ìˆ˜ ìˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6ef45e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 98360\n"
     ]
    }
   ],
   "source": [
    "# ì¤‘ë³µ ìƒ˜í”Œ ì œê±°\n",
    "data.drop_duplicates(subset=['text'], inplace=True)\n",
    "print('total samples:', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a498d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°ì— null ìˆëŠ”ì§€ ë‹¤ì‹œ í™•ì¸\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dc9b1a",
   "metadata": {},
   "source": [
    "- null ë°ì´í„°ë„ ì—†ì´ ê¹”ë”í•˜ê²Œ ì •ë¦¬ì™„ë£Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870e0d45",
   "metadata": {},
   "source": [
    "## 2) Text normalization\n",
    "- `it'll` `it will` / `mustn't` `must not` ê°™ì€ í‘œí˜„ ì„œë¡œ ê°™ì€ê±°ë¼ê³  ì„¤ì •í•´ì£¼ê¸°\n",
    "- [í…ìŠ¤íŠ¸ ì •ê·œí™” ì‚¬ì „](https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python) ë°ì´í„°ë¥¼ í™œìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce971ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •ê·œí™” ì‚¬ì „ì˜ ìˆ˜:  120\n"
     ]
    }
   ],
   "source": [
    "# í…ìŠ¤íŠ¸ ì •ê·œí™” ì‚¬ì „\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"ì •ê·œí™” ì‚¬ì „ì˜ ìˆ˜: \", len(contractions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d020c12",
   "metadata": {},
   "source": [
    "## 3) Remove `Stopwords` + etc\n",
    "`stopwords` ë¶ˆìš©ì–´\n",
    "- í…ìŠ¤íŠ¸ì—ëŠ” ìì£¼ ë“±ì¥í•˜ì§€ë§Œ ìì—°ì–´ ì²˜ë¦¬í• ë•Œ ë„ì›€ì´ ë˜ì§€ ì•ŠëŠ” ë‹¨ì–´ë“¤\n",
    "\n",
    "**etc**\n",
    "- text to lowercase\n",
    "- remove html tag\n",
    "- remove special characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "080455bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f946430d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of stopwords:  179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('# of stopwords: ', len(stopwords.words('english')))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b08b05",
   "metadata": {},
   "source": [
    "- stopwordsëŠ” ëª¨ë‘ 179ê°œê°€ ìˆë‹¤\n",
    "\n",
    "### `preprocess_sentence()` ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d09d618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing function - stopwords + etc\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # í…ìŠ¤íŠ¸ ì†Œë¬¸ìí™”\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # html íƒœê·¸ ì œê±° : <br />, <a href = ...> ë“± \n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # ê´„í˜¸ë¡œ ë‹«íŒ ë¬¸ìì—´ (...) ì œê±° : e.g. my husband (and myself!) for => my husband\n",
    "    sentence = re.sub('\"','', sentence) # ìŒë”°ì˜´í‘œ \" ì œê±°\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # ì•½ì–´ ì •ê·œí™”\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # ì†Œìœ ê²© ì œê±° : e.g. roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # ì˜ì–´ ì™¸ ë¬¸ì(ìˆ«ì, íŠ¹ìˆ˜ë¬¸ì ë“±) ê³µë°±ìœ¼ë¡œ ë³€í™˜\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # mì´ 3ê°œ ì´ìƒì´ë©´ 2ê°œë¡œ ë³€ê²½ : e.g. ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # ë¶ˆìš©ì–´ ì œê±° (text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # ë¶ˆìš©ì–´ ë¯¸ì œê±° (headlines)\n",
    "    # ì§§ì€ í…ìŠ¤íŠ¸ì˜ ê²½ìš° ë¶ˆìš©ì–´ê°€ ìˆì–´ì•¼ ìì—°ìŠ¤ëŸ½ê¸°ë•Œë¬¸\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens\n",
    "\n",
    "print('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3db07175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  everything bought great infact ordered twice third ordered wasfor mother father\n",
      "headlines: great way to start the day\n"
     ]
    }
   ],
   "source": [
    "# test fucntion\n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_headlines = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(\"text: \", preprocess_sentence(temp_text))\n",
    "print(\"headlines:\", preprocess_sentence(temp_headlines, False))  # ë¶ˆìš©ì–´ë¥¼ ì œê±°í•˜ì§€ ì•ŠëŠ”ë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03c103",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ğŸ’¡\n",
    "###  `preprocess_data()` ë°ì´í„° ì „ì²˜ë¦¬ ì†ë„ ê°œì„  í•¨ìˆ˜\n",
    "- ë°ì´í„° ì „ì²˜ë¦¬ ì‹œê°„ì´ ë§¤ìš° ì˜¤ë˜ê±¸ë ¸ëŠ”ë° [ì§€ë‚œ ê¸°ìˆ˜ ê·¸ë£¨ì˜ ì½”ë“œ](https://github.com/jangjs1103/laboratory/blob/main/AIFFEL/LMS/Exploration_10/Exploration_10_%EC%9A%94%EC%95%BD%EB%AC%B8.ipynb)ë¥¼ ì°¸ê³ í•´ì„œ ì†ë„ë¥¼ ë†’ì´ëŠ” ì‹œë„ë¥¼ í•´ë³¸ë‹¤\n",
    "- ìì„¸í•œ ì§„í–‰ë°©ë²•ì€ ì´í•´í•˜ê¸° ì–´ë ¤ì› ì§€ë§Œ, **ë©€í‹°í”„ë¡œì„¸ì‹±ì„ í• ìˆ˜ ìˆë„ë¡ cpu ì½”ì–´ìˆ˜ì— ë§ì¶°ì„œ ë°ì´í„°ë¥¼ ë°°ë¶„**í•˜ëŠ” ë°©ì‹ì´ì—ˆë‹¤.\n",
    "- ë˜ **map í•¨ìˆ˜ì— ì—¬ëŸ¬ ì¸ìë¥¼ ë„£ì–´ì¤„ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬**ê°€ ë”°ë¡œ ìˆë‹¤ëŠ”ê±¸ ì•Œê²Œë˜ì–´ ì‹ ê¸°í–ˆë‹¤!\n",
    "    - [`partial` ì°¸ê³  ìë£Œ](https://tempdev.tistory.com/36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1e11bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of cores:  4\n",
      "372.938499212265  seconds\n",
      "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers'\n",
      " 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit'\n",
      " 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history'\n",
      " ...\n",
      " 'according reports new version science fiction film matrix development michael jordan reportedly play lead role film screenwriter zak penn talks write script film reports added actor keanu reeves starred original film followed two sequels'\n",
      " 'new music video shows rapper snoop dogg aiming toy gun clown character parodying us president donald trump video also shows tv airing news conference headline ronald klump wants deport doggs airing live clown house video remixed version song lavender'\n",
      " 'madhesi morcha alliance seven political parties withdrawn support pm pushpa kamal dahal led nepal government failed meet seven day ultimatum fulfil demands including endorsement revised constitution amendment bill morcha seats parliament despite withdrawal support immediate threat government']\n",
      "# of cores:  4\n",
      "9.747351169586182  seconds\n",
      "['upgrad learner switches to career in ml al with salary hike'\n",
      " 'delhi techie wins free food from swiggy for one year on cred'\n",
      " 'new zealand end rohit sharma led india match winning streak' ...\n",
      " 'the matrix film to get reboot reports'\n",
      " 'snoop dogg aims gun at clown dressed as trump in new video'\n",
      " 'madhesi morcha withdraws support to nepalese government']\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp   # ì „ì²˜ë¦¬ ì†ë„ë¥¼ íšê¸°ì ìœ¼ë¡œ ì¤„ì—¬ì¤„ ë©€í‹° í”„ë¡œì„¸ì‹±\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import partial  # multiprocessing.Poolì˜ map()ì— ì—¬ëŸ¬ ì¸ìë¥¼ ë„£ì–´ì¤„ ìˆ˜ ìˆê²Œ í•´ì¤Œ\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# num_cores ë§Œí¼ ìª¼ê°œì§„ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ì—¬ ë°˜í™˜\n",
    "def appendTexts(sentences, remove_stopwords):\n",
    "    texts = []\n",
    "    for s in sentences:\n",
    "        texts += preprocess_sentence(s, remove_stopwords),\n",
    "    return texts\n",
    "\n",
    "# ì†ë„ê°œì„  í•¨ìˆ˜\n",
    "def preprocess_data(data, remove_stopwords=True):\n",
    "    start_time = time.time()\n",
    "    num_cores = mp.cpu_count()  # ì»´í“¨í„°ì˜ ì½”ì–´ ìˆ˜ë¥¼ í™•ì¸\n",
    "    print(\"# of cores: \", num_cores)\n",
    "\n",
    "    text_data_split = np.array_split(data, num_cores)  # ì½”ì–´ ìˆ˜ë§Œí¼ ë°ì´í„°ë¥¼ ë°°ë¶„í•˜ì—¬ ë³‘ë ¬ì ìœ¼ë¡œ ì²˜ë¦¬\n",
    "    \n",
    "    pool = Pool(num_cores)\n",
    "    \n",
    "    # partialì„ ì´ìš©í•´ì„œ map í•¨ìˆ˜ì— ì—¬ëŸ¬ ì¸ì ì „ë‹¬\n",
    "    processed_data = np.concatenate(pool.map(partial(appendTexts, remove_stopwords=remove_stopwords), text_data_split)) # ê°ì ì‘ì—…í•œ ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ ì—°ê²°\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print(time.time() - start_time, \" seconds\")\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# text ì „ì²˜ë¦¬\n",
    "clean_text = preprocess_data(data['text'])\n",
    "print(clean_text)\n",
    "\n",
    "# headlines ì „ì²˜ë¦¬\n",
    "clean_headlines = preprocess_data(data['headlines'], remove_stopwords=False) # ë¶ˆìš©ì–´ ì œê±°í•˜ì§€ ì•ŠìŒ\n",
    "print(clean_headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d8ca99",
   "metadata": {},
   "source": [
    "- text ë°ì´í„° ì „ì²˜ë¦¬ ì‹œê°„ì´ 370ì´ˆ=**6ë¶„**ì´ ì†Œìš”ë˜ì—ˆë‹¤\n",
    "- ì´ì „ ë…¸ë“œì—ì„œ ì§„í–‰í•œ ë°ì´í„° ì–‘ê³¼ ë¹„êµí–ˆì„ë•Œ ë¹„ìŠ·í•˜ë‹ˆ ì¡°ê¸ˆ ë” ë¹¨ë¼ì§„ê²Œ ì•„ë‹ê¹Œ..? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4db7ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¤‘ê°„ê³¼ì • ë°ì´í„° ë³µì‚¬ - ë¶ˆìš©ì–´ ì‚­ì œ ì „ ë°ì´í„°\n",
    "origin_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a76eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ì¡´ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¡œ ë³€í™˜\n",
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4416839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë¹ˆ ë°ì´í„° ìˆëŠ”ì§€ í™•ì¸\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce4d5aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 98360\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²˜ë¦¬ í›„ì˜ ë°ì´í„° ìˆ˜ í™•ì¸\n",
    "print('total samples:', len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c903972",
   "metadata": {},
   "source": [
    "- ìµœì¢… ë°ì´í„° ìˆ˜ëŠ” 98360ê°œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c741a610",
   "metadata": {},
   "source": [
    "## 4) ë°ì´í„° ìƒ˜í”Œì˜ ë¶„í¬ ì‹œê°í™”\n",
    "- Text, Summaryì˜ ìµœì†Œ, ìµœëŒ€, í‰ê·  ê¸¸ì´ë¥¼ êµ¬í•˜ê³ , ê¸¸ì´ ë¶„í¬ ì‹œê°í™”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1746ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[text]ì˜ ìµœì†Œ ê¸¸ì´ : 1\n",
      "[text]ì˜ ìµœëŒ€ ê¸¸ì´ : 60\n",
      "[text]ì˜ í‰ê·  ê¸¸ì´ : 35.09968483123221\n",
      "[headlines]ì˜ ìµœì†Œ ê¸¸ì´ : 1\n",
      "[headlines]ì˜ ìµœëŒ€ ê¸¸ì´ : 16\n",
      "[headlines]ì˜ í‰ê·  ê¸¸ì´ : 9.299532330215534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ê¸¸ì´ ë¶„í¬ ì¶œë ¥\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data length in each row\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('[text]ì˜ ìµœì†Œ ê¸¸ì´ : {}'.format(np.min(text_len)))\n",
    "print('[text]ì˜ ìµœëŒ€ ê¸¸ì´ : {}'.format(np.max(text_len)))\n",
    "print('[text]ì˜ í‰ê·  ê¸¸ì´ : {}'.format(np.mean(text_len)))\n",
    "print('[headlines]ì˜ ìµœì†Œ ê¸¸ì´ : {}'.format(np.min(headlines_len)))\n",
    "print('[headlines]ì˜ ìµœëŒ€ ê¸¸ì´ : {}'.format(np.max(headlines_len)))\n",
    "print('[headlines]ì˜ í‰ê·  ê¸¸ì´ : {}'.format(np.mean(headlines_len)))\n",
    "\n",
    "# boxplot\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('Headlines')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# histogram\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Headlines')\n",
    "plt.hist(headlines_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e58953",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ğŸ’¡\n",
    "[`Series.str.split()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html)\n",
    "- ()ì•ˆì— ë„£ì€ ì¸ìë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ strì„ ë¶„ë¦¬í•˜ëŠ” ë©”ì„œë“œì¸ë°, ì—¬ê¸°ì—ì„œëŠ” ì•„ë¬´ ê°’ë„ ë„£ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— ì „ì²´ strì„ ì¶”ì¶œí•˜ê²Œ ëœë‹¤.\n",
    "> Pandas `str.split()` method can be applied to a whole series.\n",
    "- pythonì˜ `split()` ë©”ì„œë“œëŠ” `str`ë§Œ ì ìš©ì´ ê°€ëŠ¥í•˜ê³ , ì§€ê¸ˆ ë°ì´í„°ëŠ” seriesì´ê¸° ë•Œë¬¸ì— pandasì˜ `str.split()`ì„ ì‚¬ìš©í•œë‹¤. \n",
    "    - ìœ„ ì½”ë“œë¥¼ ë³´ë©´ `[len(s.split()) for s in df['Text']` lambdaí˜•íƒœë¡œ ì‘ì„±í–ˆëŠ”ë°, `s`:strì„ êº¼ë‚´ì„œ s.split()ì„ í•œë‹¤. \n",
    "> Return value :Series of list or Data frame depending on expand Parameter\n",
    "- ìš°ë¦¬ëŠ” ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì—ˆê¸°ë•Œë¬¸ì— ì•„ë˜ì™€ ê°™ì€ í˜•íƒœì˜ ë°ì´í„°ê°€ ë§Œë“¤ì–´ì§„ë‹¤.\n",
    "\n",
    "- *ê·¸ëŸ°ë°, str ì„ ë¶™ì´ì§€ ì•Šê³  ì‚¬ìš©í•´ë„ë˜ëŠ”ê±´ê°€? ìœ„ì— ì½”ë“œì—ì„œ s ëŠ” series ê·¸ ìì²´ì˜ ê°’ ê°™ì€ë°, í™•ì¸ì„ í•´ë´ì•¼ê² ë‹¤.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16b1cef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([39,\n",
       "  45,\n",
       "  38,\n",
       "  34,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  35,\n",
       "  27,\n",
       "  34,\n",
       "  33,\n",
       "  42,\n",
       "  32,\n",
       "  38,\n",
       "  35,\n",
       "  39,\n",
       "  36,\n",
       "  32,\n",
       "  34,\n",
       "  36,\n",
       "  34,\n",
       "  40,\n",
       "  32,\n",
       "  36,\n",
       "  39,\n",
       "  35,\n",
       "  29,\n",
       "  34,\n",
       "  38,\n",
       "  39,\n",
       "  38,\n",
       "  36,\n",
       "  43,\n",
       "  42,\n",
       "  34,\n",
       "  40,\n",
       "  36,\n",
       "  35,\n",
       "  38,\n",
       "  31,\n",
       "  38,\n",
       "  40,\n",
       "  35,\n",
       "  38,\n",
       "  38,\n",
       "  32,\n",
       "  33,\n",
       "  35,\n",
       "  36,\n",
       "  36,\n",
       "  39,\n",
       "  35,\n",
       "  1,\n",
       "  24,\n",
       "  32,\n",
       "  36,\n",
       "  38,\n",
       "  34,\n",
       "  40,\n",
       "  40,\n",
       "  35,\n",
       "  43,\n",
       "  30,\n",
       "  38,\n",
       "  41,\n",
       "  41,\n",
       "  37,\n",
       "  34,\n",
       "  34,\n",
       "  44,\n",
       "  37,\n",
       "  40,\n",
       "  40,\n",
       "  34,\n",
       "  38,\n",
       "  36,\n",
       "  34,\n",
       "  34,\n",
       "  40,\n",
       "  35,\n",
       "  39,\n",
       "  37,\n",
       "  45,\n",
       "  37,\n",
       "  33,\n",
       "  35,\n",
       "  36,\n",
       "  38,\n",
       "  37,\n",
       "  36,\n",
       "  35,\n",
       "  32,\n",
       "  32,\n",
       "  31,\n",
       "  27,\n",
       "  28,\n",
       "  34,\n",
       "  33,\n",
       "  33,\n",
       "  36,\n",
       "  39,\n",
       "  42,\n",
       "  35,\n",
       "  40,\n",
       "  42,\n",
       "  36,\n",
       "  39,\n",
       "  33,\n",
       "  35,\n",
       "  33,\n",
       "  45,\n",
       "  34,\n",
       "  34,\n",
       "  36,\n",
       "  35,\n",
       "  37,\n",
       "  32,\n",
       "  36,\n",
       "  34,\n",
       "  36,\n",
       "  38,\n",
       "  38,\n",
       "  39,\n",
       "  35,\n",
       "  36,\n",
       "  31,\n",
       "  39,\n",
       "  44,\n",
       "  40,\n",
       "  41,\n",
       "  36,\n",
       "  33,\n",
       "  35,\n",
       "  36,\n",
       "  32,\n",
       "  33,\n",
       "  27,\n",
       "  43,\n",
       "  38,\n",
       "  37,\n",
       "  34,\n",
       "  33,\n",
       "  37,\n",
       "  31,\n",
       "  41,\n",
       "  34,\n",
       "  36,\n",
       "  35,\n",
       "  36,\n",
       "  31,\n",
       "  34,\n",
       "  35,\n",
       "  39,\n",
       "  41,\n",
       "  38,\n",
       "  41,\n",
       "  32,\n",
       "  38,\n",
       "  35,\n",
       "  32,\n",
       "  33,\n",
       "  36,\n",
       "  38,\n",
       "  39,\n",
       "  33,\n",
       "  34,\n",
       "  38,\n",
       "  34,\n",
       "  35,\n",
       "  37,\n",
       "  32,\n",
       "  38,\n",
       "  31,\n",
       "  33,\n",
       "  31,\n",
       "  37,\n",
       "  35,\n",
       "  39,\n",
       "  38,\n",
       "  25,\n",
       "  36,\n",
       "  35,\n",
       "  38,\n",
       "  33,\n",
       "  27,\n",
       "  39,\n",
       "  39,\n",
       "  31,\n",
       "  34,\n",
       "  37,\n",
       "  37,\n",
       "  37,\n",
       "  34,\n",
       "  37,\n",
       "  29,\n",
       "  35,\n",
       "  38,\n",
       "  41,\n",
       "  36,\n",
       "  34,\n",
       "  37,\n",
       "  34,\n",
       "  32,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  35,\n",
       "  39,\n",
       "  38,\n",
       "  32,\n",
       "  40,\n",
       "  35,\n",
       "  41,\n",
       "  34,\n",
       "  38,\n",
       "  35,\n",
       "  36,\n",
       "  40,\n",
       "  38,\n",
       "  34,\n",
       "  27,\n",
       "  33,\n",
       "  35,\n",
       "  35,\n",
       "  33,\n",
       "  37,\n",
       "  38,\n",
       "  38,\n",
       "  34,\n",
       "  38,\n",
       "  32,\n",
       "  41,\n",
       "  34,\n",
       "  36,\n",
       "  28,\n",
       "  31,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  32,\n",
       "  40,\n",
       "  33,\n",
       "  41,\n",
       "  33,\n",
       "  36,\n",
       "  38,\n",
       "  35,\n",
       "  37,\n",
       "  45,\n",
       "  36,\n",
       "  42,\n",
       "  38,\n",
       "  32,\n",
       "  33,\n",
       "  36,\n",
       "  35,\n",
       "  46,\n",
       "  40,\n",
       "  37,\n",
       "  28,\n",
       "  33,\n",
       "  34,\n",
       "  37,\n",
       "  39,\n",
       "  34,\n",
       "  32,\n",
       "  36,\n",
       "  40,\n",
       "  30,\n",
       "  33,\n",
       "  36,\n",
       "  30,\n",
       "  36,\n",
       "  32,\n",
       "  38,\n",
       "  34,\n",
       "  28,\n",
       "  38,\n",
       "  33,\n",
       "  28,\n",
       "  40,\n",
       "  43,\n",
       "  29,\n",
       "  36,\n",
       "  41,\n",
       "  38,\n",
       "  41,\n",
       "  30,\n",
       "  40,\n",
       "  41,\n",
       "  32,\n",
       "  35,\n",
       "  34,\n",
       "  31,\n",
       "  38,\n",
       "  28,\n",
       "  32,\n",
       "  33,\n",
       "  43,\n",
       "  35,\n",
       "  38,\n",
       "  31,\n",
       "  35,\n",
       "  42,\n",
       "  39,\n",
       "  35,\n",
       "  38,\n",
       "  31,\n",
       "  32,\n",
       "  35,\n",
       "  31,\n",
       "  35,\n",
       "  36,\n",
       "  39,\n",
       "  39,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  29,\n",
       "  36,\n",
       "  37,\n",
       "  32,\n",
       "  30,\n",
       "  31,\n",
       "  36,\n",
       "  37,\n",
       "  39,\n",
       "  36,\n",
       "  27,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  33,\n",
       "  33,\n",
       "  36,\n",
       "  36,\n",
       "  34,\n",
       "  33,\n",
       "  36,\n",
       "  39,\n",
       "  37,\n",
       "  24,\n",
       "  34,\n",
       "  38,\n",
       "  34,\n",
       "  35,\n",
       "  37,\n",
       "  40,\n",
       "  30,\n",
       "  32,\n",
       "  38,\n",
       "  34,\n",
       "  33,\n",
       "  30,\n",
       "  34,\n",
       "  34,\n",
       "  38,\n",
       "  35,\n",
       "  38,\n",
       "  35,\n",
       "  34,\n",
       "  39,\n",
       "  36,\n",
       "  39,\n",
       "  38,\n",
       "  38,\n",
       "  37,\n",
       "  33,\n",
       "  35,\n",
       "  36,\n",
       "  36,\n",
       "  35,\n",
       "  33,\n",
       "  33,\n",
       "  37,\n",
       "  36,\n",
       "  31,\n",
       "  42,\n",
       "  38,\n",
       "  42,\n",
       "  37,\n",
       "  44,\n",
       "  36,\n",
       "  32,\n",
       "  32,\n",
       "  34,\n",
       "  32,\n",
       "  33,\n",
       "  37,\n",
       "  32,\n",
       "  32,\n",
       "  42,\n",
       "  43,\n",
       "  35,\n",
       "  34,\n",
       "  33,\n",
       "  31,\n",
       "  41,\n",
       "  33,\n",
       "  36,\n",
       "  33,\n",
       "  40,\n",
       "  36,\n",
       "  35,\n",
       "  36,\n",
       "  28,\n",
       "  35,\n",
       "  33,\n",
       "  36,\n",
       "  35,\n",
       "  32,\n",
       "  33,\n",
       "  30,\n",
       "  37,\n",
       "  37,\n",
       "  36,\n",
       "  31,\n",
       "  38,\n",
       "  33,\n",
       "  39,\n",
       "  39,\n",
       "  38,\n",
       "  26,\n",
       "  35,\n",
       "  35,\n",
       "  31,\n",
       "  36,\n",
       "  38,\n",
       "  46,\n",
       "  35,\n",
       "  37,\n",
       "  41,\n",
       "  38,\n",
       "  35,\n",
       "  34,\n",
       "  32,\n",
       "  37,\n",
       "  35,\n",
       "  35,\n",
       "  34,\n",
       "  29,\n",
       "  27,\n",
       "  31,\n",
       "  36,\n",
       "  37,\n",
       "  37,\n",
       "  28,\n",
       "  29,\n",
       "  42,\n",
       "  30,\n",
       "  37,\n",
       "  30,\n",
       "  37,\n",
       "  32,\n",
       "  36,\n",
       "  37,\n",
       "  41,\n",
       "  34,\n",
       "  36,\n",
       "  37,\n",
       "  25,\n",
       "  49,\n",
       "  37,\n",
       "  38,\n",
       "  26,\n",
       "  36,\n",
       "  35,\n",
       "  40,\n",
       "  35,\n",
       "  40,\n",
       "  43,\n",
       "  27,\n",
       "  28,\n",
       "  37,\n",
       "  42,\n",
       "  32,\n",
       "  42,\n",
       "  39,\n",
       "  41,\n",
       "  36,\n",
       "  41,\n",
       "  29,\n",
       "  35,\n",
       "  32,\n",
       "  39,\n",
       "  38,\n",
       "  29,\n",
       "  32,\n",
       "  32,\n",
       "  34,\n",
       "  41,\n",
       "  35,\n",
       "  41,\n",
       "  33,\n",
       "  33,\n",
       "  36,\n",
       "  36,\n",
       "  34,\n",
       "  28,\n",
       "  33,\n",
       "  38,\n",
       "  35,\n",
       "  39,\n",
       "  32,\n",
       "  36,\n",
       "  37,\n",
       "  27,\n",
       "  41,\n",
       "  40,\n",
       "  36,\n",
       "  40,\n",
       "  27,\n",
       "  35,\n",
       "  32,\n",
       "  32,\n",
       "  35,\n",
       "  38,\n",
       "  32,\n",
       "  37,\n",
       "  35,\n",
       "  32,\n",
       "  34,\n",
       "  32,\n",
       "  41,\n",
       "  37,\n",
       "  37,\n",
       "  33,\n",
       "  36,\n",
       "  36,\n",
       "  34,\n",
       "  34,\n",
       "  35,\n",
       "  34,\n",
       "  36,\n",
       "  33,\n",
       "  32,\n",
       "  43,\n",
       "  33,\n",
       "  32,\n",
       "  39,\n",
       "  37,\n",
       "  36,\n",
       "  33,\n",
       "  38,\n",
       "  35,\n",
       "  35,\n",
       "  38,\n",
       "  37,\n",
       "  33,\n",
       "  35,\n",
       "  33,\n",
       "  36,\n",
       "  39,\n",
       "  40,\n",
       "  32,\n",
       "  34,\n",
       "  34,\n",
       "  35,\n",
       "  37,\n",
       "  32,\n",
       "  36,\n",
       "  41,\n",
       "  35,\n",
       "  35,\n",
       "  33,\n",
       "  39,\n",
       "  37,\n",
       "  33,\n",
       "  35,\n",
       "  33,\n",
       "  34,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  36,\n",
       "  34,\n",
       "  37,\n",
       "  33,\n",
       "  30,\n",
       "  34,\n",
       "  32,\n",
       "  40,\n",
       "  38,\n",
       "  31,\n",
       "  36,\n",
       "  31,\n",
       "  36,\n",
       "  33,\n",
       "  38,\n",
       "  42,\n",
       "  38,\n",
       "  33,\n",
       "  33,\n",
       "  36,\n",
       "  35,\n",
       "  44,\n",
       "  36,\n",
       "  37,\n",
       "  35,\n",
       "  35,\n",
       "  31,\n",
       "  32,\n",
       "  28,\n",
       "  40,\n",
       "  33,\n",
       "  31,\n",
       "  45,\n",
       "  34,\n",
       "  38,\n",
       "  38,\n",
       "  31,\n",
       "  38,\n",
       "  35,\n",
       "  33,\n",
       "  36,\n",
       "  31,\n",
       "  34,\n",
       "  31,\n",
       "  35,\n",
       "  41,\n",
       "  42,\n",
       "  35,\n",
       "  35,\n",
       "  34,\n",
       "  35,\n",
       "  35,\n",
       "  40,\n",
       "  39,\n",
       "  29,\n",
       "  34,\n",
       "  39,\n",
       "  38,\n",
       "  33,\n",
       "  33,\n",
       "  40,\n",
       "  37,\n",
       "  37,\n",
       "  38,\n",
       "  32,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  45,\n",
       "  33,\n",
       "  38,\n",
       "  39,\n",
       "  39,\n",
       "  37,\n",
       "  32,\n",
       "  39,\n",
       "  36,\n",
       "  32,\n",
       "  32,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  38,\n",
       "  34,\n",
       "  40,\n",
       "  37,\n",
       "  41,\n",
       "  40,\n",
       "  42,\n",
       "  34,\n",
       "  38,\n",
       "  41,\n",
       "  37,\n",
       "  38,\n",
       "  37,\n",
       "  25,\n",
       "  32,\n",
       "  29,\n",
       "  31,\n",
       "  39,\n",
       "  35,\n",
       "  37,\n",
       "  36,\n",
       "  42,\n",
       "  35,\n",
       "  35,\n",
       "  38,\n",
       "  33,\n",
       "  37,\n",
       "  32,\n",
       "  34,\n",
       "  34,\n",
       "  36,\n",
       "  41,\n",
       "  36,\n",
       "  43,\n",
       "  34,\n",
       "  35,\n",
       "  34,\n",
       "  37,\n",
       "  34,\n",
       "  42,\n",
       "  32,\n",
       "  36,\n",
       "  32,\n",
       "  40,\n",
       "  38,\n",
       "  34,\n",
       "  35,\n",
       "  40,\n",
       "  36,\n",
       "  48,\n",
       "  36,\n",
       "  37,\n",
       "  37,\n",
       "  40,\n",
       "  33,\n",
       "  38,\n",
       "  35,\n",
       "  42,\n",
       "  40,\n",
       "  28,\n",
       "  31,\n",
       "  28,\n",
       "  36,\n",
       "  38,\n",
       "  44,\n",
       "  40,\n",
       "  38,\n",
       "  50,\n",
       "  36,\n",
       "  45,\n",
       "  26,\n",
       "  37,\n",
       "  45,\n",
       "  33,\n",
       "  31,\n",
       "  35,\n",
       "  41,\n",
       "  38,\n",
       "  40,\n",
       "  33,\n",
       "  32,\n",
       "  30,\n",
       "  38,\n",
       "  29,\n",
       "  36,\n",
       "  38,\n",
       "  39,\n",
       "  41,\n",
       "  29,\n",
       "  32,\n",
       "  33,\n",
       "  36,\n",
       "  44,\n",
       "  35,\n",
       "  35,\n",
       "  35,\n",
       "  30,\n",
       "  36,\n",
       "  28,\n",
       "  32,\n",
       "  35,\n",
       "  36,\n",
       "  32,\n",
       "  33,\n",
       "  32,\n",
       "  36,\n",
       "  38,\n",
       "  33,\n",
       "  35,\n",
       "  41,\n",
       "  33,\n",
       "  31,\n",
       "  41,\n",
       "  36,\n",
       "  32,\n",
       "  33,\n",
       "  41,\n",
       "  38,\n",
       "  42,\n",
       "  31,\n",
       "  34,\n",
       "  37,\n",
       "  34,\n",
       "  40,\n",
       "  31,\n",
       "  46,\n",
       "  37,\n",
       "  33,\n",
       "  39,\n",
       "  34,\n",
       "  41,\n",
       "  32,\n",
       "  32,\n",
       "  39,\n",
       "  34,\n",
       "  32,\n",
       "  32,\n",
       "  33,\n",
       "  27,\n",
       "  31,\n",
       "  35,\n",
       "  34,\n",
       "  33,\n",
       "  29,\n",
       "  41,\n",
       "  34,\n",
       "  31,\n",
       "  31,\n",
       "  28,\n",
       "  33,\n",
       "  34,\n",
       "  32,\n",
       "  35,\n",
       "  39,\n",
       "  43,\n",
       "  30,\n",
       "  27,\n",
       "  33,\n",
       "  39,\n",
       "  28,\n",
       "  33,\n",
       "  37,\n",
       "  28,\n",
       "  32,\n",
       "  37,\n",
       "  28,\n",
       "  34,\n",
       "  33,\n",
       "  36,\n",
       "  31,\n",
       "  40,\n",
       "  37,\n",
       "  32,\n",
       "  37,\n",
       "  35,\n",
       "  38,\n",
       "  37,\n",
       "  40,\n",
       "  35,\n",
       "  38,\n",
       "  33,\n",
       "  32,\n",
       "  35,\n",
       "  32,\n",
       "  34,\n",
       "  43,\n",
       "  41,\n",
       "  34,\n",
       "  38,\n",
       "  36,\n",
       "  46,\n",
       "  36,\n",
       "  35,\n",
       "  37,\n",
       "  37,\n",
       "  34,\n",
       "  30,\n",
       "  39,\n",
       "  32,\n",
       "  32,\n",
       "  34,\n",
       "  36,\n",
       "  37,\n",
       "  32,\n",
       "  37,\n",
       "  37,\n",
       "  28,\n",
       "  34,\n",
       "  35,\n",
       "  37,\n",
       "  40,\n",
       "  35,\n",
       "  33,\n",
       "  36,\n",
       "  36,\n",
       "  38,\n",
       "  33,\n",
       "  39,\n",
       "  34,\n",
       "  28,\n",
       "  37,\n",
       "  31,\n",
       "  37,\n",
       "  33,\n",
       "  31,\n",
       "  33,\n",
       "  34,\n",
       "  40,\n",
       "  33,\n",
       "  25,\n",
       "  34,\n",
       "  38,\n",
       "  36,\n",
       "  38,\n",
       "  35,\n",
       "  28,\n",
       "  35,\n",
       "  33,\n",
       "  39,\n",
       "  38,\n",
       "  38,\n",
       "  40,\n",
       "  33,\n",
       "  39,\n",
       "  43,\n",
       "  35,\n",
       "  40,\n",
       "  35,\n",
       "  34,\n",
       "  41,\n",
       "  36,\n",
       "  31,\n",
       "  35,\n",
       "  40,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  37,\n",
       "  40,\n",
       "  36,\n",
       "  31,\n",
       "  36,\n",
       "  43,\n",
       "  33,\n",
       "  44,\n",
       "  35,\n",
       "  41,\n",
       "  40,\n",
       "  34,\n",
       "  31,\n",
       "  37,\n",
       "  31,\n",
       "  36,\n",
       "  40,\n",
       "  40,\n",
       "  39,\n",
       "  43,\n",
       "  40,\n",
       "  41,\n",
       "  29,\n",
       "  33,\n",
       "  30,\n",
       "  32,\n",
       "  34,\n",
       "  41,\n",
       "  37,\n",
       "  38,\n",
       "  34,\n",
       "  37,\n",
       "  34,\n",
       "  31,\n",
       "  41,\n",
       "  34,\n",
       "  43,\n",
       "  38,\n",
       "  39,\n",
       "  32,\n",
       "  38,\n",
       "  34,\n",
       "  33,\n",
       "  41,\n",
       "  43,\n",
       "  36,\n",
       "  43,\n",
       "  43,\n",
       "  35,\n",
       "  39,\n",
       "  35,\n",
       "  35,\n",
       "  42,\n",
       "  38,\n",
       "  28,\n",
       "  31,\n",
       "  33,\n",
       "  38,\n",
       "  36,\n",
       "  37,\n",
       "  36,\n",
       "  33,\n",
       "  32,\n",
       "  42,\n",
       "  38,\n",
       "  41,\n",
       "  40,\n",
       "  42,\n",
       "  39,\n",
       "  35,\n",
       "  31,\n",
       "  31,\n",
       "  36,\n",
       "  35,\n",
       "  35,\n",
       "  42,\n",
       "  41,\n",
       "  27,\n",
       "  37,\n",
       "  40,\n",
       "  29,\n",
       "  33,\n",
       "  39,\n",
       "  33,\n",
       "  31,\n",
       "  40,\n",
       "  28,\n",
       "  ...],\n",
       " [11,\n",
       "  12,\n",
       "  10,\n",
       "  9,\n",
       "  13,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  13,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  13,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  8,\n",
       "  6,\n",
       "  9,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  9,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  8,\n",
       "  6,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  11,\n",
       "  1,\n",
       "  8,\n",
       "  13,\n",
       "  9,\n",
       "  13,\n",
       "  9,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  7,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  12,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  6,\n",
       "  10,\n",
       "  8,\n",
       "  12,\n",
       "  12,\n",
       "  10,\n",
       "  14,\n",
       "  11,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  12,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  8,\n",
       "  10,\n",
       "  7,\n",
       "  11,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  8,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  9,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  13,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  8,\n",
       "  7,\n",
       "  7,\n",
       "  9,\n",
       "  12,\n",
       "  11,\n",
       "  9,\n",
       "  13,\n",
       "  8,\n",
       "  8,\n",
       "  10,\n",
       "  12,\n",
       "  14,\n",
       "  8,\n",
       "  11,\n",
       "  9,\n",
       "  11,\n",
       "  10,\n",
       "  9,\n",
       "  11,\n",
       "  12,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  7,\n",
       "  9,\n",
       "  9,\n",
       "  15,\n",
       "  14,\n",
       "  10,\n",
       "  12,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  7,\n",
       "  9,\n",
       "  10,\n",
       "  7,\n",
       "  11,\n",
       "  8,\n",
       "  11,\n",
       "  12,\n",
       "  11,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  8,\n",
       "  8,\n",
       "  6,\n",
       "  8,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  12,\n",
       "  13,\n",
       "  11,\n",
       "  10,\n",
       "  14,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  6,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  8,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  8,\n",
       "  11,\n",
       "  12,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  13,\n",
       "  9,\n",
       "  13,\n",
       "  8,\n",
       "  12,\n",
       "  9,\n",
       "  10,\n",
       "  12,\n",
       "  8,\n",
       "  10,\n",
       "  7,\n",
       "  9,\n",
       "  7,\n",
       "  12,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  12,\n",
       "  10,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  12,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  5,\n",
       "  12,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  8,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  12,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  6,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  11,\n",
       "  11,\n",
       "  8,\n",
       "  9,\n",
       "  13,\n",
       "  12,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  9,\n",
       "  12,\n",
       "  9,\n",
       "  8,\n",
       "  12,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  8,\n",
       "  11,\n",
       "  8,\n",
       "  14,\n",
       "  10,\n",
       "  9,\n",
       "  13,\n",
       "  10,\n",
       "  9,\n",
       "  11,\n",
       "  10,\n",
       "  12,\n",
       "  10,\n",
       "  14,\n",
       "  10,\n",
       "  6,\n",
       "  11,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  15,\n",
       "  12,\n",
       "  11,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  12,\n",
       "  12,\n",
       "  10,\n",
       "  14,\n",
       "  9,\n",
       "  14,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  6,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  6,\n",
       "  10,\n",
       "  12,\n",
       "  12,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  8,\n",
       "  10,\n",
       "  12,\n",
       "  10,\n",
       "  7,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  13,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  8,\n",
       "  12,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  12,\n",
       "  8,\n",
       "  8,\n",
       "  7,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  12,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  6,\n",
       "  8,\n",
       "  11,\n",
       "  12,\n",
       "  6,\n",
       "  9,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  12,\n",
       "  12,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  6,\n",
       "  9,\n",
       "  12,\n",
       "  11,\n",
       "  13,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  13,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  12,\n",
       "  8,\n",
       "  11,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  13,\n",
       "  8,\n",
       "  12,\n",
       "  10,\n",
       "  11,\n",
       "  8,\n",
       "  9,\n",
       "  13,\n",
       "  10,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  9,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  13,\n",
       "  10,\n",
       "  12,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  13,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  11,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  13,\n",
       "  10,\n",
       "  12,\n",
       "  10,\n",
       "  9,\n",
       "  12,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  13,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  7,\n",
       "  6,\n",
       "  10,\n",
       "  7,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  14,\n",
       "  11,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  9,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  7,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  11,\n",
       "  7,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  7,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  8,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  9,\n",
       "  8,\n",
       "  13,\n",
       "  8,\n",
       "  11,\n",
       "  7,\n",
       "  9,\n",
       "  10,\n",
       "  14,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  8,\n",
       "  9,\n",
       "  13,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  10,\n",
       "  9,\n",
       "  7,\n",
       "  10,\n",
       "  9,\n",
       "  11,\n",
       "  8,\n",
       "  11,\n",
       "  8,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  7,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  8,\n",
       "  12,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  12,\n",
       "  7,\n",
       "  11,\n",
       "  12,\n",
       "  8,\n",
       "  10,\n",
       "  7,\n",
       "  9,\n",
       "  11,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  11,\n",
       "  8,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  7,\n",
       "  11,\n",
       "  3,\n",
       "  9,\n",
       "  12,\n",
       "  11,\n",
       "  9,\n",
       "  11,\n",
       "  7,\n",
       "  7,\n",
       "  11,\n",
       "  8,\n",
       "  13,\n",
       "  9,\n",
       "  12,\n",
       "  11,\n",
       "  8,\n",
       "  10,\n",
       "  8,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  7,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  7,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  6,\n",
       "  10,\n",
       "  7,\n",
       "  10,\n",
       "  12,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  13,\n",
       "  11,\n",
       "  11,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  12,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  7,\n",
       "  11,\n",
       "  8,\n",
       "  8,\n",
       "  12,\n",
       "  11,\n",
       "  9,\n",
       "  12,\n",
       "  11,\n",
       "  9,\n",
       "  13,\n",
       "  13,\n",
       "  8,\n",
       "  9,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  12,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  14,\n",
       "  8,\n",
       "  11,\n",
       "  9,\n",
       "  7,\n",
       "  11,\n",
       "  12,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  9,\n",
       "  7,\n",
       "  9,\n",
       "  8,\n",
       "  11,\n",
       "  8,\n",
       "  9,\n",
       "  8,\n",
       "  12,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  12,\n",
       "  10,\n",
       "  12,\n",
       "  13,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  13,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  7,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  13,\n",
       "  9,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  6,\n",
       "  10,\n",
       "  12,\n",
       "  9,\n",
       "  8,\n",
       "  7,\n",
       "  9,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  7,\n",
       "  7,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  13,\n",
       "  12,\n",
       "  8,\n",
       "  11,\n",
       "  13,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  7,\n",
       "  10,\n",
       "  13,\n",
       "  10,\n",
       "  7,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  11,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  7,\n",
       "  7,\n",
       "  9,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  11,\n",
       "  8,\n",
       "  13,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  7,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  13,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  6,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  7,\n",
       "  11,\n",
       "  10,\n",
       "  12,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  ...])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text_len, headlines_len í™•ì¸\n",
    "text_len, headlines_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cad5fba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98360"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "176f1af5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_113/3701299234.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_113/3701299234.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'str'"
     ]
    }
   ],
   "source": [
    "check_len = [len(s.str.split()) for s in data['text']]\n",
    "len(text_len), len(check_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad39577",
   "metadata": {},
   "source": [
    "- ì—¬ê¸°ì—ì„œ ì‚¬ìš©í•œê±´ **pythonì˜ split í•¨ìˆ˜**ë‹¤!\n",
    "- ë‹¤ì‹œ ì½”ë“œë¥¼ ì§„í–‰í•œë‹¤:)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f3ac103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    saurav kant alumnus upgrad iiit pg program mac...\n",
       "1    kunal shah credit card bill payment platform c...\n",
       "2    new zealand defeated india wickets fourth odi ...\n",
       "3    aegon life iterm insurance plan customers enjo...\n",
       "4    speaking sexual harassment allegations rajkuma...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë°ì´í„° í˜•íƒœ í™•ì¸\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e78bb6",
   "metadata": {},
   "source": [
    "- ê° rowì— ìˆëŠ” ë°ì´í„°ì˜ ê¸¸ì´ê°€ text_len, headlines_lenì— ë‹´ê²¨ìˆë‹¤.\n",
    "- ë…¸ë“œì—ì„œ ì§„í–‰í–ˆë˜ kaggleì˜ ë°ì´í„°ëŠ” ìƒ˜í”Œë³„ë¡œ ê¸¸ì´ ì°¨ì´ê°€ ì»¤ì„œ ìœ„ ê·¸ë˜í”„ ê²°ê³¼ë¥¼ ì°¸ê³ ë¡œ `max_len`ë¥¼ ì„¤ì •í•˜ê³  ì´ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì œì™¸ì‹œí‚¤ê³  ì •ìˆ˜ ì¸ì½”ë”©ì„ ì§„í–‰í–ˆë‹¤. ë”°ë¼ì„œ ì§„í–‰í•´ë³¸ë‹¤.<br>\n",
    "    (*ì‚¬ì‹¤ ì´ ê¸¸ì´ë¥¼ ì¡°ì •í•˜ëŠ” ì‘ì—…ì„ ì™œ í•˜ëŠ”ì§€ ì •í™•í•œ ì´í•´ê°€ ë¶€ì¡±í•œë° ì°¬ì°¬íˆ ì´í›„ NLPí”„ë¡œì íŠ¸ë„ ì§„í–‰í•˜ë©´ì„œ ê³µë¶€ë¥¼ ìŒ“ì•„ê°€ë³´ë ¤ê³ í•œë‹¤*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "312305dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max length\n",
    "text_max_len = 45       # text í‰ê· ê¸¸ì´: 35,ìµœëŒ€ê¸¸ì´: 60\n",
    "headlines_max_len = 15  # head í‰ê· ê¸¸ì´: 9, ìµœëŒ€ê¸¸ì´: 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae719b86",
   "metadata": {},
   "source": [
    "### `below_threshold_len` : max length ë¡œ ë°ì´í„° ëª‡ %ê°€ í•´ë‹¹í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cad3017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max length ë¡œ ë°ì´í„° ëª‡ %ê°€ í•´ë‹¹í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt=0\n",
    "    for s in nested_list:\n",
    "        if(len(s.split()) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    print('ì „ì²´ ìƒ˜í”Œ ì¤‘ ê¸¸ì´ê°€ %s ì´í•˜ì¸ ìƒ˜í”Œì˜ ë¹„ìœ¨: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83bd4ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ ìƒ˜í”Œ ì¤‘ ê¸¸ì´ê°€ 45 ì´í•˜ì¸ ìƒ˜í”Œì˜ ë¹„ìœ¨: 0.9967771451809678\n",
      "ì „ì²´ ìƒ˜í”Œ ì¤‘ ê¸¸ì´ê°€ 15 ì´í•˜ì¸ ìƒ˜í”Œì˜ ë¹„ìœ¨: 0.9999694997966653\n"
     ]
    }
   ],
   "source": [
    "# check percentage\n",
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len, data['headlines'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10960f8d",
   "metadata": {},
   "source": [
    "- max length ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° 99% ì´ìƒì´ í•´ë‹¹í•œë‹¤.\n",
    "- ì¶”ê°€ ì‘ì—…ì„ ì§„í–‰í•˜ì§€ ì•Šì•„ë„ ë ê²ƒ ê°™ì•„ì„œ max lengthë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì´ˆê³¼ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ëŠ” ë¶€ë¶„ì€ íŒ¨ìŠ¤í•´ë„ ë ê²ƒê°™ë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17edd5a8",
   "metadata": {},
   "source": [
    "## 5) Add SOS start token & EOS end token\n",
    "- decoderì— SOS, EOS token ì¶”ê°€\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### ğŸ’¡ Start token , End token\n",
    "<a href='https://arxiv.org/pdf/1812.02303.pdf'><img src='./img/seq2seq_token.png' width=40% height=40%></a>\n",
    "- í›ˆë ¨ë°ì´í„°ì˜ ì˜ˆì¸¡ ëŒ€ìƒ ì‹œí€€ìŠ¤ì˜ ì•, ë’¤ì—ëŠ” ì‹œì‘í† í°, ì¢…ë£Œ í† í°ì„ ë„£ì–´ì£¼ëŠ” ì „ì²˜ë¦¬ë¥¼ í†µí•´ ì–´ë””ì—ì„œ ë©ˆì¶°ì•¼í•˜ëŠ”ì§€ ì§€ì •í•´ì•¼í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce4125a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>sostoken delhi techie wins free food from swig...</td>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
       "      <td>sostoken have known hirani for yrs what if met...</td>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "4  have known hirani for yrs what if metoo claims...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "4  speaking sexual harassment allegations rajkuma...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "1  sostoken delhi techie wins free food from swig...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "4  sostoken have known hirani for yrs what if met...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "1  delhi techie wins free food from swiggy for on...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "4  have known hirani for yrs what if metoo claims...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add SOS, EOS at headlines data - ìƒˆë¡œìš´ ì—´ë¡œ ì¶”ê°€í•œë‹¤\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x: 'sostoken ' + x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x: x + ' eostoken')\n",
    "\n",
    "# check data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32655c6",
   "metadata": {},
   "source": [
    "# Step 3. Seperate data\n",
    "- numpy arrayë¡œ ë³€í™˜í•´ì„œ numpy slicing ê¸°ëŠ¥ ì‚¬ìš© [ì°¸ê³ -í…ìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬ë°©ë²•](https://wikidocs.net/33274)\n",
    "- train:testë¥¼ 8:2 ë¹„ìœ¨ë¡œ ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6d45653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98360,)\n",
      "(98360,)\n",
      "(98360,)\n"
     ]
    }
   ],
   "source": [
    "# change dataframe to numpy array \n",
    "encoder_input = np.array(data['text']) # input data of encoder\n",
    "decoder_input = np.array(data['decoder_input']) # input data of decoder\n",
    "decoder_target = np.array(data['decoder_target']) # label data of decoder\n",
    "\n",
    "# shape í™•ì¸\n",
    "print(encoder_input.shape)\n",
    "print(decoder_input.shape)\n",
    "print(decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "195d815b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32539 92635 71821 ... 62569 58637 40158]\n"
     ]
    }
   ],
   "source": [
    "# encoder_input ê³¼ 1)í¬ê¸°, í˜•íƒœê°€ ê°™ì€ , 2)ìˆœì„œê°€ ì„ì¸ ì •ìˆ˜ ì‹œí€€ìŠ¤ ìƒì„±\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23aa850c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers',\n",
       "        'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit',\n",
       "        'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history',\n",
       "        'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years'],\n",
       "       dtype=object),\n",
       " array(['sostoken upgrad learner switches to career in ml al with salary hike',\n",
       "        'sostoken delhi techie wins free food from swiggy for one year on cred',\n",
       "        'sostoken new zealand end rohit sharma led india match winning streak',\n",
       "        'sostoken aegon life iterm insurance plan helps customers save tax'],\n",
       "       dtype=object),\n",
       " array(['upgrad learner switches to career in ml al with salary hike eostoken',\n",
       "        'delhi techie wins free food from swiggy for one year on cred eostoken',\n",
       "        'new zealand end rohit sharma led india match winning streak eostoken',\n",
       "        'aegon life iterm insurance plan helps customers save tax eostoken'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì›ë˜ ë°ì´í„° í™•ì¸\n",
    "encoder_input[:4], decoder_input[:4], decoder_target[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6c7b5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n"
     ]
    }
   ],
   "source": [
    "# ìœ„ì˜ ì •ìˆ˜ ì‹œí€€ìŠ¤ë¥¼ ì´ìš©í•´ì„œ ë°ì´í„° ìƒ˜í”Œ ìˆœì„œë¥¼ ì •ì˜í•´ì¤Œ\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "print(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ef2e352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n"
     ]
    }
   ],
   "source": [
    "decoder_target = decoder_target[indices]\n",
    "print(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2490ce0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['us navy veteran sentenced life imprisonment killing indian engineer srinivas kuchibhotla hate crime kansas city bar february last year veteran also sentenced months imprisonment attempted murder two others heard shouting get country shooting kuchibhotla',\n",
       "        'many lakh teaching positions vacant government run schools across uttar pradesh rti query revealed state lakh teaching positions primary upper primary government schools lakh positions yet filled notably primary upper primary schools run state one teacher',\n",
       "        'customary inauguration letter former us president barack obama left successor donald trump revealed obama left four pieces advice trump letter urging trump sustain international order build ladders success hard working people obama advised trump protect democratic institutions traditions',\n",
       "        'bjp mla mithilesh kumar tiwari monday called congress president rahul gandhi rjd leader tejashwi yadav bunty babli remark purportedly refers movie bunty aur babli wherein abhishek bachchan rani mukerji played role fraudsters gandhi yadav recently seen together several occasions amidst opposition parties attempts forge alliance'],\n",
       "       dtype=object),\n",
       " array(['sostoken us navy veteran who murdered indian techie sentenced to life',\n",
       "        'sostoken lakh teaching positions vacant in up govt run schools',\n",
       "        'sostoken obama inauguration letter to trump revealed',\n",
       "        'sostoken bjp mla dubs rahul and tejashwi as bunty and babli'],\n",
       "       dtype=object),\n",
       " array(['us navy veteran who murdered indian techie sentenced to life eostoken',\n",
       "        'lakh teaching positions vacant in up govt run schools eostoken',\n",
       "        'obama inauguration letter to trump revealed eostoken',\n",
       "        'bjp mla dubs rahul and tejashwi as bunty and babli eostoken'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë°”ë€ ë°ì´í„° í™•ì¸\n",
    "encoder_input[:4], decoder_input[:4], decoder_target[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f689ff6a",
   "metadata": {},
   "source": [
    "- indexingì„ í•œë‹¤ê³  ìƒê°í•˜ë©´ ë ê²ƒê°™ë‹¤. í•´ë‹¹ ìˆœì„œì˜ indexë¥¼ ê°€ì§„ df ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ”ê±°ë¼ê³  ì´í•´í–ˆë‹¤.\n",
    "\n",
    "\n",
    "- ë§ì´ ì•ˆë˜ëŠ” ë‹¨ì–´ë“¤ì´ ê½¤ ë³´ì—¬ì„œ ì°¾ì•„ë´¤ë”ë‹ˆ ì•½ì–´í‘œí˜„ë“¤ì´ë‹¤\n",
    "    - `bjp`: The Bharatiya Janata Party is a political party in India\n",
    "    - `mla`, `dubs` ..\n",
    "    - [ì¸ë„ ì •ì¹˜ ê´€ë ¨ ë‰´ìŠ¤](https://indianexpress.com/article/political-pulse/bjp-dubs-arrest-1992-riot-case-karnataka-witch-hunt-against-hindus-links-ram-temple-event-9092233/)ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë‹¨ì–´ì´ë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b466e2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of test data: 19672\n"
     ]
    }
   ],
   "source": [
    "# [ì „ì²´ ë°ì´í„° í¬ê¸° * 0.2]ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸° ì •ì˜ (20%)\n",
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('# of test data:', n_of_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9279db",
   "metadata": {},
   "source": [
    "- ì „ì²´ ë°ì´í„°ì˜ 20%ì¸ **19672ê°œ**ê°€ test ë°ì´í„° ê°œìˆ˜ê°€ ëœë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "104f236d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í›ˆë ¨ ë°ì´í„°ì˜ ê°œìˆ˜ : 78688\n",
      "í›ˆë ¨ ë ˆì´ë¸”ì˜ ê°œìˆ˜ : 78688\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ê°œìˆ˜ : 19672\n",
      "í…ŒìŠ¤íŠ¸ ë ˆì´ë¸”ì˜ ê°œìˆ˜ : 19672\n"
     ]
    }
   ],
   "source": [
    "# separate data\n",
    "\n",
    "# ê±°ê¾¸ë¡œ indexing\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('í›ˆë ¨ ë°ì´í„°ì˜ ê°œìˆ˜ :', len(encoder_input_train))\n",
    "print('í›ˆë ¨ ë ˆì´ë¸”ì˜ ê°œìˆ˜ :', len(decoder_input_train))\n",
    "print('í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ê°œìˆ˜ :', len(encoder_input_test))\n",
    "print('í…ŒìŠ¤íŠ¸ ë ˆì´ë¸”ì˜ ê°œìˆ˜ :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc39434",
   "metadata": {},
   "source": [
    "# Step 4. ë‹¨ì–´ ì§‘í•©(vocabulary)ë§Œë“¤ê¸° & ì •ìˆ˜ ì¸ì½”ë”©\n",
    "\n",
    "- ë°ì´í„°ì˜ ë‹¨ì–´ë¥¼ ëª¨ë‘ 'ì •ìˆ˜'ë¡œ ë°”ê¿”ì•¼ ì»´í“¨í„°ê°€ ì¸ì‹í• ìˆ˜ ìˆë‹¤\n",
    "- **ê° ë‹¨ì–´ì— ê³ ìœ í•œ ì •ìˆ˜**ë¥¼ ë§¤í•‘ => `ë‹¨ì–´ ì§‘í•©(vocabulary)`ì„ ë§Œë“œëŠ” ê³¼ì •\n",
    "\n",
    "**[ì°¸ê³ ]**\n",
    "- [ìœ„í‚¤ë…ìŠ¤](https://wikidocs.net/31766)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1a5d8b",
   "metadata": {},
   "source": [
    "## 1) ë‹¨ì–´ì§‘í•© vocabulary ìƒì„±\n",
    "- kerasì˜ `tokenizer` ì‚¬ìš©\n",
    "\n",
    "\n",
    "**[ì°¸ê³ ]**\n",
    "- [keras doc](https://keras.io/api/keras_nlp/tokenizers/tokenizer/)\n",
    "- [ìœ„í‚¤ë…ìŠ¤](https://wikidocs.net/182469)\n",
    "\n",
    "### text data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6318db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make vocabulary with keras tokenizer\n",
    "src_tokenizer = Tokenizer()\n",
    "\n",
    "# encoder input train -> vocab\n",
    "src_tokenizer.fit_on_texts(encoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4791d4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Tokenizer in module keras_preprocessing.text object:\n",
      "\n",
      "class Tokenizer(builtins.object)\n",
      " |  Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0, **kwargs)\n",
      " |  \n",
      " |  Text tokenization utility class.\n",
      " |  \n",
      " |  This class allows to vectorize a text corpus, by turning each\n",
      " |  text into either a sequence of integers (each integer being the index\n",
      " |  of a token in a dictionary) or into a vector where the coefficient\n",
      " |  for each token could be binary, based on word count, based on tf-idf...\n",
      " |  \n",
      " |  # Arguments\n",
      " |      num_words: the maximum number of words to keep, based\n",
      " |          on word frequency. Only the most common `num_words-1` words will\n",
      " |          be kept.\n",
      " |      filters: a string where each element is a character that will be\n",
      " |          filtered from the texts. The default is all punctuation, plus\n",
      " |          tabs and line breaks, minus the `'` character.\n",
      " |      lower: boolean. Whether to convert the texts to lowercase.\n",
      " |      split: str. Separator for word splitting.\n",
      " |      char_level: if True, every character will be treated as a token.\n",
      " |      oov_token: if given, it will be added to word_index and used to\n",
      " |          replace out-of-vocabulary words during text_to_sequence calls\n",
      " |  \n",
      " |  By default, all punctuation is removed, turning the texts into\n",
      " |  space-separated sequences of words\n",
      " |  (words maybe include the `'` character). These sequences are then\n",
      " |  split into lists of tokens. They will then be indexed or vectorized.\n",
      " |  \n",
      " |  `0` is a reserved index that won't be assigned to any word.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit_on_sequences(self, sequences)\n",
      " |      Updates internal vocabulary based on a list of sequences.\n",
      " |      \n",
      " |      Required before using `sequences_to_matrix`\n",
      " |      (if `fit_on_texts` was never called).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequence.\n",
      " |              A \"sequence\" is a list of integer word indices.\n",
      " |  \n",
      " |  fit_on_texts(self, texts)\n",
      " |      Updates internal vocabulary based on a list of texts.\n",
      " |      \n",
      " |      In the case where texts contains lists,\n",
      " |      we assume each entry of the lists to be a token.\n",
      " |      \n",
      " |      Required before using `texts_to_sequences` or `texts_to_matrix`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: can be a list of strings,\n",
      " |              a generator of strings (for memory-efficiency),\n",
      " |              or a list of list of strings.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the tokenizer configuration as Python dictionary.\n",
      " |      The word count dictionaries used by the tokenizer get serialized\n",
      " |      into plain JSON, so that the configuration can be read by other\n",
      " |      projects.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Python dictionary with the tokenizer configuration.\n",
      " |  \n",
      " |  sequences_to_matrix(self, sequences, mode='binary')\n",
      " |      Converts a list of sequences into a Numpy matrix.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: list of sequences\n",
      " |              (a sequence is a list of integer word indices).\n",
      " |          mode: one of \"binary\", \"count\", \"tfidf\", \"freq\"\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Numpy matrix.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid `mode` argument,\n",
      " |              or if the Tokenizer requires to be fit to sample data.\n",
      " |  \n",
      " |  sequences_to_texts(self, sequences)\n",
      " |      Transforms each sequence into a list of text.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequences (list of integers).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of texts (strings)\n",
      " |  \n",
      " |  sequences_to_texts_generator(self, sequences)\n",
      " |      Transforms each sequence in `sequences` to a list of texts(strings).\n",
      " |      \n",
      " |      Each sequence has to a list of integers.\n",
      " |      In other words, sequences should be a list of sequences\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequences.\n",
      " |      \n",
      " |      # Yields\n",
      " |          Yields individual texts.\n",
      " |  \n",
      " |  texts_to_matrix(self, texts, mode='binary')\n",
      " |      Convert a list of texts to a Numpy matrix.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: list of strings.\n",
      " |          mode: one of \"binary\", \"count\", \"tfidf\", \"freq\".\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Numpy matrix.\n",
      " |  \n",
      " |  texts_to_sequences(self, texts)\n",
      " |      Transforms each text in texts to a sequence of integers.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: A list of texts (strings).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of sequences.\n",
      " |  \n",
      " |  texts_to_sequences_generator(self, texts)\n",
      " |      Transforms each text in `texts` to a sequence of integers.\n",
      " |      \n",
      " |      Each item in texts can also be a list,\n",
      " |      in which case we assume each item of that list to be a token.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: A list of texts (strings).\n",
      " |      \n",
      " |      # Yields\n",
      " |          Yields individual sequences.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the tokenizer configuration.\n",
      " |      To load a tokenizer from a JSON string, use\n",
      " |      `keras.preprocessing.text.tokenizer_from_json(json_string)`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A JSON string containing the tokenizer configuration.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check data vocab\n",
    "help(src_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00be6ef",
   "metadata": {},
   "source": [
    "- ì¶œë ¥í•´ì„œ ë³´ë ¤ê³ í–ˆëŠ”ë° ì‰½ì§€ ì•Šë‹¤. ì¼ë‹¨ ë…¸ë“œë¥¼ ë§ˆì¹œí›„ì— ì¶”ê°€ê³µë¶€ë¥¼ í•´ë´ì•¼ê² ë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c782353",
   "metadata": {},
   "source": [
    "- ìƒì„±ëœ vocabularyëŠ” `src_tokenizer.word_index`ì— ì €ì¥ë˜ì–´ ìˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90be611c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'said': 1,\n",
       " 'india': 2,\n",
       " 'year': 3,\n",
       " 'added': 4,\n",
       " 'us': 5,\n",
       " 'also': 6,\n",
       " 'first': 7,\n",
       " 'government': 8,\n",
       " 'police': 9,\n",
       " 'people': 10,\n",
       " 'indian': 11,\n",
       " 'two': 12,\n",
       " 'old': 13,\n",
       " 'minister': 14,\n",
       " 'film': 15,\n",
       " 'president': 16,\n",
       " 'one': 17,\n",
       " 'world': 18,\n",
       " 'crore': 19,\n",
       " 'court': 20,\n",
       " 'state': 21,\n",
       " 'would': 22,\n",
       " 'reportedly': 23,\n",
       " 'years': 24,\n",
       " 'new': 25,\n",
       " 'time': 26,\n",
       " 'former': 27,\n",
       " 'delhi': 28,\n",
       " 'last': 29,\n",
       " 'three': 30,\n",
       " 'reports': 31,\n",
       " 'company': 32,\n",
       " 'like': 33,\n",
       " 'based': 34,\n",
       " 'earlier': 35,\n",
       " 'congress': 36,\n",
       " 'man': 37,\n",
       " 'bjp': 38,\n",
       " 'country': 39,\n",
       " 'team': 40,\n",
       " 'trump': 41,\n",
       " 'claimed': 42,\n",
       " 'day': 43,\n",
       " 'modi': 44,\n",
       " 'chief': 45,\n",
       " 'pakistan': 46,\n",
       " 'accused': 47,\n",
       " 'singh': 48,\n",
       " 'pm': 49,\n",
       " 'actor': 50,\n",
       " 'women': 51,\n",
       " 'million': 52,\n",
       " 'according': 53,\n",
       " 'allegedly': 54,\n",
       " 'made': 55,\n",
       " 'friday': 56,\n",
       " 'wednesday': 57,\n",
       " 'pradesh': 58,\n",
       " 'tuesday': 59,\n",
       " 'party': 60,\n",
       " 'comes': 61,\n",
       " 'monday': 62,\n",
       " 'lakh': 63,\n",
       " 'called': 64,\n",
       " 'woman': 65,\n",
       " 'video': 66,\n",
       " 'around': 67,\n",
       " 'asked': 68,\n",
       " 'billion': 69,\n",
       " 'thursday': 70,\n",
       " 'khan': 71,\n",
       " 'tweeted': 72,\n",
       " 'including': 73,\n",
       " 'took': 74,\n",
       " 'test': 75,\n",
       " 'cm': 76,\n",
       " 'mumbai': 77,\n",
       " 'case': 78,\n",
       " 'actress': 79,\n",
       " 'found': 80,\n",
       " 'revealed': 81,\n",
       " 'national': 82,\n",
       " 'could': 83,\n",
       " 'saturday': 84,\n",
       " 'four': 85,\n",
       " 'five': 86,\n",
       " 'sunday': 87,\n",
       " 'officials': 88,\n",
       " 'leader': 89,\n",
       " 'second': 90,\n",
       " 'arrested': 91,\n",
       " 'match': 92,\n",
       " 'wrote': 93,\n",
       " 'announced': 94,\n",
       " 'high': 95,\n",
       " 'following': 96,\n",
       " 'group': 97,\n",
       " 'used': 98,\n",
       " 'captain': 99,\n",
       " 'however': 100,\n",
       " 'china': 101,\n",
       " 'since': 102,\n",
       " 'startup': 103,\n",
       " 'take': 104,\n",
       " 'notably': 105,\n",
       " 'cricket': 106,\n",
       " 'users': 107,\n",
       " 'alleged': 108,\n",
       " 'part': 109,\n",
       " 'media': 110,\n",
       " 'due': 111,\n",
       " 'narendra': 112,\n",
       " 'killed': 113,\n",
       " 'family': 114,\n",
       " 'may': 115,\n",
       " 'bank': 116,\n",
       " 'get': 117,\n",
       " 'international': 118,\n",
       " 'make': 119,\n",
       " 'th': 120,\n",
       " 'ceo': 121,\n",
       " 'led': 122,\n",
       " 'adding': 123,\n",
       " 'per': 124,\n",
       " 'donald': 125,\n",
       " 'days': 126,\n",
       " 'security': 127,\n",
       " 'air': 128,\n",
       " 'gandhi': 129,\n",
       " 'twitter': 130,\n",
       " 'set': 131,\n",
       " 'six': 132,\n",
       " 'month': 133,\n",
       " 'facebook': 134,\n",
       " 'home': 135,\n",
       " 'south': 136,\n",
       " 'life': 137,\n",
       " 'house': 138,\n",
       " 'work': 139,\n",
       " 'saying': 140,\n",
       " 'series': 141,\n",
       " 'kapoor': 142,\n",
       " 'picture': 143,\n",
       " 'data': 144,\n",
       " 'number': 145,\n",
       " 'help': 146,\n",
       " 'incident': 147,\n",
       " 'report': 148,\n",
       " 'another': 149,\n",
       " 'north': 150,\n",
       " 'prime': 151,\n",
       " 'official': 152,\n",
       " 'using': 153,\n",
       " 'several': 154,\n",
       " 'social': 155,\n",
       " 'car': 156,\n",
       " 'wife': 157,\n",
       " 'girl': 158,\n",
       " 'later': 159,\n",
       " 'uttar': 160,\n",
       " 'post': 161,\n",
       " 'seen': 162,\n",
       " 'back': 163,\n",
       " 'board': 164,\n",
       " 'australia': 165,\n",
       " 'released': 166,\n",
       " 'show': 167,\n",
       " 'public': 168,\n",
       " 'kumar': 169,\n",
       " 'next': 170,\n",
       " 'least': 171,\n",
       " 'talking': 172,\n",
       " 'supreme': 173,\n",
       " 'week': 174,\n",
       " 'city': 175,\n",
       " 'hospital': 176,\n",
       " 'students': 177,\n",
       " 'rahul': 178,\n",
       " 'upcoming': 179,\n",
       " 'google': 180,\n",
       " 'elections': 181,\n",
       " 'among': 182,\n",
       " 'become': 183,\n",
       " 'recently': 184,\n",
       " 'launched': 185,\n",
       " 'death': 186,\n",
       " 'money': 187,\n",
       " 'user': 188,\n",
       " 'union': 189,\n",
       " 'third': 190,\n",
       " 'school': 191,\n",
       " 'nearly': 192,\n",
       " 'got': 193,\n",
       " 'filed': 194,\n",
       " 'without': 195,\n",
       " 'months': 196,\n",
       " 'kohli': 197,\n",
       " 'children': 198,\n",
       " 'son': 199,\n",
       " 'cup': 200,\n",
       " 'men': 201,\n",
       " 'technology': 202,\n",
       " 'taken': 203,\n",
       " 'even': 204,\n",
       " 'shared': 205,\n",
       " 'many': 206,\n",
       " 'centre': 207,\n",
       " 'record': 208,\n",
       " 'attack': 209,\n",
       " 'times': 210,\n",
       " 'uk': 211,\n",
       " 'run': 212,\n",
       " 'away': 213,\n",
       " 'co': 214,\n",
       " 'director': 215,\n",
       " 'worth': 216,\n",
       " 'ever': 217,\n",
       " 'named': 218,\n",
       " 'others': 219,\n",
       " 'online': 220,\n",
       " 'win': 221,\n",
       " 'hit': 222,\n",
       " 'father': 223,\n",
       " 'held': 224,\n",
       " 'ministry': 225,\n",
       " 'release': 226,\n",
       " 'district': 227,\n",
       " 'researchers': 228,\n",
       " 'deal': 229,\n",
       " 'law': 230,\n",
       " 'place': 231,\n",
       " 'use': 232,\n",
       " 'sharma': 233,\n",
       " 'shah': 234,\n",
       " 'making': 235,\n",
       " 'came': 236,\n",
       " 'cannot': 237,\n",
       " 'korea': 238,\n",
       " 'across': 239,\n",
       " 'england': 240,\n",
       " 'long': 241,\n",
       " 'final': 242,\n",
       " 'founder': 243,\n",
       " 'order': 244,\n",
       " 'given': 245,\n",
       " 'body': 246,\n",
       " 'reported': 247,\n",
       " 'died': 248,\n",
       " 'system': 249,\n",
       " 'told': 250,\n",
       " 'directed': 251,\n",
       " 'open': 252,\n",
       " 'water': 253,\n",
       " 'capital': 254,\n",
       " 'received': 255,\n",
       " 'general': 256,\n",
       " 'army': 257,\n",
       " 'every': 258,\n",
       " 'best': 259,\n",
       " 'working': 260,\n",
       " 'event': 261,\n",
       " 'taking': 262,\n",
       " 'flight': 263,\n",
       " 'american': 264,\n",
       " 'chinese': 265,\n",
       " 'daughter': 266,\n",
       " 'way': 267,\n",
       " 'started': 268,\n",
       " 'along': 269,\n",
       " 'pay': 270,\n",
       " 'members': 271,\n",
       " 'come': 272,\n",
       " 'hours': 273,\n",
       " 'karnataka': 274,\n",
       " 'want': 275,\n",
       " 'department': 276,\n",
       " 'lost': 277,\n",
       " 'top': 278,\n",
       " 'person': 279,\n",
       " 'assembly': 280,\n",
       " 'tax': 281,\n",
       " 'left': 282,\n",
       " 'mother': 283,\n",
       " 'united': 284,\n",
       " 'play': 285,\n",
       " 'app': 286,\n",
       " 'go': 287,\n",
       " 'firm': 288,\n",
       " 'fire': 289,\n",
       " 'space': 290,\n",
       " 'raised': 291,\n",
       " 'never': 292,\n",
       " 'seven': 293,\n",
       " 'runs': 294,\n",
       " 'today': 295,\n",
       " 'decision': 296,\n",
       " 'apple': 297,\n",
       " 'kashmir': 298,\n",
       " 'university': 299,\n",
       " 'services': 300,\n",
       " 'name': 301,\n",
       " 'cricketer': 302,\n",
       " 'went': 303,\n",
       " 'odi': 304,\n",
       " 'within': 305,\n",
       " 'became': 306,\n",
       " 'human': 307,\n",
       " 'highest': 308,\n",
       " 'service': 309,\n",
       " 'right': 310,\n",
       " 'injured': 311,\n",
       " 'largest': 312,\n",
       " 'good': 313,\n",
       " 'star': 314,\n",
       " 'end': 315,\n",
       " 'australian': 316,\n",
       " 'well': 317,\n",
       " 'officer': 318,\n",
       " 'airport': 319,\n",
       " 'employees': 320,\n",
       " 'power': 321,\n",
       " 'authorities': 322,\n",
       " 'read': 323,\n",
       " 'speaking': 324,\n",
       " 'issued': 325,\n",
       " 'player': 326,\n",
       " 'chairman': 327,\n",
       " 'action': 328,\n",
       " 'food': 329,\n",
       " 'gold': 330,\n",
       " 'playing': 331,\n",
       " 'countries': 332,\n",
       " 'states': 333,\n",
       " 'films': 334,\n",
       " 'bengaluru': 335,\n",
       " 'kerala': 336,\n",
       " 'league': 337,\n",
       " 'maharashtra': 338,\n",
       " 'business': 339,\n",
       " 'known': 340,\n",
       " 'sexual': 341,\n",
       " 'total': 342,\n",
       " 'ram': 343,\n",
       " 'companies': 344,\n",
       " 'give': 345,\n",
       " 'russia': 346,\n",
       " 'december': 347,\n",
       " 'round': 348,\n",
       " 'meeting': 349,\n",
       " 'meanwhile': 350,\n",
       " 'posted': 351,\n",
       " 'gujarat': 352,\n",
       " 'eight': 353,\n",
       " 'office': 354,\n",
       " 'foreign': 355,\n",
       " 'march': 356,\n",
       " 'central': 357,\n",
       " 'russian': 358,\n",
       " 'move': 359,\n",
       " 'information': 360,\n",
       " 'slammed': 361,\n",
       " 'private': 362,\n",
       " 'currently': 363,\n",
       " 'support': 364,\n",
       " 'face': 365,\n",
       " 'virat': 366,\n",
       " 'free': 367,\n",
       " 'sent': 368,\n",
       " 'role': 369,\n",
       " 'share': 370,\n",
       " 'special': 371,\n",
       " 'tweet': 372,\n",
       " 'near': 373,\n",
       " 'june': 374,\n",
       " 'election': 375,\n",
       " 'cases': 376,\n",
       " 'head': 377,\n",
       " 'going': 378,\n",
       " 'child': 379,\n",
       " 'visit': 380,\n",
       " 'amid': 381,\n",
       " 'ahead': 382,\n",
       " 'salman': 383,\n",
       " 'issue': 384,\n",
       " 'list': 385,\n",
       " 'ball': 386,\n",
       " 'tamil': 387,\n",
       " 'registered': 388,\n",
       " 'think': 389,\n",
       " 'instagram': 390,\n",
       " 'passengers': 391,\n",
       " 'claiming': 392,\n",
       " 'un': 393,\n",
       " 'non': 394,\n",
       " 'ban': 395,\n",
       " 'song': 396,\n",
       " 'april': 397,\n",
       " 'statement': 398,\n",
       " 'market': 399,\n",
       " 'scored': 400,\n",
       " 'war': 401,\n",
       " 'love': 402,\n",
       " 'husband': 403,\n",
       " 'scheduled': 404,\n",
       " 'need': 405,\n",
       " 'investigation': 406,\n",
       " 'ipl': 407,\n",
       " 'sabha': 408,\n",
       " 'boy': 409,\n",
       " 'commission': 410,\n",
       " 'ago': 411,\n",
       " 'know': 412,\n",
       " 'september': 413,\n",
       " 'played': 414,\n",
       " 'january': 415,\n",
       " 'ex': 416,\n",
       " 'west': 417,\n",
       " 'real': 418,\n",
       " 'much': 419,\n",
       " 'bihar': 420,\n",
       " 'secretary': 421,\n",
       " 'class': 422,\n",
       " 'nuclear': 423,\n",
       " 'health': 424,\n",
       " 'global': 425,\n",
       " 'uber': 426,\n",
       " 'senior': 427,\n",
       " 'anti': 428,\n",
       " 'funding': 429,\n",
       " 'august': 430,\n",
       " 'shows': 431,\n",
       " 'shot': 432,\n",
       " 'development': 433,\n",
       " 'singer': 434,\n",
       " 'passed': 435,\n",
       " 'punjab': 436,\n",
       " 'defence': 437,\n",
       " 'leaders': 438,\n",
       " 'military': 439,\n",
       " 'train': 440,\n",
       " 'platform': 441,\n",
       " 'sri': 442,\n",
       " 'finance': 443,\n",
       " 'news': 444,\n",
       " 'inside': 445,\n",
       " 'see': 446,\n",
       " 'put': 447,\n",
       " 'age': 448,\n",
       " 'wedding': 449,\n",
       " 'political': 450,\n",
       " 'major': 451,\n",
       " 'area': 452,\n",
       " 'late': 453,\n",
       " 'student': 454,\n",
       " 'pakistani': 455,\n",
       " 'dead': 456,\n",
       " 'recent': 457,\n",
       " 'players': 458,\n",
       " 'station': 459,\n",
       " 'feature': 460,\n",
       " 'project': 461,\n",
       " 'launch': 462,\n",
       " 'act': 463,\n",
       " 'failed': 464,\n",
       " 'yadav': 465,\n",
       " 'allegations': 466,\n",
       " 'member': 467,\n",
       " 'trying': 468,\n",
       " 'rape': 469,\n",
       " 'force': 470,\n",
       " 'dhoni': 471,\n",
       " 'suicide': 472,\n",
       " 'bollywood': 473,\n",
       " 'still': 474,\n",
       " 'ordered': 475,\n",
       " 'different': 476,\n",
       " 'towards': 477,\n",
       " 'cbi': 478,\n",
       " 'couple': 479,\n",
       " 'july': 480,\n",
       " 'game': 481,\n",
       " 'november': 482,\n",
       " 'mp': 483,\n",
       " 'expected': 484,\n",
       " 'bill': 485,\n",
       " 'getting': 486,\n",
       " 'award': 487,\n",
       " 'financial': 488,\n",
       " 'female': 489,\n",
       " 'claims': 490,\n",
       " 'lead': 491,\n",
       " 'giant': 492,\n",
       " 'complaint': 493,\n",
       " 'denied': 494,\n",
       " 'amazon': 495,\n",
       " 'birthday': 496,\n",
       " 'side': 497,\n",
       " 'wanted': 498,\n",
       " 'decided': 499,\n",
       " 'fake': 500,\n",
       " 'medical': 501,\n",
       " 'batsman': 502,\n",
       " 'agency': 503,\n",
       " 'jail': 504,\n",
       " 'allowed': 505,\n",
       " 'october': 506,\n",
       " 'stated': 507,\n",
       " 'road': 508,\n",
       " 'local': 509,\n",
       " 'plans': 510,\n",
       " 'sachin': 511,\n",
       " 'stop': 512,\n",
       " 'korean': 513,\n",
       " 'study': 514,\n",
       " 'phone': 515,\n",
       " 'paid': 516,\n",
       " 'together': 517,\n",
       " 'past': 518,\n",
       " 'campaign': 519,\n",
       " 'minutes': 520,\n",
       " 'change': 521,\n",
       " 'earth': 522,\n",
       " 'british': 523,\n",
       " 'reacting': 524,\n",
       " 'building': 525,\n",
       " 'forces': 526,\n",
       " 'calling': 527,\n",
       " 'white': 528,\n",
       " 'history': 529,\n",
       " 'rajasthan': 530,\n",
       " 'married': 531,\n",
       " 'founded': 532,\n",
       " 'workers': 533,\n",
       " 'driver': 534,\n",
       " 'jammu': 535,\n",
       " 'nadu': 536,\n",
       " 'priyanka': 537,\n",
       " 'iran': 538,\n",
       " 'vice': 539,\n",
       " 'rights': 540,\n",
       " 'mark': 541,\n",
       " 'scientists': 542,\n",
       " 'victim': 543,\n",
       " 'outside': 544,\n",
       " 'look': 545,\n",
       " 'games': 546,\n",
       " 'temple': 547,\n",
       " 'despite': 548,\n",
       " 'control': 549,\n",
       " 'musk': 550,\n",
       " 'committee': 551,\n",
       " 'railway': 552,\n",
       " 'account': 553,\n",
       " 'quarter': 554,\n",
       " 'ali': 555,\n",
       " 'saudi': 556,\n",
       " 'debut': 557,\n",
       " 'winning': 558,\n",
       " 'football': 559,\n",
       " 'nation': 560,\n",
       " 'parents': 561,\n",
       " 'till': 562,\n",
       " 'great': 563,\n",
       " 'always': 564,\n",
       " 'big': 565,\n",
       " 'gst': 566,\n",
       " 'half': 567,\n",
       " 'starrer': 568,\n",
       " 'refused': 569,\n",
       " 'coach': 570,\n",
       " 'seeking': 571,\n",
       " 'live': 572,\n",
       " 'cost': 573,\n",
       " 'madhya': 574,\n",
       " 'planning': 575,\n",
       " 'letter': 576,\n",
       " 'sharing': 577,\n",
       " 'single': 578,\n",
       " 'pictures': 579,\n",
       " 'nasa': 580,\n",
       " 'behind': 581,\n",
       " 'instead': 582,\n",
       " 'matches': 583,\n",
       " 'call': 584,\n",
       " 'nine': 585,\n",
       " 'banned': 586,\n",
       " 'haryana': 587,\n",
       " 'provide': 588,\n",
       " 'affairs': 589,\n",
       " 'fell': 590,\n",
       " 'night': 591,\n",
       " 'africa': 592,\n",
       " 'violence': 593,\n",
       " 'london': 594,\n",
       " 'filmmaker': 595,\n",
       " 'black': 596,\n",
       " 'met': 597,\n",
       " 'border': 598,\n",
       " 'mobile': 599,\n",
       " 'french': 600,\n",
       " 'fourth': 601,\n",
       " 'muslim': 602,\n",
       " 'developed': 603,\n",
       " 'tesla': 604,\n",
       " 'light': 605,\n",
       " 'leave': 606,\n",
       " 'declared': 607,\n",
       " 'career': 608,\n",
       " 'cash': 609,\n",
       " 'amount': 610,\n",
       " 'protest': 611,\n",
       " 'previous': 612,\n",
       " 'biggest': 613,\n",
       " 'bachchan': 614,\n",
       " 'gave': 615,\n",
       " 'aircraft': 616,\n",
       " 'justice': 617,\n",
       " 'murder': 618,\n",
       " 'start': 619,\n",
       " 'fund': 620,\n",
       " 'season': 621,\n",
       " 'better': 622,\n",
       " 'charges': 623,\n",
       " 'offered': 624,\n",
       " 'parliament': 625,\n",
       " 'brother': 626,\n",
       " 'turned': 627,\n",
       " 'personal': 628,\n",
       " 'probe': 629,\n",
       " 'yet': 630,\n",
       " 'loss': 631,\n",
       " 'intelligence': 632,\n",
       " 'matter': 633,\n",
       " 'harassment': 634,\n",
       " 'investors': 635,\n",
       " 'say': 636,\n",
       " 'self': 637,\n",
       " 'club': 638,\n",
       " 'lok': 639,\n",
       " 'model': 640,\n",
       " 'innings': 641,\n",
       " 'suspended': 642,\n",
       " 'staff': 643,\n",
       " 'tournament': 644,\n",
       " 'written': 645,\n",
       " 'must': 646,\n",
       " 'far': 647,\n",
       " 'tried': 648,\n",
       " 'hotel': 649,\n",
       " 'bengal': 650,\n",
       " 'land': 651,\n",
       " 'showed': 652,\n",
       " 'industry': 653,\n",
       " 'level': 654,\n",
       " 'hyderabad': 655,\n",
       " 'already': 656,\n",
       " 'let': 657,\n",
       " 'happy': 658,\n",
       " 'km': 659,\n",
       " 'stating': 660,\n",
       " 'confirmed': 661,\n",
       " 'aadhaar': 662,\n",
       " 'rukh': 663,\n",
       " 'education': 664,\n",
       " 'sale': 665,\n",
       " 'february': 666,\n",
       " 'cut': 667,\n",
       " 'admitted': 668,\n",
       " 'indians': 669,\n",
       " 'current': 670,\n",
       " 'price': 671,\n",
       " 'spokesperson': 672,\n",
       " 'opposition': 673,\n",
       " 'champions': 674,\n",
       " 'flipkart': 675,\n",
       " 'character': 676,\n",
       " 'banks': 677,\n",
       " 'customers': 678,\n",
       " 'issues': 679,\n",
       " 'nations': 680,\n",
       " 'chopra': 681,\n",
       " 'caused': 682,\n",
       " 'done': 683,\n",
       " 'vehicles': 684,\n",
       " 'return': 685,\n",
       " 'owned': 686,\n",
       " 'create': 687,\n",
       " 'baby': 688,\n",
       " 'meet': 689,\n",
       " 'driving': 690,\n",
       " 'japan': 691,\n",
       " 'shares': 692,\n",
       " 'able': 693,\n",
       " 'wearing': 694,\n",
       " 'farmers': 695,\n",
       " 'created': 696,\n",
       " 'photo': 697,\n",
       " 'gone': 698,\n",
       " 'include': 699,\n",
       " 'operations': 700,\n",
       " 'tv': 701,\n",
       " 'period': 702,\n",
       " 'fight': 703,\n",
       " 'keep': 704,\n",
       " 'policy': 705,\n",
       " 'carrying': 706,\n",
       " 'stake': 707,\n",
       " 'allow': 708,\n",
       " 'forced': 709,\n",
       " 'proposed': 710,\n",
       " 'demanded': 711,\n",
       " 'village': 712,\n",
       " 'officers': 713,\n",
       " 'afghanistan': 714,\n",
       " 'commerce': 715,\n",
       " 'appointed': 716,\n",
       " 'reach': 717,\n",
       " 'full': 718,\n",
       " 'girls': 719,\n",
       " 'vehicle': 720,\n",
       " 'hand': 721,\n",
       " 'treatment': 722,\n",
       " 'income': 723,\n",
       " 'organisation': 724,\n",
       " 'job': 725,\n",
       " 'things': 726,\n",
       " 'adityanath': 727,\n",
       " 'missing': 728,\n",
       " 'accounts': 729,\n",
       " 'term': 730,\n",
       " 'increase': 731,\n",
       " 'rbi': 732,\n",
       " 'lot': 733,\n",
       " 'trade': 734,\n",
       " 'reliance': 735,\n",
       " 'suggested': 736,\n",
       " 'economic': 737,\n",
       " 'room': 738,\n",
       " 'wickets': 739,\n",
       " 'response': 740,\n",
       " 'passenger': 741,\n",
       " 'investment': 742,\n",
       " 'process': 743,\n",
       " 'mla': 744,\n",
       " 'defeated': 745,\n",
       " 'showing': 746,\n",
       " 'sold': 747,\n",
       " 'reached': 748,\n",
       " 'oil': 749,\n",
       " 'continue': 750,\n",
       " 'warned': 751,\n",
       " 'plan': 752,\n",
       " 'attacks': 753,\n",
       " 'illegal': 754,\n",
       " 'ongoing': 755,\n",
       " 'talks': 756,\n",
       " 'broke': 757,\n",
       " 'hindu': 758,\n",
       " 'yogi': 759,\n",
       " 'region': 760,\n",
       " 'various': 761,\n",
       " 'feel': 762,\n",
       " 'less': 763,\n",
       " 'form': 764,\n",
       " 'find': 765,\n",
       " 'governor': 766,\n",
       " 'lanka': 767,\n",
       " 'score': 768,\n",
       " 'involved': 769,\n",
       " 'features': 770,\n",
       " 'sought': 771,\n",
       " 'sanjay': 772,\n",
       " 'products': 773,\n",
       " 'zealand': 774,\n",
       " 'hearing': 775,\n",
       " 'ensure': 776,\n",
       " 'airline': 777,\n",
       " 'born': 778,\n",
       " 'council': 779,\n",
       " 'rao': 780,\n",
       " 'caught': 781,\n",
       " 'cars': 782,\n",
       " 'related': 783,\n",
       " 'story': 784,\n",
       " 'bus': 785,\n",
       " 'spot': 786,\n",
       " 'marriage': 787,\n",
       " 'deepika': 788,\n",
       " 'addressing': 789,\n",
       " 'travel': 790,\n",
       " 'friend': 791,\n",
       " 'forward': 792,\n",
       " 'giving': 793,\n",
       " 'committed': 794,\n",
       " 'karan': 795,\n",
       " 'sex': 796,\n",
       " 'personnel': 797,\n",
       " 'research': 798,\n",
       " 'asking': 799,\n",
       " 'anil': 800,\n",
       " 'seats': 801,\n",
       " 'signed': 802,\n",
       " 'threatened': 803,\n",
       " 'andhra': 804,\n",
       " 'safety': 805,\n",
       " 'compared': 806,\n",
       " 'terror': 807,\n",
       " 'community': 808,\n",
       " 'friends': 809,\n",
       " 'title': 810,\n",
       " 'electric': 811,\n",
       " 'jaitley': 812,\n",
       " 'doctors': 813,\n",
       " 'corporation': 814,\n",
       " 'college': 815,\n",
       " 'built': 816,\n",
       " 'date': 817,\n",
       " 'looking': 818,\n",
       " 'whose': 819,\n",
       " 'saw': 820,\n",
       " 'rohit': 821,\n",
       " 'legal': 822,\n",
       " 'red': 823,\n",
       " 'line': 824,\n",
       " 'viral': 825,\n",
       " 'future': 826,\n",
       " 'deputy': 827,\n",
       " 'revenue': 828,\n",
       " 'york': 829,\n",
       " 'kg': 830,\n",
       " 'offer': 831,\n",
       " 'fans': 832,\n",
       " 'protests': 833,\n",
       " 'ended': 834,\n",
       " 'notice': 835,\n",
       " 'value': 836,\n",
       " 'bcci': 837,\n",
       " 'vijay': 838,\n",
       " 'almost': 839,\n",
       " 'hour': 840,\n",
       " 'schools': 841,\n",
       " 'television': 842,\n",
       " 'someone': 843,\n",
       " 'bangladesh': 844,\n",
       " 'website': 845,\n",
       " 'discovered': 846,\n",
       " 'conducted': 847,\n",
       " 'net': 848,\n",
       " 'access': 849,\n",
       " 'removed': 850,\n",
       " 'airlines': 851,\n",
       " 'corruption': 852,\n",
       " 'helped': 853,\n",
       " 'internet': 854,\n",
       " 'increased': 855,\n",
       " 'ceremony': 856,\n",
       " 'tendulkar': 857,\n",
       " 'really': 858,\n",
       " 'small': 859,\n",
       " 'kejriwal': 860,\n",
       " 'actors': 861,\n",
       " 'aged': 862,\n",
       " 'ranveer': 863,\n",
       " 'traffic': 864,\n",
       " 'management': 865,\n",
       " 'strike': 866,\n",
       " 'pacer': 867,\n",
       " 'hai': 868,\n",
       " 'weeks': 869,\n",
       " 'stars': 870,\n",
       " 'al': 871,\n",
       " 'points': 872,\n",
       " 'ambani': 873,\n",
       " 'citizens': 874,\n",
       " 'similar': 875,\n",
       " 'dismissed': 876,\n",
       " 'asian': 877,\n",
       " 'english': 878,\n",
       " 'administration': 879,\n",
       " 'birth': 880,\n",
       " 'festival': 881,\n",
       " 'shooting': 882,\n",
       " 'suffered': 883,\n",
       " 'opened': 884,\n",
       " 'digital': 885,\n",
       " 'victims': 886,\n",
       " 'ms': 887,\n",
       " 'aimed': 888,\n",
       " 'germany': 889,\n",
       " 'militants': 890,\n",
       " 'front': 891,\n",
       " 'agreed': 892,\n",
       " 'parties': 893,\n",
       " 'buy': 894,\n",
       " 'akshay': 895,\n",
       " 'victory': 896,\n",
       " 'rejected': 897,\n",
       " 'whether': 898,\n",
       " 'delivery': 899,\n",
       " 'music': 900,\n",
       " 'medal': 901,\n",
       " 'german': 902,\n",
       " 'wants': 903,\n",
       " 'available': 904,\n",
       " 'close': 905,\n",
       " 'position': 906,\n",
       " 'judge': 907,\n",
       " 'affected': 908,\n",
       " 'began': 909,\n",
       " 'trophy': 910,\n",
       " 'kolkata': 911,\n",
       " 'approved': 912,\n",
       " 'injuries': 913,\n",
       " 'soon': 914,\n",
       " 'accident': 915,\n",
       " 'killing': 916,\n",
       " 'chennai': 917,\n",
       " 'kapil': 918,\n",
       " 'areas': 919,\n",
       " 'jobs': 920,\n",
       " 'low': 921,\n",
       " 'islamic': 922,\n",
       " 'tests': 923,\n",
       " 'joined': 924,\n",
       " 'association': 925,\n",
       " 'ground': 926,\n",
       " 'rate': 927,\n",
       " 'fashion': 928,\n",
       " 'whatsapp': 929,\n",
       " 'annual': 930,\n",
       " 'worked': 931,\n",
       " 'growth': 932,\n",
       " 'site': 933,\n",
       " 'spinner': 934,\n",
       " 'kim': 935,\n",
       " 'charge': 936,\n",
       " 'elon': 937,\n",
       " 'arrest': 938,\n",
       " 'sena': 939,\n",
       " 'imposed': 940,\n",
       " 'scheme': 941,\n",
       " 'search': 942,\n",
       " 'tata': 943,\n",
       " 'claim': 944,\n",
       " 'followed': 945,\n",
       " 'something': 946,\n",
       " 'included': 947,\n",
       " 'interview': 948,\n",
       " 'kangana': 949,\n",
       " 'owner': 950,\n",
       " 'urged': 951,\n",
       " 'early': 952,\n",
       " 'production': 953,\n",
       " 'emergency': 954,\n",
       " 'message': 955,\n",
       " 'leading': 956,\n",
       " 'fine': 957,\n",
       " 'amit': 958,\n",
       " 'fast': 959,\n",
       " 'asia': 960,\n",
       " 'anyone': 961,\n",
       " 'de': 962,\n",
       " 'brought': 963,\n",
       " 'cover': 964,\n",
       " 'charged': 965,\n",
       " 'goal': 966,\n",
       " 'wrong': 967,\n",
       " 'rules': 968,\n",
       " 'happened': 969,\n",
       " 'image': 970,\n",
       " 'plane': 971,\n",
       " 'prasad': 972,\n",
       " 'france': 973,\n",
       " 'metro': 974,\n",
       " 'joint': 975,\n",
       " 'funds': 976,\n",
       " 'connection': 977,\n",
       " 'energy': 978,\n",
       " 'grand': 979,\n",
       " 'surfaced': 980,\n",
       " 'executive': 981,\n",
       " 'cause': 982,\n",
       " 'sanctions': 983,\n",
       " 'details': 984,\n",
       " 'thought': 985,\n",
       " 'book': 986,\n",
       " 'served': 987,\n",
       " 'century': 988,\n",
       " 'brand': 989,\n",
       " 'prices': 990,\n",
       " 'champion': 991,\n",
       " 'payments': 992,\n",
       " 'programme': 993,\n",
       " 'fifa': 994,\n",
       " 'attempt': 995,\n",
       " 'terrorists': 996,\n",
       " 'featured': 997,\n",
       " 'aap': 998,\n",
       " 'facing': 999,\n",
       " 'lives': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b305d6",
   "metadata": {},
   "source": [
    "- dictionary í˜•íƒœë¡œ ì €ì¥ë˜ì–´ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a3b288f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 1), ('india', 2), ('year', 3), ('added', 4)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(src_tokenizer.word_index.items())[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d80278",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ğŸ’¡\n",
    "`src_tokenizer.word_counts.items()`\n",
    "- **ë‹¨ì–´ì™€ ê° ë‹¨ì–´ì˜ ë“±ì¥ ë¹ˆë„ìˆ˜**ê°€ ì €ì¥ë˜ì–´ìˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "- **ë¹ˆë„ìˆ˜ê°€ ë‚®ì€ ë‹¨ì–´ëŠ” í›ˆë ¨ ë°ì´í„°ì—ì„œ ì œì™¸**í•˜ê³  ì§„í–‰\n",
    "    - ë“±ì¥ ë¹ˆë„ê°€ ë‚®ì€ ë‹¨ì–´ëŠ” ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ì˜ë¯¸ë¥¼ ê°€ì§€ì§€ ì•Šì„ ê°€ëŠ¥ì„±ì´ ë†’ê¸° ë•Œë¬¸\n",
    "- **ë“±ì¥ ë¹ˆë„ìˆ˜ë¥¼ threshold**ë¡œ ì§€ì •í•˜ê³  í•´ë‹¹ ê°’ ë¯¸ë§Œì¸ ë‹¨ì–´ê°€ ì°¨ì§€í•˜ëŠ” ë¹„ì¤‘ í™•ì¸\n",
    "- thresholdë¥¼ 4\\~8ë¡œ ì„¤ì •í•˜ê³  ë¹„ì¤‘ì„ ë¹„êµí•´ë³¸ë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec482fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 4\n",
      "ë‹¨ì–´ ì§‘í•©(vocabulary)ì˜ í¬ê¸°(ì´ ê°œìˆ˜) : 69702\n",
      "ë“±ì¥ ë¹ˆë„ê°€ 3ë²ˆ ì´í•˜ì¸ í¬ê·€ ë‹¨ì–´ì˜ ìˆ˜: 40031\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ë¥¼ ì œì™¸ì‹œí‚¬ ê²½ìš°ì˜ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° 29671\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ì˜ ë¹„ìœ¨: 57.4316375426817\n",
      "ì „ì²´ ë“±ì¥ ë¹ˆë„ì—ì„œ í¬ê·€ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ë¹„ìœ¨: 2.1801242640781817\n",
      "\n",
      "==============================\n",
      "\n",
      "Threshold: 5\n",
      "ë‹¨ì–´ ì§‘í•©(vocabulary)ì˜ í¬ê¸°(ì´ ê°œìˆ˜) : 69702\n",
      "ë“±ì¥ ë¹ˆë„ê°€ 4ë²ˆ ì´í•˜ì¸ í¬ê·€ ë‹¨ì–´ì˜ ìˆ˜: 43366\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ë¥¼ ì œì™¸ì‹œí‚¬ ê²½ìš°ì˜ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° 26336\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ì˜ ë¹„ìœ¨: 62.21629221543141\n",
      "ì „ì²´ ë“±ì¥ ë¹ˆë„ì—ì„œ í¬ê·€ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ë¹„ìœ¨: 2.6630757857375076\n",
      "\n",
      "==============================\n",
      "\n",
      "Threshold: 6\n",
      "ë‹¨ì–´ ì§‘í•©(vocabulary)ì˜ í¬ê¸°(ì´ ê°œìˆ˜) : 69702\n",
      "ë“±ì¥ ë¹ˆë„ê°€ 5ë²ˆ ì´í•˜ì¸ í¬ê·€ ë‹¨ì–´ì˜ ìˆ˜: 45713\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ë¥¼ ì œì™¸ì‹œí‚¬ ê²½ìš°ì˜ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° 23989\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ì˜ ë¹„ìœ¨: 65.58348397463487\n",
      "ì „ì²´ ë“±ì¥ ë¹ˆë„ì—ì„œ í¬ê·€ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ë¹„ìœ¨: 3.087921071095243\n",
      "\n",
      "==============================\n",
      "\n",
      "Threshold: 7\n",
      "ë‹¨ì–´ ì§‘í•©(vocabulary)ì˜ í¬ê¸°(ì´ ê°œìˆ˜) : 69702\n",
      "ë“±ì¥ ë¹ˆë„ê°€ 6ë²ˆ ì´í•˜ì¸ í¬ê·€ ë‹¨ì–´ì˜ ìˆ˜: 47505\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ë¥¼ ì œì™¸ì‹œí‚¬ ê²½ìš°ì˜ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° 22197\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ì˜ ë¹„ìœ¨: 68.1544288542653\n",
      "ì „ì²´ ë“±ì¥ ë¹ˆë„ì—ì„œ í¬ê·€ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ë¹„ìœ¨: 3.47717854942216\n",
      "\n",
      "==============================\n",
      "\n",
      "Threshold: 8\n",
      "ë‹¨ì–´ ì§‘í•©(vocabulary)ì˜ í¬ê¸°(ì´ ê°œìˆ˜) : 69702\n",
      "ë“±ì¥ ë¹ˆë„ê°€ 7ë²ˆ ì´í•˜ì¸ í¬ê·€ ë‹¨ì–´ì˜ ìˆ˜: 49008\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ë¥¼ ì œì™¸ì‹œí‚¬ ê²½ìš°ì˜ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° 20694\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ì˜ ë¹„ìœ¨: 70.31075148489283\n",
      "ì „ì²´ ë“±ì¥ ë¹ˆë„ì—ì„œ í¬ê·€ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ë¹„ìœ¨: 3.858073074113147\n",
      "\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# threshold 4~8ê¹Œì§€ ë¹„êµ\n",
    "thresholds = [4, 5, 6, 7, 8]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    total_cnt = len(src_tokenizer.word_index) # ì „ì²´ ë‹¨ì–´ì˜ ìˆ˜\n",
    "    rare_cnt = 0     # ë“±ì¥ ë¹ˆë„ìˆ˜ê°€ thresholdë³´ë‹¤ ì‘ì€ ë‹¨ì–´ ì¹´ìš´íŠ¸\n",
    "    total_freq = 0   # í›ˆë ¨ ë°ì´í„°ì˜ ì „ì²´ ë‹¨ì–´ ë¹ˆë„ìˆ˜ì˜ ì´ í•©\n",
    "    rare_freq = 0    # ë“±ì¥ ë¹ˆë„ìˆ˜ê°€ thresholdë³´ë‹¤ ì‘ì€ ë‹¨ì–´ ë¹ˆë„ìˆ˜ì˜ ì´ í•©\n",
    "\n",
    "    # ë‹¨ì–´, ë¹ˆë„ìˆ˜ pairë¥¼ key, valueë¡œ\n",
    "    for key, value in src_tokenizer.word_counts.items():\n",
    "        total_freq += value\n",
    "\n",
    "        # ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ìˆ˜ê°€ thresholdë³´ë‹¤ ì‘ìœ¼ë©´\n",
    "        if (value < threshold):\n",
    "            rare_cnt += 1\n",
    "            rare_freq += value\n",
    "\n",
    "    print('Threshold:', threshold)\n",
    "    print('ë‹¨ì–´ ì§‘í•©(vocabulary)ì˜ í¬ê¸°(ì´ ê°œìˆ˜) :', total_cnt)\n",
    "    print('ë“±ì¥ ë¹ˆë„ê°€ %së²ˆ ì´í•˜ì¸ í¬ê·€ ë‹¨ì–´ì˜ ìˆ˜: %s'%(threshold - 1, rare_cnt))\n",
    "    print('ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ë¥¼ ì œì™¸ì‹œí‚¬ ê²½ìš°ì˜ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° %s'%(total_cnt - rare_cnt))\n",
    "    print(\"ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ì˜ ë¹„ìœ¨:\", (rare_cnt / total_cnt)*100)\n",
    "    print(\"ì „ì²´ ë“±ì¥ ë¹ˆë„ì—ì„œ í¬ê·€ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ë¹„ìœ¨:\", (rare_freq / total_freq)*100)\n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376d5762",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**ê²°ê³¼ ë¶„ì„** (GPTì°¸ê³ )\n",
    "1. Vocabulary size:\n",
    "     - thresholdê°€ ë‚®ìœ¼ë©´ vocabulary ì‚¬ì´ì¦ˆê°€ ì»¤ì§€ê³ \n",
    "     - thresholdê°€ ë†’ìœ¼ë©´ vocabulary ì‚¬ì´ì¦ˆê°€ ì‘ì•„ì§„ë‹¤\n",
    "2. Rare word exclusion:\n",
    "    - ì¼ë°˜ì ì¸ ë‹¨ì–´ê°€ í¬í•¨ëœ ê°„ê²°í•œ ì–´íœ˜ë¥¼ ë½‘ì•„ë‚´ê³  ì‹¶ìœ¼ë©´ ë†’ì€ thresholdê°’ì„ ì‚¬ìš©í•œë‹¤\n",
    "3. Rare word ratio:\n",
    "    - trade-off ê´€ê³„ë‹¤.\n",
    "    - ë‹¤ì–‘í•œ ë‹¨ì–´ë¥¼ ì‚¬ìš©í• ì§€, ë¹ˆë„ìˆ˜ê°€ ë‚®ì€ ë‹¨ì–´ë¥¼ ì œì™¸í• ì§€\n",
    "4. Frequency ratio:\n",
    "    - ë¹„ìœ¨ì´ ë‚®ì„ìˆ˜ë¡ í¬ê·€ë‹¨ì–´ê°€ ì „ì²´ ë¹ˆë„ìˆ˜ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ ì ë‹¤\n",
    "    \n",
    "- ìµœëŒ€í•œ í¬ê·€ë‹¨ì–´ë¥¼ ë§ì´ ì œì™¸ì‹œì¼œì„œ ê°„ê²°í•œ ì–´íœ˜ë¥¼ ì‚¬ìš©í•´ë³´ê³  ì‹¶ìœ¼ë©´ `threshold 8`ì„ ì„ íƒí•˜ëŠ”ê²Œ ì¢‹ì„ê²ƒ ê°™ê³ \n",
    "- ì–´íœ˜í¬ê¸°, í¬ê·€ë‹¨ì–´ ì œì™¸ ì‚¬ì´ì˜ ì ë‹¹í•œ ê· í˜•ì„ ì´ë£¨ê³ ì‹¶ë‹¤ë©´ `threshold 5`ë¥¼ ì„ íƒí•˜ëŠ”ê²Œ ì¢‹ì„ê²ƒê°™ë‹¤\n",
    "\n",
    "ğŸ‘‰ **threshold 5**ë¥¼ ì‚¬ìš©í•˜ê¸°ë¡œ ê²°ì •!\n",
    "\n",
    "---\n",
    "\n",
    "- **ë“±ì¥ ë¹ˆë„ê°€ 5ì´í•˜**ì¸ ë‹¨ì–´ëŠ” ì •ìˆ˜ ì¸ì½”ë”© ê³¼ì •ì—ì„œ ì œì™¸, í›ˆë ¨ë°ì´í„°ì—ì„œ ì œê±°\n",
    "- ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸°ëŠ” ì–´ë¦¼ì¡ì•„ 26000ìœ¼ë¡œ ì œí•œ\n",
    "- Tokenizerë¥¼ ì •ì˜í• ë•Œ `num_words`ê°’ì„ ì •í•˜ë©´ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸°ë¥¼ ì œí•œí• ìˆ˜ ìˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "994ebefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69702\n"
     ]
    }
   ],
   "source": [
    "# vocabulary size ì§€ì •í•´ì„œ ë‹¤ì‹œ í† í¬ë‚˜ì˜ì € ì •ì˜\n",
    "src_vocab = 26000 # vocabulary size \n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # size limit 26000\n",
    "src_tokenizer.fit_on_texts(encoder_input_train)\n",
    "print(len(src_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77902c95",
   "metadata": {},
   "source": [
    "- ì´ ë‹¨ê³„ì—ì„œëŠ” ë‹¨ì–´ ì§‘í•© í¬ê¸° ì œí•œì´ ì ìš©ë˜ëŠ”ê²Œ ì•„ë‹Œê°€ë³´ë‹¤.. ì¼ë‹¨ ë„˜ì–´ê°„ë‹¤\n",
    "\n",
    "\n",
    "- `texts_to_sequences()`ëŠ” ìƒì„±ëœ ë‹¨ì–´ ì§‘í•©ì— ê¸°ë°˜í•´ì„œ ì…ë ¥ìœ¼ë¡œ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ ë°ì´í„° ë‹¨ì–´ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜(ì •ìˆ˜ ì¸ì½”ë”©)ì„ ì§„í–‰\n",
    "- í˜„ì¬ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸°ë¥¼ 8000ìœ¼ë¡œ ì œí•œí–ˆê¸° ë•Œë¬¸ì— 26000ì´ ë„˜ëŠ” ìˆ«ìëŠ” ì •ìˆ˜ ì¸ì½”ë”© ì´í›„ì— ë°ì´í„°ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75e46e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 1400, 1773, 1051, 137, 2240, 916, 11, 2291, 10743, 16032, 2506, 1027, 8820, 175, 2001, 666, 29, 3, 1773, 6, 1051, 196, 2240, 2054, 618, 12, 219, 1302, 5138, 117, 39, 882, 16032], [206, 63, 3841, 3991, 4236, 8, 212, 841, 239, 160, 58, 2407, 4692, 81, 21, 63, 3841, 3991, 2626, 3266, 2626, 8, 841, 63, 3991, 630, 3392, 105, 2626, 3266, 2626, 841, 212, 21, 17, 1588], [15416, 4390, 576, 27, 5, 16, 3123, 1942, 282, 6733, 125, 41, 81, 1942, 282, 85, 3344, 3377, 41, 576, 2893, 41, 11007, 118, 244, 1032, 22198, 1839, 1286, 260, 10, 1942, 2408, 41, 1429, 2214, 2231, 7798]]\n"
     ]
    }
   ],
   "source": [
    "# text sequence -> integer sequence\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train)\n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# check\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3edade",
   "metadata": {},
   "source": [
    "### headlines data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7aab52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make vocabulary of headlines data \n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5d05c6",
   "metadata": {},
   "source": [
    "- headlines dataëŠ” decoder input train ë°ì´í„°ë¡œ ë§ì¶˜ í† í¬ë‚˜ì´ì €ë¥¼ ë§Œë“¤ì–´ì„œ ì‚¬ìš©í•œë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54d75764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 4\n",
      "ë‹¨ì–´ ì§‘í•©(vocabulary)ì˜ í¬ê¸°(ì´ ê°œìˆ˜) : 30140\n",
      "ë“±ì¥ ë¹ˆë„ê°€ 3ë²ˆ ì´í•˜ì¸ í¬ê·€ ë‹¨ì–´ì˜ ìˆ˜: 16990\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ë¥¼ ì œì™¸ì‹œí‚¬ ê²½ìš°ì˜ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° 13150\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ì˜ ë¹„ìœ¨: 56.37027206370272\n",
      "ì „ì²´ ë“±ì¥ ë¹ˆë„ì—ì„œ í¬ê·€ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ë¹„ìœ¨: 3.1587571269758428\n",
      "\n",
      "==============================\n",
      "\n",
      "Threshold: 5\n",
      "ë‹¨ì–´ ì§‘í•©(vocabulary)ì˜ í¬ê¸°(ì´ ê°œìˆ˜) : 30140\n",
      "ë“±ì¥ ë¹ˆë„ê°€ 4ë²ˆ ì´í•˜ì¸ í¬ê·€ ë‹¨ì–´ì˜ ìˆ˜: 18566\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ë¥¼ ì œì™¸ì‹œí‚¬ ê²½ìš°ì˜ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° 11574\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ì˜ ë¹„ìœ¨: 61.59920371599203\n",
      "ì „ì²´ ë“±ì¥ ë¹ˆë„ì—ì„œ í¬ê·€ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ë¹„ìœ¨: 3.9365706861514886\n",
      "\n",
      "==============================\n",
      "\n",
      "Threshold: 6\n",
      "ë‹¨ì–´ ì§‘í•©(vocabulary)ì˜ í¬ê¸°(ì´ ê°œìˆ˜) : 30140\n",
      "ë“±ì¥ ë¹ˆë„ê°€ 5ë²ˆ ì´í•˜ì¸ í¬ê·€ ë‹¨ì–´ì˜ ìˆ˜: 19731\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ë¥¼ ì œì™¸ì‹œí‚¬ ê²½ìš°ì˜ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° 10409\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ì˜ ë¹„ìœ¨: 65.46449900464499\n",
      "ì „ì²´ ë“±ì¥ ë¹ˆë„ì—ì„œ í¬ê·€ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ë¹„ìœ¨: 4.655283246779366\n",
      "\n",
      "==============================\n",
      "\n",
      "Threshold: 7\n",
      "ë‹¨ì–´ ì§‘í•©(vocabulary)ì˜ í¬ê¸°(ì´ ê°œìˆ˜) : 30140\n",
      "ë“±ì¥ ë¹ˆë„ê°€ 6ë²ˆ ì´í•˜ì¸ í¬ê·€ ë‹¨ì–´ì˜ ìˆ˜: 20624\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ë¥¼ ì œì™¸ì‹œí‚¬ ê²½ìš°ì˜ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° 9516\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ì˜ ë¹„ìœ¨: 68.42733908427338\n",
      "ì „ì²´ ë“±ì¥ ë¹ˆë„ì—ì„œ í¬ê·€ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ë¹„ìœ¨: 5.316375418426433\n",
      "\n",
      "==============================\n",
      "\n",
      "Threshold: 8\n",
      "ë‹¨ì–´ ì§‘í•©(vocabulary)ì˜ í¬ê¸°(ì´ ê°œìˆ˜) : 30140\n",
      "ë“±ì¥ ë¹ˆë„ê°€ 7ë²ˆ ì´í•˜ì¸ í¬ê·€ ë‹¨ì–´ì˜ ìˆ˜: 21351\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ë¥¼ ì œì™¸ì‹œí‚¬ ê²½ìš°ì˜ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° 8789\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ì˜ ë¹„ìœ¨: 70.83941605839415\n",
      "ì „ì²´ ë“±ì¥ ë¹ˆë„ì—ì„œ í¬ê·€ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ë¹„ìœ¨: 5.944277258947508\n",
      "\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# threshold 4~8ê¹Œì§€ ë¹„êµ\n",
    "thresholds = [4, 5, 6, 7, 8]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    total_cnt = len(tar_tokenizer.word_index) # ì „ì²´ ë‹¨ì–´ì˜ ìˆ˜\n",
    "    rare_cnt = 0     # ë“±ì¥ë¹ˆë„ìˆ˜ < threshold ë‹¨ì–´ ê°œìˆ˜ ì¹´ìš´íŠ¸\n",
    "    total_freq = 0   # í›ˆë ¨ ë°ì´í„°ì˜ ì „ì²´ ë‹¨ì–´ ë¹ˆë„ìˆ˜ì˜ ì´ í•©\n",
    "    rare_freq = 0    # ë“±ì¥ë¹ˆë„ìˆ˜ < threshold ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ìˆ˜ ì´ í•©\n",
    "\n",
    "    # ë‹¨ì–´, ë¹ˆë„ìˆ˜ pairë¥¼ key, valueë¡œ\n",
    "    for key, value in tar_tokenizer.word_counts.items():\n",
    "        total_freq += value\n",
    "\n",
    "        # ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ìˆ˜ê°€ thresholdë³´ë‹¤ ì‘ìœ¼ë©´\n",
    "        if (value < threshold):\n",
    "            rare_cnt += 1\n",
    "            rare_freq += value\n",
    "\n",
    "    print('Threshold:', threshold)\n",
    "    print('ë‹¨ì–´ ì§‘í•©(vocabulary)ì˜ í¬ê¸°(ì´ ê°œìˆ˜) :', total_cnt)\n",
    "    print('ë“±ì¥ ë¹ˆë„ê°€ %së²ˆ ì´í•˜ì¸ í¬ê·€ ë‹¨ì–´ì˜ ìˆ˜: %s'%(threshold - 1, rare_cnt))\n",
    "    print('ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ë¥¼ ì œì™¸ì‹œí‚¬ ê²½ìš°ì˜ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° %s'%(total_cnt - rare_cnt))\n",
    "    print(\"ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ì˜ ë¹„ìœ¨:\", (rare_cnt / total_cnt)*100)\n",
    "    print(\"ì „ì²´ ë“±ì¥ ë¹ˆë„ì—ì„œ í¬ê·€ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ë¹„ìœ¨:\", (rare_freq / total_freq)*100)\n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e97cb8",
   "metadata": {},
   "source": [
    "- headlines ë°ì´í„°ëŠ” í¬ê·€ë‹¨ì–´ë¥¼ ìµœëŒ€í•œ ë§ì´ í¬í•¨í•´ì„œ ì§„í–‰í•´ë³¸ë‹¤.\n",
    "\n",
    "ğŸ‘‰ threshold 4ë¥¼ ì‚¬ìš©í•˜ê¸°ë¡œ ê²°ì •!\n",
    "\n",
    "- ë“±ì¥ ë¹ˆë„ê°€ 4ì´í•˜ì¸ ë‹¨ì–´ëŠ” ì •ìˆ˜ ì¸ì½”ë”© ê³¼ì •ì—ì„œ ì œì™¸, í›ˆë ¨ë°ì´í„°ì—ì„œ ì œê±°\n",
    "- ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸°ëŠ” ì–´ë¦¼ì¡ì•„ 13000ìœ¼ë¡œ ì œí•œ\n",
    "- Tokenizerë¥¼ ì •ì˜í• ë•Œ num_wordsê°’ì„ ì •í•´ì„œ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸°ë¥¼ ì œí•œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "622be8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 13, 1010, 2439, 41, 2047, 29, 4395, 1545, 3, 180], [1, 68, 4849, 7251, 4262, 4, 25, 24, 209, 548], [1, 1165, 6480, 890, 3, 30, 2906], [1, 33, 288, 11576, 76, 48, 2087, 16, 48], [1, 1235, 165, 275, 10411, 429, 12, 2394, 51, 3897]]\n",
      "target\n",
      "decoder  [[13, 1010, 2439, 41, 2047, 29, 4395, 1545, 3, 180, 2], [68, 4849, 7251, 4262, 4, 25, 24, 209, 548, 2], [1165, 6480, 890, 3, 30, 2906, 2], [33, 288, 11576, 76, 48, 2087, 16, 48, 2], [1235, 165, 275, 10411, 429, 12, 2394, 51, 3897, 2]]\n"
     ]
    }
   ],
   "source": [
    "# vocabulary size ì§€ì •í•´ì„œ ë‹¤ì‹œ í† í¬ë‚˜ì˜ì € ì •ì˜\n",
    "tar_vocab = 13000 # vocabulary size\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab)  # size limit 13000\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# text sequence -> integer sequence\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# ì˜ ë³€í™˜ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b143e092",
   "metadata": {},
   "source": [
    "## 2) ì¶”ê°€ ì‘ì—… - empty sample ì‚­ì œ\n",
    "- ì „ì²´ ë°ì´í„°ì—ì„œ ë¹ˆë„ìˆ˜ê°€ ë‚®ì€ ë‹¨ì–´ëŠ” ì‚­ì œ ë˜ì—ˆë‹¤ => **empty sample**ë¡œ ë°”ë€Œì—ˆë‹¤\n",
    "- headlinesëŠ” í‰ê·  ê¸¸ì´ê°€ 9ì˜€ê¸°ë•Œë¬¸ì— ì´ëŸ° ìƒ˜í”Œì´ ë” ë§ì„ìˆ˜ ìˆë‹¤\n",
    "\n",
    "\n",
    "1. headlinesì—ì„œ ê¸¸ì´ê°€ 0ì´ ëœ ìƒ˜í”Œ ì¸ë±ìŠ¤ë¥¼ ì¶”ì¶œí•˜ê³ \n",
    "    - `decoder_input` ì—ëŠ” `sostoken`, `decoder_target`ì—ëŠ” `eostoken`ê°€ ëª¨ë‘ ì¶”ê°€ëœ ìƒí™©\n",
    "    - ëª¨ë“  ìƒ˜í”Œì—ì„œ ë“±ì¥í•˜ê¸°ë•Œë¬¸ì— ë‹¨ì–´ì§‘í•© ì œí•œì´ ìˆì–´ë„ ì‚­ì œë˜ì§€ ì•ŠìŒ\n",
    "    - ê¸¸ì´ê°€ 0ì´ ëœ summaryì˜ ì‹¤ì œ ê¸¸ì´ëŠ” ìœ„ì˜ ë‹¨ì–´ë§Œ ë‚¨ì•„ìˆì–´ì„œ `1`ë¡œ ë‚˜ì˜¬ê²ƒ!  \n",
    "2. train, test ë°ì´í„°ì—ì„œ summary ê¸¸ì´ê°€ 1ì¸ ê²½ìš° ì¸ë±ìŠ¤ë¥¼ ê°ê° `drop_train`ê³¼ `drop_test` ë³€ìˆ˜ì— ì €ì¥\n",
    "3. ì´ ì¸ë±ìŠ¤ì˜ column ìƒ˜í”Œì„ ëª¨ë‘ ì‚­ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96b842b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚­ì œí•  í›ˆë ¨ ë°ì´í„°ì˜ ê°œìˆ˜ : 0\n",
      "ì‚­ì œí•  í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ê°œìˆ˜ : 0\n"
     ]
    }
   ],
   "source": [
    "# train, test ë°ì´í„°ì—ì„œ headlines ê¸¸ì´ê°€ 1ì¸ ì¸ë±ìŠ¤ ì¶”ì¶œ - 'sostoken', 'eostoken'ë§Œ ë‚¨ì•„ìˆëŠ” ìƒíƒœ\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('ì‚­ì œí•  í›ˆë ¨ ë°ì´í„°ì˜ ê°œìˆ˜ :', len(drop_train))\n",
    "print('ì‚­ì œí•  í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ê°œìˆ˜ :', len(drop_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b97e0",
   "metadata": {},
   "source": [
    "- ì˜¤! ì‚­ì œí•  ë°ì´í„°ê°€ ì—†ë‹¤! \n",
    "    - *ì™œ ì´ë ‡ê²Œ ë˜ì—ˆëŠ”ì§€ ì´í•´ë˜ì§€ì•Šì§€ë§Œ ì¼ë‹¨ pass*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "614108d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í›ˆë ¨ ë°ì´í„°ì˜ ê°œìˆ˜ : 78688\n",
      "í›ˆë ¨ ë ˆì´ë¸”ì˜ ê°œìˆ˜ : 78688\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ê°œìˆ˜ : 19672\n",
      "í…ŒìŠ¤íŠ¸ ë ˆì´ë¸”ì˜ ê°œìˆ˜ : 19672\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ ë°ì´í„°ìˆ˜ í™•ì¸\n",
    "print('í›ˆë ¨ ë°ì´í„°ì˜ ê°œìˆ˜ :', len(encoder_input_train))\n",
    "print('í›ˆë ¨ ë ˆì´ë¸”ì˜ ê°œìˆ˜ :', len(decoder_input_train))\n",
    "print('í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ê°œìˆ˜ :', len(encoder_input_test))\n",
    "print('í…ŒìŠ¤íŠ¸ ë ˆì´ë¸”ì˜ ê°œìˆ˜ :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd6e64",
   "metadata": {},
   "source": [
    "# Step 5. íŒ¨ë”©ì¶”ê°€\n",
    "- ì„œë¡œ ë‹¤ë¥¸ ê¸¸ì´ì˜ ìƒ˜í”Œì„ ë³‘ë ¬ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ê°™ì€ ê¸¸ì´ë¡œ ë§ì¶°ì•¼í•¨\n",
    "    - ìµœëŒ€ ê¸¸ì´ë³´ë‹¤ ì§§ì€ ë°ì´í„°ì—” ë’¤ì— ìˆ«ì 0ì´ ì¶”ê°€ë˜ì–´ ê¸¸ì´ê°€ ë§ì¶°ì§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27ec1d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 15)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max length í™•ì¸\n",
    "text_max_len, headlines_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "131daae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "612c3fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    5,  1400,  1773, ...,     0,     0,     0],\n",
       "       [  206,    63,  3841, ...,     0,     0,     0],\n",
       "       [15416,  4390,   576, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  523,    65,   184, ...,     0,     0,     0],\n",
       "       [  443,   225,    68, ...,     0,     0,     0],\n",
       "       [    5,    16,   125, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding check\n",
    "encoder_input_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9062e560",
   "metadata": {},
   "source": [
    "# Step 6. index2word data\n",
    "- í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì—ì„œ ì •ìˆ˜ ì¸ë±ìŠ¤ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‹¤ì œ ë°ì´í„°ë¡œ ë³µì›í•´ì•¼í•œë‹¤\n",
    "- í•„ìš”í•œ 3ê°œì˜ ì‚¬ì „ì„ ë¯¸ë¦¬ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ed4161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # text dataset : int -> word\n",
    "tar_word_to_index = tar_tokenizer.word_index # headlines dataset : word -> int\n",
    "tar_index_to_word = tar_tokenizer.index_word # headlines dataset : int -> word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ebaf68",
   "metadata": {},
   "source": [
    "- ì˜ ë³€í™˜ë˜ì—ˆëŠ”ì§€ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f870b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sostoken', 1), ('eostoken', 2), ('to', 3)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tar_word_to_index.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bb2ddf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'sostoken'), (2, 'eostoken'), (3, 'to')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tar_index_to_word.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ed63655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'said'), (2, 'india'), (3, 'year')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(src_index_to_word.items())[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af056ebf",
   "metadata": {},
   "source": [
    "# Step 7. ëª¨ë¸ ì„¤ê³„\n",
    "- functional API ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b842a5e7",
   "metadata": {},
   "source": [
    "## 1) Encoder\n",
    "\n",
    "**recurrent dropout**\n",
    "- layerê°€ ì•„ë‹Œ time stepë§ˆë‹¤ dropoutì„ ì ìš©í•˜ëŠ” ë°©ì‹\n",
    "- time stepì˜ ì…ë ¥ì„ ëœë¤ìœ¼ë¡œ ìƒì„±\n",
    "- íš¨ê³¼ : regularization, overfitting ë°©ì§€\n",
    "\n",
    "<a href='https://arxiv.org/pdf/1512.05287.pdf'><img src='./img/recurrent_dropout.png' width=70% height=70%></a>\n",
    "\n",
    "    - left: only dropout / right: dropout + recurrent dropout(Variational Dropout)\n",
    "    - colored arrow : dropout\n",
    "    \n",
    "> ì°¸ê³  - recurrent dropoutì„ ì‚¬ìš©í•˜ë©´ ê²½ê³ ë¬¸ì´ ëœ¬ë‹¤<br>\n",
    "> ```WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU```\n",
    "=> recurrent dropoutì„ ì‚¬ìš©í•˜ë©´ cuDNNã…‡ë¥´ ì‚¬ìš©í• ìˆ˜ ì—†ì–´ì„œ í•™ìŠµì‹œê°„ì´ ë” ì˜¤ë˜ê±¸ë¦¼\n",
    "\n",
    "- [recurrent dropout ë…¼ë¬¸](https://arxiv.org/pdf/1603.05118v2.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "80e19b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "embedding_dim = 128 # vector dimension\n",
    "hidden_size = 256   # LSTMì˜ capacityì— í•´ë‹¹(ë‰´ëŸ°ì˜ ê°œìˆ˜) - í¬ë‹¤ê³  í•­ìƒ ì¢‹ì€ê±´ ì•„ë‹˜\n",
    "\n",
    "# encoder\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# encoder - embedding layer\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# encoder - LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# encoder - LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# encoder - LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "encoder_output, state_h, state_c = encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f5e71a",
   "metadata": {},
   "source": [
    "- ëª¨ë¸ í›ˆë ¨ ë‚´ìš©ì„ ë³´ê³  ì‹œê°„ì´ ë˜ë©´ recurrent dropoutë„ ì‹œë„í•´ë³´ê¸°ìœ„í•´ ì½”ë“œë¥¼ ë‚¨ê²¨ë‘”ë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0400ab53",
   "metadata": {},
   "source": [
    "## 2) Decoder\n",
    "- LSTMì˜ ì…ë ¥ì—ì„œ `initial_state`ì¸ìê°’ìœ¼ë¡œ encoderì˜ `hidden state`, `cell state`ë¥¼ ë„£ì–´ì•¼í•¨\n",
    "\n",
    "## 2-1) decoder input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ba19ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# decoder - embedding layer\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# decoder - LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb69573d",
   "metadata": {},
   "source": [
    "## 2-2) decoder output layer\n",
    "- headlines ë‹¨ì–´ì¥ `tar_vocab`ì—ì„œ í•˜ë‚˜ì˜ ë‹¨ì–´ë¥¼ ì„ íƒí•˜ëŠ” ë‹¤ì¤‘í´ë˜ìŠ¤ ë¶„ë¥˜ ì‘ì—…ì„ í•˜ê²Œëœë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a1c406ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 45)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 45, 128)      3328000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 45, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 45, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1664000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 45, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 13000)  3341000     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 10,172,104\n",
      "Trainable params: 10,172,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# decoder output layer\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "# define model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae1599d",
   "metadata": {},
   "source": [
    "- ì—¬ê¸°ê¹Œì§€ê°€ ì¸ì½”ë”ì˜ hidden_stateì™€ cell stateë¥¼ ë””ì½”ë”ì˜ initial stateë¡œ ì‚¬ìš©í•˜ëŠ” ê°€ì¥ ê¸°ë³¸ì ì¸ seq2seq!\n",
    "- decoderì˜ output layerë¥¼ ì‚´ì§ ë°”ê¿”ì„œ ì„±ëŠ¥ì„ ë†’ì¼ìˆ˜ ìˆëŠ” ë°©ë²•ì´ `Attention` mechanism!\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "âœ”ï¸ *ì´ ë¶€ë¶„ì—ì„œ ì–´í…ì…˜ ë©”í„°ë‹ˆì¦˜ì„ êµ¬ì¶•í•˜ëŠ” ê±¸ ë¹ ëœ¨ë¦¬ê³  ëª¨ë¸íŠ¸ë ˆì´ë‹ì„ ì§„í–‰í–ˆë‹¤..:) ì•„ë˜ì—ì„œ ë‹¤ì‹œ ì–´í…ì…˜êµ¬ì¡°ë¥¼ ì¶”ê°€í•œ ëª¨ë¸í•™ìŠµì„ ì§„í–‰í•œë‹¤*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62819b7d",
   "metadata": {},
   "source": [
    "# Step 8. Training model\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ’¡\n",
    "## Evaluate metrics for Text summarization\n",
    "\n",
    "**ROUGE (Recall-Oriented Understudy for Gisting Evaluation)**\n",
    "- label(ì‚¬ëŒì´ ë§Œë“  ìš”ì•½ë¬¸)ê³¼ summary(ëª¨ë¸ì´ ìƒì„±í•œ inference)ì„ ë¹„êµí•´ì„œ ì„±ëŠ¥ ê³„ì‚°\n",
    "- ROUGE-N, ROUGE-L, ROUGE-W, ROUGE-S ë“± ë‹¤ì–‘í•œ ì§€í‘œê°€ ìˆìŒ\n",
    "- ê°ê° ì§€í‘œë³„ë¡œ recall ë° precisionì„ ë‘˜ ë‹¤ êµ¬í•˜ëŠ” ê²ƒì´ ë„ì›€ì´ ë¨(ê¸°ë°˜í•˜ì—¬ F1 scoreë¡œ ì¸¡ì • ê°€ëŠ¥)\n",
    "\n",
    "**BLEU (Bilingual Evaluation Understudy)**\n",
    "- Measures the precision of n-grams (usually up to 4-grams) in the generated summary compared to the reference summary\n",
    "\n",
    "\n",
    "\n",
    "ğŸ‘‰ `ROUGE metric`ì€ [ë¼ì´ë¸ŒëŸ¬ë¦¬](https://github.com/pltrdy/rouge)ë¡œ ì‚¬ìš©í• ìˆ˜ ìˆì–´ì„œ í•™ìŠµ ì´í›„ì— ì´ ë°©ë²•ì„ ì´ìš©í•´ì„œ í™•ì¸í•´ë´ì•¼ê² ë‹¤.\n",
    "\n",
    "\n",
    "**[ì°¸ê³ ]** \n",
    "- [blog](https://arc.net/l/quote/egjdfsto)\n",
    "- [blog](https://medium.com/nlplanet/two-minutes-nlp-learn-the-rouge-metric-by-examples-f179cc285499)\n",
    "- [ROUGE: A Package for Automatic Evaluation of Summaries](https://aclanthology.org/W04-1013.pdf)\n",
    "- [github](https://github.com/pltrdy/rouge)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a9f4eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from rouge) (1.16.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# # install rough libarary\n",
    "# !pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dbd392e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE library\n",
    "from rouge import Rouge\n",
    "\n",
    "# make rouge instance\n",
    "rouge = Rouge()\n",
    "\n",
    "# # check the scores - í˜¹ì‹œ ëª¨ë¸ì— ë°”ë¡œ ì‚¬ìš©ì´ ì•ˆë˜ë©´ ì•„ë˜ì—ì„œ ì´ëŸ° ë°©ì‹ìœ¼ë¡œ ìŠ¤ì½”ì–´ë¥¼ í™•ì¸\n",
    "# rouge.get_scores(model_out, reference, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3f74b62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:792 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:436 update_state\n        self.build(y_pred, y_true)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:358 build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1376 map_structure_up_to\n        return map_structure_with_tuple_paths_up_to(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1474 map_structure_with_tuple_paths_up_to\n        results = [\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1475 <listcomp>\n        func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1378 <lambda>\n        lambda _, *values: func(*values),  # Discards the path arg.\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:482 _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:482 <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:501 _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    /opt/conda/lib/python3.9/site-packages/keras/metrics.py:3717 get\n        raise ValueError(\n\n    ValueError: Could not interpret metric function identifier: <rouge.rouge.Rouge object at 0x7f96942d5d30>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_113/4055766550.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# gpuë¡œ ëª¨ë¸í•™ìŠµ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/GPU:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train,\n\u001b[0m\u001b[1;32m     19\u001b[0m                        \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                         batch_size=256, callbacks=[es, checkpoint], epochs=50)\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:792 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:436 update_state\n        self.build(y_pred, y_true)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:358 build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1376 map_structure_up_to\n        return map_structure_with_tuple_paths_up_to(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1474 map_structure_with_tuple_paths_up_to\n        results = [\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1475 <listcomp>\n        func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:1378 <lambda>\n        lambda _, *values: func(*values),  # Discards the path arg.\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:482 _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:482 <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:501 _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    /opt/conda/lib/python3.9/site-packages/keras/metrics.py:3717 get\n        raise ValueError(\n\n    ValueError: Could not interpret metric function identifier: <rouge.rouge.Rouge object at 0x7f96942d5d30>\n"
     ]
    }
   ],
   "source": [
    "# compile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=[rouge])\n",
    "\n",
    "# early stop setting\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "# checkpoint setting\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint_filepath = 'abstract_summma_model.keras'\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, \n",
    "                             save_best_only=True, # Save only the best model\n",
    "                             monitor='val_loss')  # Monitor validation loss\n",
    "\n",
    "# gpuë¡œ ëª¨ë¸í•™ìŠµ\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train,\n",
    "                       validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "                        batch_size=256, callbacks=[es, checkpoint], epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4fa55",
   "metadata": {},
   "source": [
    "- ì—ëŸ¬ë¥¼ í•´ì„í•˜ê¸° ì–´ë µë‹¤. í›ˆë ¨ ì´í›„ì— ìŠ¤ì½”ì–´ë¥¼ í™•ì¸í•´ë³¸ë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abc497d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "308/308 [==============================] - 61s 90ms/step - loss: 5.0482 - val_loss: 4.5299\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 27s 88ms/step - loss: 4.5057 - val_loss: 4.3862\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 4.3641 - val_loss: 4.2483\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 27s 88ms/step - loss: 4.1945 - val_loss: 4.0893\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 4.0358 - val_loss: 3.9705\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 27s 88ms/step - loss: 3.8881 - val_loss: 3.8349\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 3.7359 - val_loss: 3.7241\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 27s 88ms/step - loss: 3.6023 - val_loss: 3.6233\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 3.4814 - val_loss: 3.5366\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 27s 88ms/step - loss: 3.3712 - val_loss: 3.4651\n",
      "Epoch 11/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 3.2709 - val_loss: 3.4090\n",
      "Epoch 12/50\n",
      "308/308 [==============================] - 27s 88ms/step - loss: 3.1800 - val_loss: 3.3524\n",
      "Epoch 13/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 3.0968 - val_loss: 3.3122\n",
      "Epoch 14/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 3.0195 - val_loss: 3.2715\n",
      "Epoch 15/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.9482 - val_loss: 3.2372\n",
      "Epoch 16/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.8816 - val_loss: 3.2074\n",
      "Epoch 17/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.8184 - val_loss: 3.1823\n",
      "Epoch 18/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.7582 - val_loss: 3.1602\n",
      "Epoch 19/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.7013 - val_loss: 3.1406\n",
      "Epoch 20/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.6487 - val_loss: 3.1270\n",
      "Epoch 21/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.5985 - val_loss: 3.1131\n",
      "Epoch 22/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.5509 - val_loss: 3.1010\n",
      "Epoch 23/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.5048 - val_loss: 3.0915\n",
      "Epoch 24/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.4611 - val_loss: 3.0815\n",
      "Epoch 25/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.4188 - val_loss: 3.0779\n",
      "Epoch 26/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.3790 - val_loss: 3.0749\n",
      "Epoch 27/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.3413 - val_loss: 3.0678\n",
      "Epoch 28/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.3039 - val_loss: 3.0663\n",
      "Epoch 29/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.2704 - val_loss: 3.0635\n",
      "Epoch 30/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.2347 - val_loss: 3.0648\n",
      "Epoch 31/50\n",
      "308/308 [==============================] - 27s 89ms/step - loss: 2.2035 - val_loss: 3.0661\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "# compile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# early stop setting\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "# checkpoint setting\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint_filepath = 'abstract_summma_model.keras'\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, \n",
    "                             save_best_only=True, # Save only the best model\n",
    "                             monitor='val_loss')  # Monitor validation loss\n",
    "\n",
    "# gpuë¡œ ëª¨ë¸í•™ìŠµ\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train,\n",
    "                       validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "                        batch_size=256, callbacks=[es, checkpoint], epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ddf58a",
   "metadata": {},
   "source": [
    "# Step 9. Visualize training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "26a8dff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label = 'test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7575a9d3",
   "metadata": {},
   "source": [
    "- í…ŒìŠ¤íŠ¸ ì†ì‹¤ê°’ì€ 15ì—í­ ë¶€í„°ëŠ” ê±°ì˜ ì¤„ì–´ë“¤ì§€ì•ŠëŠ”ë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98c8659",
   "metadata": {},
   "source": [
    "## 3) Attention mechanism\n",
    "- ìƒˆë¡œìš´ layerì„ ì„¤ê³„\n",
    "- keras `AdditiveAttention` ì‚¬ìš©\n",
    "- Bahdanau-style attention ì´ë¼ê³  ë¶€ë¥´ê¸°ë„ í•œë‹¤<br>\n",
    "[tensorflow doc](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AdditiveAttention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a3312b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 45)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 45, 128)      3328000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 45, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 45, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1664000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 45, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_3[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 13000)  6669000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 13,500,360\n",
      "Trainable params: 13,500,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# attention layer\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# encoder & decoder's all hidden state of time steps -> attention layer\n",
    "attn_out = attn_layer([decoder_outputs, encoder_output])\n",
    "\n",
    "# connect attention output with decoder's hidden state\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out]) # ë°ì´í„°ì˜ ê°€ì¥ ë’·ì°¨ì›ì— ë¶™ì¸ë‹¤\n",
    "\n",
    "# decoder output layer\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# define model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e069e7a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ğŸ’¡\n",
    "**`Concatenate(axis=-1)`**\n",
    "- ë’¤ì—ì„œë¶€í„° ì¸ë±ì‹±í•˜ëŠ” ë°©ì‹ê³¼ ë™ì¼í•˜ë‹¤\n",
    "- ë§Œì•½ 3ì°¨ì›ì´ë¼ë©´ 2ì°¨ì›ì¶• ë’¤ì— ë¶™ì´ê³ , ë§Œì•½ 2ì°¨ì›ì´ë¼ë©´ 1ì°¨ì› ì¶• ë’¤ì— ë¶™ì¸ë‹¤<br>\n",
    "[blog](https://supermemi.tistory.com/entry/Tensorflow-2-tfconcat-axis-1-0-1-2)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da9510b",
   "metadata": {},
   "source": [
    "- ì•„ë˜ ì¸í¼ëŸ°ìŠ¤ ëª¨ë¸ì„ êµ¬í˜„í•˜ëŠ” ë¶€ë¶„ì—ì„œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ë§Œë“œëŠ” ë¶€ë¶„ì„ ë¹ ëœ¨ë¦¬ê³  ëª¨ë¸í•™ìŠµì„ ì§„í–‰í•œê²ƒì„ í™•ì¸í–ˆë‹¤!!!\n",
    "- ì–´í…ì…˜ë©”ì»¤ë‹ˆì¦˜ì„ í¬í•¨ì‹œí‚¨ ëª¨ë¸ë¡œ ë‹¤ì‹œ í•™ìŠµì§„í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4500951a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "308/308 [==============================] - 44s 125ms/step - loss: 4.0229 - val_loss: 3.3382\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 38s 125ms/step - loss: 3.0377 - val_loss: 3.0849\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 38s 123ms/step - loss: 2.7410 - val_loss: 2.9856\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 38s 124ms/step - loss: 2.5587 - val_loss: 2.9372\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 38s 123ms/step - loss: 2.4247 - val_loss: 2.9098\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 38s 124ms/step - loss: 2.3183 - val_loss: 2.9000\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 38s 124ms/step - loss: 2.2277 - val_loss: 2.8926\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 38s 124ms/step - loss: 2.1480 - val_loss: 2.8892\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 38s 124ms/step - loss: 2.0788 - val_loss: 2.8916\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 38s 124ms/step - loss: 2.0153 - val_loss: 2.8962\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# early stop setting\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "# checkpoint setting\n",
    "checkpoint_filepath = 'abstract_summma_model_attention.keras'\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, \n",
    "                             save_best_only=True, # Save only the best model\n",
    "                             monitor='val_loss')  # Monitor validation loss\n",
    "\n",
    "# gpuë¡œ ëª¨ë¸í•™ìŠµ\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train,\n",
    "                       validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "                        batch_size=256, callbacks=[es, checkpoint], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7b47c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label = 'test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309db3b",
   "metadata": {},
   "source": [
    "- ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ í¬í•¨í•œ ëª¨ë¸ì€ train lossëŠ” ë” ë‚®ê²Œ ë‚˜ì˜¤ì§€ë§Œ test lossëŠ” ê±°ì˜ ë¹„ìŠ·í•œ ê°’ì„ ë³´ì¸ë‹¤\n",
    "- ì‹œê°„ì´ ë˜ë©´ recurrent dropoutë„ ì‹œë„í•´ë´ì•¼ê² ë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08693b",
   "metadata": {},
   "source": [
    "# Step 10. Inference model\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ’¡\n",
    "`Inference`\n",
    "- **í•™ìŠµì„ ë§ˆì¹œ ëª¨ë¸ë¡œ ì‹¤ì œ ê³¼ì œë¥¼ ìˆ˜í–‰í•˜ëŠ” ê²ƒ í˜¹ì€ ê³¼ì •**ì„ ë§í•œë‹¤\n",
    "\n",
    "\n",
    "- seq2seqëŠ” í›ˆë ¨í•  ë•Œì™€ ì¸í¼ëŸ°ìŠ¤ ë‹¨ê³„ì˜ ë°©ì‹ì´ ë‹¤ë¥´ë‹¤ => ëª¨ë¸ ì„¤ê³„ë¥¼ ë³„ë„ë¡œ í•´ì¤˜ì•¼í•œë‹¤\n",
    "- inference ë‹¨ê³„ì—ì„œëŠ” `target ì •ë‹µë°ì´í„°`ê°€ ì—†ë‹¤\n",
    "- ë§Œë“¤ì–´ì•¼í•  ë¬¸ì¥ì˜ ê¸¸ì´ë§Œí¼ ë””ì½”ë”ê°€ ë°˜ë³µ êµ¬ì¡°ë¡œ ë™ì‘í•´ì•¼í•¨\n",
    "- encoder modelê³¼ decoder modelì„ ë¶„ë¦¬í•´ì„œ ì„¤ê³„í•œë‹¤\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 1) Inference - encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3c70f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_output, state_h, state_c])\n",
    "\n",
    "# ì´ì „ ì‹œì ì˜ ìƒíƒœë¥¼ ì €ì¥í•˜ëŠ” í…ì„œ\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h,\n",
    "                                                                            decoder_state_input_c])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ee54a9",
   "metadata": {},
   "source": [
    "- ë¬¸ì¥ì˜ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ì„œ initial stateë¥¼ ì´ì „ ì‹œì ì˜ ìƒíƒœë¡œ ì‚¬ìš©í•œë‹¤\n",
    "    - ë’¤ì˜ í•¨ìˆ˜ decode_sequence()ì—ì„œ êµ¬í˜„\n",
    "- í›ˆë ¨ ê³¼ì •ê³¼ëŠ” ë‹¤ë¥´ê²Œ LSTMì˜ ë¦¬í„´í•˜ëŠ” ì€ë‹‰ìƒíƒœì™€ ì…€ ìƒíƒœì¸ state_h, state_cë¥¼ ë²„ë¦¬ì§€ ì•ŠëŠ”ë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81de4477",
   "metadata": {},
   "source": [
    "## 2) Inference - attention + decoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4288e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# decoder output layer\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat)\n",
    "\n",
    "# decoder model\n",
    "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n",
    "                      [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf22bd2",
   "metadata": {},
   "source": [
    "## `decode_sequence() ì¸í¼ëŸ°ìŠ¤ ë‹¨ê³„ì—ì„œ ë‹¨ì–´ ì‹œí€€ìŠ¤ë¥¼ ì™„ì„±í•˜ëŠ” í•¨ìˆ˜`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "811b3ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # get encoder state from input\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # generate SOS token\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0,0] = tar_word_to_index['sostoken']\n",
    "    \n",
    "    stop_condition=False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition=True ë ë•Œê¹Œì§€ loop\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "        \n",
    "        if (sampled_token != 'eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "            \n",
    "        # if 'reach eos' or 'over max length', stop\n",
    "        if (sampled_token == 'eostoken' or len(decoded_sentence.split()) >= (headlines_max_len - 1)):\n",
    "            stop_condition = True\n",
    "            \n",
    "        \n",
    "        # update target_seq - length 1\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0,0] = sampled_token_index\n",
    "        \n",
    "        # update states\n",
    "        e_h, e_c = h, c\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da048c8c",
   "metadata": {},
   "source": [
    "# Step 11. Test model\n",
    "- ì •ìˆ˜ ì‹œí€€ìŠ¤ë¥¼ í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•´ì•¼ ê²°ê³¼ë¥¼ í™•ì¸í•˜ëŠ”ê²Œ ì¢‹ë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4506d7d",
   "metadata": {},
   "source": [
    "## `seq2text & seq2summary function`\n",
    "- Text int sequence : padding ìˆ«ì 0ì„ ì œì™¸\n",
    "- Summary int seq : ìˆ«ì 0, sos & eos token index ì œì™¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f5bf4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›ë¬¸ì˜ int seq -> text seq\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i != 0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# ìš”ì•½ë¬¸ì˜ int seq -> text seq\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i != 0 and i != tar_word_to_index['sostoken'] and i != tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i]+ ' '\n",
    "    return temp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c100910",
   "metadata": {},
   "source": [
    "## 2) ì‹¤ì œ ìš”ì•½ vs ì˜ˆì¸¡ ìš”ì•½ ë¹„êµ + ROGUE metric\n",
    "- ìœ„ì—ì„œ ì‹œë„í•´ë´¤ë˜ ROGUE ì§€í‘œë¥¼ ì‚¬ìš©í•´ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„° 30ê°œ ìƒ˜í”Œ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d9b2714f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: largest rome stretch kilometres open public seven years restoration laser technology named member roman family house tombs years old depict scenes saints martyrs \n",
      "Original Summary: rome largest with tombs to open after yrs \n",
      "Predicted Summary:  floating building opens in the world\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
      "\n",
      "\n",
      "Original Text: uttar pradesh cm yogi adityanath awarded two lucknow based sisters sharp memory honey singh associated beti bachao beti padhao campaign answer around general knowledge questions within minutes government keep helping sisters ensure well inspire others cm yogi said \n",
      "Original Summary: up cm yogi awards each to sisters for sharp memory \n",
      "Predicted Summary:  up cm yogi adityanath launches his own brain\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.3, 'p': 0.375, 'f': 0.33333332839506175}, 'rouge-2': {'r': 0.2222222222222222, 'p': 0.2857142857142857, 'f': 0.24999999507812506}, 'rouge-l': {'r': 0.3, 'p': 0.375, 'f': 0.33333332839506175}}\n",
      "\n",
      "\n",
      "Original Text: harsh goenka brother rising pune supergiant owner sanjiv goenka trolled twitter earlier criticism ms dhoni player hit sunrisers hyderabad ipl saturday moment silence dhoni apply vera burnt area oh also bother tweeted user \n",
      "Original Summary: rps co owner brother trolled after dhoni hits in ipl \n",
      "Predicted Summary:  stuart broad trolls fans over his tweet on twitter\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
      "\n",
      "\n",
      "Original Text: india muslim mahasangh president ali khan announced would give lakh cash publicly destroy posters mohammad ali jinnah people like khan added pakistan never displayed photos mahatma gandhi freedom fighters indian university display jinnah photo campus \n",
      "Original Summary: muslim org offers lakh for tearing down jinnah poster \n",
      "Predicted Summary:  india should not give free to honour nawaz sharif\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
      "\n",
      "\n",
      "Original Text: actor jim carrey late former girlfriend white accused giving newly discovered note wrote two years suicide note read introduced cocaine prostitutes mental abuse disease good things broke person nnn \n",
      "Original Summary: jim carrey late ex girlfriend accused him of giving \n",
      "Predicted Summary:  actor james bond actor james bond\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
      "\n",
      "\n",
      "Original Text: one first decisions amarinder singh led punjab government decided close liquor shops state government new excise policy also announced slash liquor quota ban sale alcohol within meters national state highways poll manifesto congress promised discourage liquor consumption \n",
      "Original Summary: amarinder singh govt shuts over liquor shops in punjab \n",
      "Predicted Summary:  punjab to impose liquor ban on highways in punjab\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.3333333333333333, 'p': 0.375, 'f': 0.35294117148788934}, 'rouge-2': {'r': 0.125, 'p': 0.125, 'f': 0.1249999950000002}, 'rouge-l': {'r': 0.3333333333333333, 'p': 0.375, 'f': 0.35294117148788934}}\n",
      "\n",
      "\n",
      "Original Text: indian shuttler saina nehwal wished carolina marin speedy recovery marin got injured midway title match indonesia masters sunday way wanted finals injuries worst players unfortunate see best player women badminton face tweeted saina \n",
      "Original Summary: not the way wanted it in the final saina on marin injury \n",
      "Predicted Summary:  saina nehwal shares picture with marin in indonesia\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.2727272727272727, 'p': 0.375, 'f': 0.3157894688088643}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.18181818181818182, 'p': 0.25, 'f': 0.21052631091412755}}\n",
      "\n",
      "\n",
      "Original Text: health ministry clarified mandatory beneficiaries submit aadhaar details seeking lakh health insurance ayushman bharat scheme dubbed use aadhaar authentication purposes added comes media reports claimed applicants submit aadhaar details undergo aadhaar authentication \n",
      "Original Summary: aadhaar not mandatory for lakh insurance under modicare \n",
      "Predicted Summary:  aadhaar mandatory for aadhaar mandatory for aadhaar uidai\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.375, 'p': 0.75, 'f': 0.49999999555555563}, 'rouge-2': {'r': 0.14285714285714285, 'p': 0.25, 'f': 0.18181817719008275}, 'rouge-l': {'r': 0.375, 'p': 0.75, 'f': 0.49999999555555563}}\n",
      "\n",
      "\n",
      "Original Text: pooja bhatt asked half sister alia bhatt relationship ranbir kapoor said let young girl enjoy life think job entertaining india world really well added pooja said alia personal life problem \n",
      "Original Summary: we should let her enjoy pooja on sister alia dating ranbir \n",
      "Predicted Summary:  alia is not to be alia bhatt on alia bhatt\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.18181818181818182, 'p': 0.2857142857142857, 'f': 0.2222222174691359}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.18181818181818182, 'p': 0.2857142857142857, 'f': 0.2222222174691359}}\n",
      "\n",
      "\n",
      "Original Text: least civilians killed saturday government troops allegedly dropped barrel bomb containing poisonous chemicals syria eastern ghouta syrian government denied allegations called reports chemical attack fabrication meanwhile us said would demand immediate response international community reports confirmed \n",
      "Original Summary: civilians killed in suspected chemical attack in syria \n",
      "Predicted Summary:  civilians killed in syria in syria amid avalanche\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.5714285714285714, 'p': 0.6666666666666666, 'f': 0.6153846104142012}, 'rouge-2': {'r': 0.42857142857142855, 'p': 0.5, 'f': 0.4615384565680473}, 'rouge-l': {'r': 0.5714285714285714, 'p': 0.6666666666666666, 'f': 0.6153846104142012}}\n",
      "\n",
      "\n",
      "Original Text: reserve bank india sought fresh applications eligible candidates post chief financial officer however candidates applied earlier may barred applying notably rbi created post cfo first time rank executive director \n",
      "Original Summary: rbi seeks fresh applicants for its new cfo post \n",
      "Predicted Summary:  rbi refuses to allow voluntary to pay for months\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.2222222222222222, 'p': 0.25, 'f': 0.23529411266435996}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.2222222222222222, 'p': 0.25, 'f': 0.23529411266435996}}\n",
      "\n",
      "\n",
      "Original Text: csk sharma saved shot kane williamson going third man boundary six fourth srh chase sunday year old pulled mid air catch flicked ball back falling outside boundary line williamson taking single csk went win match four runs \n",
      "Original Summary: jumps high to save six csk win match by runs \n",
      "Predicted Summary:  fielder sprints to pull off boundary to pull off boundary\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.1, 'p': 0.16666666666666666, 'f': 0.12499999531250018}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.1, 'p': 0.16666666666666666, 'f': 0.12499999531250018}}\n",
      "\n",
      "\n",
      "Original Text: former actress amrita arora took instagram share series pictures videos workout session actress kareena kapoor khan duo seen using bell among exercises videos gym together lose weight together read caption one pictures shared amrita \n",
      "Original Summary: amrita arora shares workout video with kareena kapoor \n",
      "Predicted Summary:  sushant shares pic of making his marriage with karan\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.25, 'p': 0.2222222222222222, 'f': 0.23529411266435996}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.25, 'p': 0.2222222222222222, 'f': 0.23529411266435996}}\n",
      "\n",
      "\n",
      "Original Text: twenty nine indian cities towns including delhi fall severe severe seismic zones according national centre different regions across country classified earthquake zones ii bureau indian standards zone active delhi northern uttar pradesh parts jammu kashmir fall zone iv \n",
      "Original Summary: delhi among cities towns highly vulnerable to quakes \n",
      "Predicted Summary:  thunderstorm warning issued in delhi\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.125, 'p': 0.2, 'f': 0.1538461491124262}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.125, 'p': 0.2, 'f': 0.1538461491124262}}\n",
      "\n",
      "\n",
      "Original Text: blanket plastic ban prevent choking rivers water bodies maharashtra government told bombay high court beaches rivers water bodies flooded plastic also choking drainage systems added court hearing petitions filed several plastic manufacturing associations opposing plastic ban imposed state \n",
      "Original Summary: only full plastic ban can stop choking of rivers maha to hc \n",
      "Predicted Summary:  plastic waste found in plastic water to avoid pollution\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.16666666666666666, 'p': 0.25, 'f': 0.1999999952000001}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.16666666666666666, 'p': 0.25, 'f': 0.1999999952000001}}\n",
      "\n",
      "\n",
      "Original Text: year old female trainee constable hanged death telangana state police academy saturday committed suicide receiving information friend police constable suicide police said colleagues admitting feeling depressed later found hanging noose room \n",
      "Original Summary: female trainee constable hangs herself at telangana academy \n",
      "Predicted Summary:  class student commits suicide in telangana\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.125, 'p': 0.16666666666666666, 'f': 0.14285713795918387}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.125, 'p': 0.16666666666666666, 'f': 0.14285713795918387}}\n",
      "\n",
      "\n",
      "Original Text: indian air force chief bs dhanoa sunday said cause concern rapid pace modernisation induction new equipment neighbourhood however iaf capable countering effectively iaf well equipped take threats occur border added iaf prepared threat said \n",
      "Original Summary: concerned by rate in iaf chief \n",
      "Predicted Summary:  new iaf chief may have been capable of war crimes\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.3333333333333333, 'p': 0.2, 'f': 0.24999999531250006}, 'rouge-2': {'r': 0.2, 'p': 0.1111111111111111, 'f': 0.14285713826530627}, 'rouge-l': {'r': 0.3333333333333333, 'p': 0.2, 'f': 0.24999999531250006}}\n",
      "\n",
      "\n",
      "Original Text: external affairs minister sushma swaraj tuesday announced rule requiring married couples present marriage certificate passports scrapped following complaints married men women divorced women complained required fill name ex husband children estranged father changed rule added \n",
      "Original Summary: marriage certificates no longer needed for passports swaraj \n",
      "Predicted Summary:  un marriage marriage marriage can be allowed to marriage\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.125, 'p': 0.16666666666666666, 'f': 0.14285713795918387}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.125, 'p': 0.16666666666666666, 'f': 0.14285713795918387}}\n",
      "\n",
      "\n",
      "Original Text: republican senator graham said us president donald trump told would rather go war destroy north korea allow develop nuclear armed missiles adding prefers diplomatic approach solve north korean threat graham claimed military option destroy north korea programme north korea \n",
      "Original Summary: donald trump ready for war with north korea us senator \n",
      "Predicted Summary:  us should not allow nukes if it is not doing nuclear war trump\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.3, 'p': 0.25, 'f': 0.27272726776859507}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.1, 'p': 0.08333333333333333, 'f': 0.09090908595041348}}\n",
      "\n",
      "\n",
      "Original Text: minister state water resources vijay goel monday apprised parliament water ganga unfit bathing parts haridwar notably haridwar hindu site pilgrims go wash away sins ganga ashes loved ones pm modi allotted crore namami gange programme \n",
      "Original Summary: ganga water unfit for bathing in parts of govt \n",
      "Predicted Summary:  ganga clean ganga river to be cleaned by\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.1111111111111111, 'p': 0.14285714285714285, 'f': 0.12499999507812519}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.1111111111111111, 'p': 0.14285714285714285, 'f': 0.12499999507812519}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through the range \n",
    "for i in range(10, 30):\n",
    "    original_text = seq2text(encoder_input_test[i])\n",
    "    original_summary = seq2summary(decoder_input_test[i])\n",
    "    predicted_summary = decode_sequence(encoder_input_test[i].reshape(1, text_max_len))\n",
    "\n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scores = rouge.get_scores(predicted_summary, original_summary, avg=True)\n",
    "\n",
    "    print('Original Text:', original_text)\n",
    "    print('Original Summary:', original_summary)\n",
    "    print('Predicted Summary:', predicted_summary)\n",
    "    print('ROUGE Scores:', rouge_scores)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d76f59",
   "metadata": {},
   "source": [
    "- ìš”ì•½ë³¸ì„ ë´¤ì„ë•Œ ì œëŒ€ë¡œ ìš”ì•½ì´ ë˜ì§€ ëª»í•œê²ƒ ê°™ë‹¤ (ì‚¬ì‹¤ ì—‰ë§ì¸ê²ƒ ê°™ë‹¤..?)\n",
    "- ROUGE scoreë„ í•´ì„í•´ë³´ê³ ì‹¶ì€ë° ì–´ë–»ê²Œ í•´ì„í•´ì•¼í•˜ëŠ”ì§€ ëª¨ë¥´ê² ë‹¤. \n",
    "- gpt ë„ì›€ì„ ë°›ì•„ë³¸ë‹¤\n",
    "\n",
    "> - **rouge-1**: **The F1 score is relatively low (0.2727)**, indicating a moderate balance between precision and recall. Improvement in both precision and recall could enhance the model's performance.<br>\n",
    "> - **rouge-2**: The scores for bigrams are all zero, suggesting that **the model is not capturing two-word sequences well. This might be an area for improvement**.<br>\n",
    "> - **rouge-l**: **The F1 score is relatively low (0.0909)**. It measures **the longest common subsequence, and a higher score indicates a better match**. Improvement in both precision and recall for this metric could be beneficial.\n",
    "\n",
    "\n",
    "- ì•„ì£¼ ë” ì„±ëŠ¥ê°œì„ ì´ í•„ìš”í•˜ë‹¤!\n",
    "- ì‹œê°„ì´ ëœë‹¤ë©´ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì‚¬ìš©í•´ë³´ê³ ì‹¶ë‹¤!\n",
    "\n",
    "\n",
    "**ì°¸ê³ **\n",
    "- [blog](https://huffon.github.io/2019/12/07/rouge/)\n",
    "- [blog](https://sooftware.io/metric/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a2ba4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ğŸ’¡\n",
    "# ì„±ëŠ¥ê°œì„ ì„ í•˜ë ¤ë©´!\n",
    "- seq2seq + attention ì¡°í•©ì„ ë” ì¢‹ê²Œ ìˆ˜ì •\n",
    "- beam search ë¹”ì„œì¹˜\n",
    "- pre-trained word embedding\n",
    "- transformer : encoder + decoder ìì²´ êµ¬ì¡°ë¥¼ ìƒˆë¡­ê²Œ í•¨\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d287b08",
   "metadata": {},
   "source": [
    "# `ì¶”ì¶œì  ìš”ì•½`\n",
    "- ì´ë¯¸ ë³¸ë¬¸ì—ì„œ ì¡´ì¬í•˜ëŠ” ë‹¨ì–´êµ¬, ë¬¸ì¥ì„ ë½‘ì•„ì„œ ìš”ì•½\n",
    "- íŒ¨í‚¤ì§€ [`Summa`](https://summanlp.github.io/textrank/)ì˜ `summarize` ëª¨ë“ˆì„ í™œìš©í•´ì„œ ì‹¤ìŠµ<br>\n",
    "[ì°¸ê³ ] [Summa NLP](https://github.com/summanlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7c7ec5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summa                             1.2.0\r\n"
     ]
    }
   ],
   "source": [
    "# summa install check \n",
    "!pip list | grep summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a60409d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7111a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data - ì¶”ì¶œì ìš”ì•½ì„ ìœ„í•œ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ë§Œë“ ë‹¤\n",
    "data_for_summa = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cf5fbce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3377</th>\n",
       "      <td>Threat to Goa CM's life due to Rafale files: C...</td>\n",
       "      <td>Goa Congress on Saturday wrote to President Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83123</th>\n",
       "      <td>Adnan Sami to make Bollywood acting debut</td>\n",
       "      <td>Singer Adnan Sami is set to make his acting de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75241</th>\n",
       "      <td>Virus-free pigs cloned for safer transplants f...</td>\n",
       "      <td>US-based scientists aiming to make pig organs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5321</th>\n",
       "      <td>Rahul plays chess with differently abled child...</td>\n",
       "      <td>Congress President Rahul Gandhi played chess w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58298</th>\n",
       "      <td>300 engineering colleges to be shut down over ...</td>\n",
       "      <td>Around 300 private engineering colleges which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57592</th>\n",
       "      <td>Scientists unveil duck dinosaur that could run...</td>\n",
       "      <td>The study of a 75-million-year-old fossil smug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43212</th>\n",
       "      <td>Vidarbha win Irani Cup after posting 800 in 1s...</td>\n",
       "      <td>Vidarbha claimed the Irani Cup trophy after po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64548</th>\n",
       "      <td>Which were the most polluted cities in India o...</td>\n",
       "      <td>Rajasthan's Bhiwadi was the most polluted city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24377</th>\n",
       "      <td>Body of newborn with paper stuffed in mouth fo...</td>\n",
       "      <td>The body of a newborn was found with toilet pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53909</th>\n",
       "      <td>Redditor makes joke on Trump claiming credit, ...</td>\n",
       "      <td>A Redditor made a joke crediting Trump for com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "3377   Threat to Goa CM's life due to Rafale files: C...   \n",
       "83123          Adnan Sami to make Bollywood acting debut   \n",
       "75241  Virus-free pigs cloned for safer transplants f...   \n",
       "5321   Rahul plays chess with differently abled child...   \n",
       "58298  300 engineering colleges to be shut down over ...   \n",
       "57592  Scientists unveil duck dinosaur that could run...   \n",
       "43212  Vidarbha win Irani Cup after posting 800 in 1s...   \n",
       "64548  Which were the most polluted cities in India o...   \n",
       "24377  Body of newborn with paper stuffed in mouth fo...   \n",
       "53909  Redditor makes joke on Trump claiming credit, ...   \n",
       "\n",
       "                                                    text  \n",
       "3377   Goa Congress on Saturday wrote to President Ra...  \n",
       "83123  Singer Adnan Sami is set to make his acting de...  \n",
       "75241  US-based scientists aiming to make pig organs ...  \n",
       "5321   Congress President Rahul Gandhi played chess w...  \n",
       "58298  Around 300 private engineering colleges which ...  \n",
       "57592  The study of a 75-million-year-old fossil smug...  \n",
       "43212  Vidarbha claimed the Irani Cup trophy after po...  \n",
       "64548  Rajasthan's Bhiwadi was the most polluted city...  \n",
       "24377  The body of a newborn was found with toilet pa...  \n",
       "53909  A Redditor made a joke crediting Trump for com...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data\n",
    "data_for_summa.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3003ff8",
   "metadata": {},
   "source": [
    "- text ë°ì´í„°ë§Œ í™œìš©í•´ì„œ ì¶”ì¶œì ìš”ì•½ì„ ì§„í–‰í•œë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58733bbb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ğŸ’¡\n",
    "\n",
    "## `summarize()`\n",
    "\n",
    "**Summa ì˜ summarize() ì¸ìë“¤**\n",
    "> text (str) : ìš”ì•½í•  í…ŒìŠ¤íŠ¸<br>\n",
    "ratio (float, optional) â€“ ìš”ì•½ë¬¸ì—ì„œ ì›ë³¸ì—ì„œ ì„ íƒë˜ëŠ” ë¬¸ì¥ ë¹„ìœ¨. 0~1 ì‚¬ì´ê°’<br>\n",
    "words (int or None, optional) â€“ ì¶œë ¥ì— í¬í•¨í•  ë‹¨ì–´ ìˆ˜<br>\n",
    "ë§Œì•½, ratioì™€ í•¨ê»˜ ë‘ íŒŒë¼ë¯¸í„°ê°€ ëª¨ë‘ ì œê³µë˜ëŠ” ê²½ìš° ratioëŠ” ë¬´ì‹œí•œë‹¤<br>\n",
    "split (bool, optional) â€“ Trueë©´ ë¬¸ì¥ list / FalseëŠ” ì¡°ì¸(join)ëœ ë¬¸ìì—´ì„ ë°˜í™˜<br>\n",
    "\n",
    "\n",
    "- ë¬¸ì¥ í† í°í™”ë¥¼ ë³„ë„ë¡œ í•˜ì§€ ì•Šì•„ë„ ë‚´ë¶€ì ìœ¼ë¡œ ë¬¸ì¥í† í°í™”ë¥¼ ìˆ˜í–‰\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4eabd2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for row 32572:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 35185:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 59998:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 64666:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 15344:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 52899:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 95150:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 76916:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 49399:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 74037:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 87659:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 73015:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 73027:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 37832:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 23956:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 81908:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 4625:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 70369:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 23375:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 87882:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 20748:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 25890:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 59976:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 93365:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 97870:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 1802:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 81625:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 29700:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 9925:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 62050:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 46057:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 93064:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 19879:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 85994:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 71002:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 25803:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 75312:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 53944:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 68956:\n",
      "\n",
      "\n",
      "\n",
      "Summary for row 17567:\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Randomly select 40 texts\n",
    "random_sample = data_for_summa.sample(n=40, random_state=42)\n",
    "\n",
    "# iterate through the rows and print the summarized text\n",
    "for index, row in random_sample.iterrows():\n",
    "    text_to_summarize = row['text']  # text \n",
    "    \n",
    "    # check if the text is not empty\n",
    "    if isinstance(text_to_summarize, str) and len(text_to_summarize.strip()) > 0:\n",
    "        summarized_text = summarize(text_to_summarize, ratio=0.005) # ì›ë¬¸ì„ ë°”ë¡œ ë„£ê³ , ìš”ì•½ë¬¸ìœ¼ë¡œ ì„ íƒí•˜ëŠ” ë¬¸ì¥ê°œìˆ˜ëŠ” ì›ë¬¸ì˜ 0.005%ë¡œ ì„¤ì •\n",
    "        \n",
    "        # Print the summary for each text\n",
    "        print(f'Summary for row {index + 1}:')\n",
    "        print(summarized_text)\n",
    "        print('\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44298eb3",
   "metadata": {},
   "source": [
    "- ìš”ì•½ëœ ë°ì´í„°ê°€ ì¶œë ¥ë˜ì§€ì•ŠëŠ”ë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dbf9366c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
       "1    Kunal Shah's credit card bill payment platform...\n",
       "2    New Zealand defeated India by 8 wickets in the...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text data\n",
    "text_data = data_for_summa['text']\n",
    "\n",
    "# check data\n",
    "text_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fa5dec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# summarize 1 row data\n",
    "print('Summary:')\n",
    "print(summarize(text_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73fe56f",
   "metadata": {},
   "source": [
    "- ì•„! ì§€ê¸ˆ ë°ì´í„°ëŠ” object íƒ€ì…ì´ë¼ì„œ ì•ˆë˜ëŠ”ê±¸ì§€ë„ ëª¨ë¥´ê² ë‹¤\n",
    "- str íƒ€ì…ìœ¼ë¡œ ë³€í™˜ì‹œë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fc77574f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
       "1    Kunal Shah's credit card bill payment platform...\n",
       "2    New Zealand defeated India by 8 wickets in the...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text data which dtype is str\n",
    "text_data = data_for_summa['text'].astype(str)\n",
    "\n",
    "# check data\n",
    "text_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8cd42d7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_113/3688227157.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "example = text_data[0].astype(str)\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf2a40c",
   "metadata": {},
   "source": [
    "- ê°•í›ˆë‹˜ ë„ì›€ì„ ë°›ì•„ì„œ ì½”ë“œë¥¼ ìˆ˜ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "738f49f7",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32571</th>\n",
       "      <td>K'taka students to get extra marks if parents ...</td>\n",
       "      <td>Students in Karnataka will get extra marks if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35184</th>\n",
       "      <td>Syria shoots down missiles fired at two air bases</td>\n",
       "      <td>Syrian anti-aircraft defences on Monday shot d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>Dinosaur-like animal's fossil found in Uttarak...</td>\n",
       "      <td>A Dinosaur-like creature's fossil was found du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64665</th>\n",
       "      <td>UP may merge Shia, Sunni Waqf boards to preven...</td>\n",
       "      <td>The Uttar Pradesh government is planning to fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15343</th>\n",
       "      <td>Egypt actress gets 2 yrs jail for 'fake news' ...</td>\n",
       "      <td>Egyptian activist-actress Amal Fathy has been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52898</th>\n",
       "      <td>Jeff Bezos added more wealth in 2017 than GDP ...</td>\n",
       "      <td>World's richest person and Amazon CEO Jeff Bez...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95149</th>\n",
       "      <td>Bangladeshi captain Mortaza announces retireme...</td>\n",
       "      <td>Bangladesh cricket team's limited overs captai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76915</th>\n",
       "      <td>Mexican drug lord El Chapo questions US extrad...</td>\n",
       "      <td>Mexican drug lord Joaquin 'El Chapo' Guzman ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49398</th>\n",
       "      <td>N Korea supplies ballistic missiles to Myanmar...</td>\n",
       "      <td>Independent United Nations (UN) monitors have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74036</th>\n",
       "      <td>Thenga mila hamme: Harbhajan responds to home ...</td>\n",
       "      <td>After reports of three Amrapali Group companie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "32571  K'taka students to get extra marks if parents ...   \n",
       "35184  Syria shoots down missiles fired at two air bases   \n",
       "59997  Dinosaur-like animal's fossil found in Uttarak...   \n",
       "64665  UP may merge Shia, Sunni Waqf boards to preven...   \n",
       "15343  Egypt actress gets 2 yrs jail for 'fake news' ...   \n",
       "52898  Jeff Bezos added more wealth in 2017 than GDP ...   \n",
       "95149  Bangladeshi captain Mortaza announces retireme...   \n",
       "76915  Mexican drug lord El Chapo questions US extrad...   \n",
       "49398  N Korea supplies ballistic missiles to Myanmar...   \n",
       "74036  Thenga mila hamme: Harbhajan responds to home ...   \n",
       "\n",
       "                                                    text  \n",
       "32571  Students in Karnataka will get extra marks if ...  \n",
       "35184  Syrian anti-aircraft defences on Monday shot d...  \n",
       "59997  A Dinosaur-like creature's fossil was found du...  \n",
       "64665  The Uttar Pradesh government is planning to fo...  \n",
       "15343  Egyptian activist-actress Amal Fathy has been ...  \n",
       "52898  World's richest person and Amazon CEO Jeff Bez...  \n",
       "95149  Bangladesh cricket team's limited overs captai...  \n",
       "76915  Mexican drug lord Joaquin 'El Chapo' Guzman ha...  \n",
       "49398  Independent United Nations (UN) monitors have ...  \n",
       "74036  After reports of three Amrapali Group companie...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 40 texts\n",
    "random_sample = data_for_summa.sample(n=40, random_state=42)\n",
    "random_sample[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9dc40f81",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_113/549980538.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# index ì–»ê¸° ì‹œë„\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandom_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Index: {index}, Values: {row}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "# index ì–»ê¸° ì‹œë„\n",
    "for index, row in random_sample['text'].iterrows():\n",
    "    print(f'Index: {index}, Values: {row}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "886573c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([32571, 35184, 59997, 64665, 15343, 52898, 95149, 76915, 49398,\n",
       "            74036, 87658, 73014, 73026, 37831, 23955, 81907,  4624, 70368,\n",
       "            23374, 87881, 20747, 25889, 59975, 93364, 97869,  1801, 81624,\n",
       "            29699,  9924, 62049, 46056, 93063, 19878, 85993, 71001, 25802,\n",
       "            75311, 53943, 68955, 17566],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index ì–»ê¸° ì‹œë„ 2\n",
    "random_sample_idx = random_sample['text'].index\n",
    "random_sample_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3c9165b8",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 13370\n",
      "Original Text: Sushmita Sen is dating model Rohman Shawl whom she had met at a fashion event in August, as per reports. Rohman was spotted cheering for Sushmita at Neeta Lulla's fashion show a few days ago where he was also seen interacting with Sushmita's daughters Renee and Alisah, reports suggested. Sushmita was earlier said to be dating hotelier Ritik Bhasin. \n",
      "Predicted Summary: Sushmita Sen is dating model Rohman Shawl whom she had met at a fashion event in August, as per reports.\n",
      "ROUGE F1 Score: 0.5714285673469389\n",
      "\n",
      "\n",
      "index: 24057\n",
      "Original Text: Micro-blogging site Twitter on Friday revealed its earnings for the second quarter of 2018 where it stated that its monthly active users dropped from 336 million in Q1 to 335 million in Q2. The company saw revenue of $711 million, up from $665 million in the last quarter. Twitter reported a net income of $100 million, its third-straight profitable quarter.\n",
      "Predicted Summary: Twitter reported a net income of $100 million, its third-straight profitable quarter.\n",
      "ROUGE F1 Score: 0.41379310016646853\n",
      "\n",
      "\n",
      "index: 42500\n",
      "Original Text: The Centre on Wednesday cleared a plan to set up an Indian Air Force (IAF) base close to Gujarat's Deesa near India's border with Pakistan. Reportedly, the PM Narendra Modi-led Cabinet Committee on Security (CCS) cleared the plan to extend the runway, build fighter-pens, and administrative facilities, with an initial investment of around ÃƒÂ¢Ã‚Â‚Ã‚Â¹1,000 crore.\n",
      "Predicted Summary: The Centre on Wednesday cleared a plan to set up an Indian Air Force (IAF) base close to Gujarat's Deesa near India's border with Pakistan.\n",
      "ROUGE F1 Score: 0.6857142812081632\n",
      "\n",
      "\n",
      "index: 67384\n",
      "Original Text: A Chandigarh court has rejected a surrender plea of former Punjab minister Sucha Langah, who is accused of raping a woman for nearly a decade. The court directed him to go to Punjab's Gurdaspur town where the rape and cheating cases were registered against him. The Punjab Police has been conducting raids across the state to arrest him.  \n",
      "Predicted Summary: The court directed him to go to Punjab's Gurdaspur town where the rape and cheating cases were registered against him.\n",
      "ROUGE F1 Score: 0.5538461498414202\n",
      "\n",
      "\n",
      "index: 9404\n",
      "Original Text: A selfie has saved a US man from a possible prison sentence of 99 years. Cristopher Precopia's ex-girlfriend had accused him of breaking into her home on September 20, 2017, and carving an \"X\" below her neck using a box cutter. However, the selfie taken by Precopia's mother proved he was at a hotel, 70 miles from the accuser's home.\n",
      "Predicted Summary: However, the selfie taken by Precopia's mother proved he was at a hotel, 70 miles from the accuser's home.\n",
      "ROUGE F1 Score: 0.5294117608131489\n",
      "\n",
      "\n",
      "index: 81670\n",
      "Original Text: Yale researchers have identified 60 potential new \"hot Jupiters\", a class of Jupiter-like giant gas planets which complete an orbit around host star within a week due to their proximity. The discovery was made by studying reflected signals in observations of over 1,40,000 stars by NASA's Kepler spacecraft. Reflected light signals hold rich information about planets' atmospheres, researchers said.\n",
      "Predicted Summary: Reflected light signals hold rich information about planets' atmospheres, researchers said.\n",
      "ROUGE F1 Score: 0.33846153564970416\n",
      "\n",
      "\n",
      "index: 96525\n",
      "Original Text: The government had reportedly rejected the proposal to felicitate cricketer MS Dhoni, journalist Arnab Goswami, spiritual leader Gurmeet Ram Rahim Singh, music composer Anu Malik and others with Padma awards. NCP leader Sharad Pawar and BJP leader Murli Manohar Joshi were awarded Padma Vibhushan under the \"public affairs\" category, which falls under the government's discretion, a report said.\n",
      "Predicted Summary: The government had reportedly rejected the proposal to felicitate cricketer MS Dhoni, journalist Arnab Goswami, spiritual leader Gurmeet Ram Rahim Singh, music composer Anu Malik and others with Padma awards.\n",
      "ROUGE F1 Score: 0.7407407360768176\n",
      "\n",
      "\n",
      "index: 30846\n",
      "Original Text: A 10-year-old girl was allegedly raped and murdered during a wedding last week in Madhya Pradesh's Umaria district, the police said on Wednesday. The minor, who was visiting her grandmother's house for a wedding, disappeared after falling off to sleep on May 13. Her body was later found strangled to death with her scarf. \n",
      "Predicted Summary: A 10-year-old girl was allegedly raped and murdered during a wedding last week in Madhya Pradesh's Umaria district, the police said on Wednesday.\n",
      "ROUGE F1 Score: 0.6388888845408951\n",
      "\n",
      "\n",
      "index: 73029\n",
      "Original Text: US-based cab-hailing startup Uber launched in-app messaging feature along with multi-destination rides for users in India. The feature aims to help riders and drivers get in touch without incurring call charges or sharing their contact numbers. The in-app chat for both iOS and Android has been updated and also supports a number of local languages. \n",
      "Predicted Summary: The in-app chat for both iOS and Android has been updated and also supports a number of local languages.\n",
      "ROUGE F1 Score: 0.5373134289062153\n",
      "\n",
      "\n",
      "index: 52230\n",
      "Original Text: The Unique Identification Authority of India (UIDAI) on Monday announced the introduction of face authentication feature for Aadhaar users by July 1, 2018. This feature will help all elderly or others facing issues with fingerprint authentication, the UIDAI said. The feature must be combined with either fingerprint, iris scan, or OTP for successful authentication of an Aadhaar number.\n",
      "Predicted Summary: This feature will help all elderly or others facing issues with fingerprint authentication, the UIDAI said.\n",
      "ROUGE F1 Score: 0.5079365041471403\n",
      "\n",
      "\n",
      "index: 9834\n",
      "Original Text: Myntra CEO Ananth Narayanan has said all of Jabong's functions will be integrated with the company and about 10% of the combined workforce would be cut. Myntra and Jabong will operate as distinct brands but will be run by one team. Following Binny Bansal's resignation as Flipkart Group CEO, Walmart said Narayanan will report to Flipkart CEO Kalyan Krishnamurthy.\n",
      "Predicted Summary: Myntra CEO Ananth Narayanan has said all of Jabong's functions will be integrated with the company and about 10% of the combined workforce would be cut.\n",
      "ROUGE F1 Score: 0.6764705837586505\n",
      "\n",
      "\n",
      "index: 22931\n",
      "Original Text: A woman in Gujarat has alleged her live-in partner forced her to remove two front teeth to avoid male attention. She added he suspected her of seeing someone else and made her sit beside him all day while he worked as an autorickshaw driver. This was discovered when she jumped out of the autorickshaw one day and passersby alerted authorities.\n",
      "Predicted Summary: She added he suspected her of seeing someone else and made her sit beside him all day while he worked as an autorickshaw driver.\n",
      "ROUGE F1 Score: 0.602739721816476\n",
      "\n",
      "\n",
      "index: 19631\n",
      "Original Text: French female tennis player Alize Cornet was punished by the on-court official at the US Open 2018 for taking her top off and exposing her black bra during her mid-match 10-minute heat break. After walking back to court following her break, Cornet realised that she had worn her top backwards before taking it off to wear it properly.\n",
      "Predicted Summary: French female tennis player Alize Cornet was punished by the on-court official at the US Open 2018 for taking her top off and exposing her black bra during her mid-match 10-minute heat break.\n",
      "ROUGE F1 Score: 0.7792207744644967\n",
      "\n",
      "\n",
      "index: 76864\n",
      "Original Text: A US-based study has found elements heavier than iron may have been formed by interactions between primordial black holes and neutron stars. A neutron-rich environment was needed to forge such elements, scientists said, which was formed by black holes devouring neutron stars. This finding is consistent with paucity of neutron stars in galactic centres with high black hole density.\n",
      "Predicted Summary: A US-based study has found elements heavier than iron may have been formed by interactions between primordial black holes and neutron stars.\n",
      "ROUGE F1 Score: 0.6376811550766647\n",
      "\n",
      "\n",
      "index: 92696\n",
      "Original Text: Three different coloured crater lakes at the summit of Mount Kelimutu volcano in Indonesia change their colour. It is believed that minerals in the water interact with volcanic gas to create different shades. According to a local belief, the lakes are a resting place for departed souls, and those who die are sent to different lakes depending on their merits.\n",
      "Predicted Summary: Three different coloured crater lakes at the summit of Mount Kelimutu volcano in Indonesia change their colour.\n",
      "ROUGE F1 Score: 0.5230769192142012\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Hypothesis is empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_113/2238828765.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ì›ë¬¸ì„ ë°”ë¡œ ë„£ê³ , ìš”ì•½ë¬¸ìœ¼ë¡œ ì„ íƒí•˜ëŠ” ë¬¸ì¥ê°œìˆ˜ëŠ” ì›ë¬¸ì˜ 50%ë¡œ ì„¤ì •\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Calculate ROUGE scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrouge_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Extract only the F1 score from the ROUGE scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/rouge/rouge.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(self, hyps, refs, avg, ignore_empty)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_avg_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/rouge/rouge.py\u001b[0m in \u001b[0;36m_get_avg_scores\u001b[0;34m(self, hyps, refs)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAVAILABLE_METRICS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                 \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclusive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexclusive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/rouge/rouge.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(hyp, ref, **k)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mDEFAULT_METRICS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"rouge-1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rouge-2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rouge-l\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     AVAILABLE_METRICS = {\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;34m\"rouge-1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrouge_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouge_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;34m\"rouge-2\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrouge_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouge_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;34m\"rouge-3\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrouge_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouge_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/rouge/rouge_score.py\u001b[0m in \u001b[0;36mrouge_n\u001b[0;34m(evaluated_sentences, reference_sentences, n, raw_results, exclusive)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \"\"\"\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluated_sentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hypothesis is empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_sentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reference is empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Hypothesis is empty."
     ]
    }
   ],
   "source": [
    "# iterate through the rows and print the summarized text\n",
    "for idx, text in enumerate(random_sample['text']):\n",
    "    summary = summarize(text, ratio=0.5) # ì›ë¬¸ì„ ë°”ë¡œ ë„£ê³ , ìš”ì•½ë¬¸ìœ¼ë¡œ ì„ íƒí•˜ëŠ” ë¬¸ì¥ê°œìˆ˜ëŠ” ì›ë¬¸ì˜ 50%ë¡œ ì„¤ì •\n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scores = rouge.get_scores(summary, text, avg=True)\n",
    "    \n",
    "    # Extract only the F1 score from the ROUGE scores\n",
    "    f1_score = rouge_scores['rouge-1']['f']\n",
    "    \n",
    "    # Print the summary for each text\n",
    "    print('index:', random_sample_idx[idx])\n",
    "    print('Original Text:', text)\n",
    "    print('Predicted Summary:', summary)\n",
    "    print('ROUGE F1 Score:', f1_score)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404121a2",
   "metadata": {},
   "source": [
    "**formula for F1 score**\n",
    "$$F1 = \\frac{2â‹…Precisionâ‹…Recall}{Precision+Recall}$$\n",
    "\n",
    "\n",
    "- f1 scoreê°€ ë†’ì„ìˆ˜ë¡ ê³¼í•œ ì¤‘ë³µì—†ì´ ìš”ì•½ì´ ë§ì€ ê´€ë ¨ ì •ë³´ë¥¼ ìº¡ì²˜í•´ì„œ ì¢‹ì€ ìš”ì•½ì„ ë§Œë“¤ì—ˆë‹¤ëŠ”ê±¸ ì˜ë¯¸í•œë‹¤ê³  í•œë‹¤.\n",
    "- ëŒ€ì²´ë¡œ `0.5` ì„ ë§´ë„ëŠ” ì ìˆ˜ë¥¼ ë³´ì—¬ì¤€ë‹¤.\n",
    "- í™•ì‹¤íˆ ì¶”ì¶œì ìš”ì•½ì´ ì¶”ìƒì ìš”ì•½ë³´ë‹¤ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤€ë‹¤\n",
    "\n",
    "\n",
    "- íšŒê³ ë¥¼ ë¯¸ë¦¬ ì¨ë‘ê³  íŠ¸ëœìŠ¤í¬ë¨¸ ì‚¬ìš©ì„ ì‹œë„í•´ë³¸ë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355fb916",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "- NLP ë‚´ìš©ì€ ìŠì€ì§€ ì˜¤ë˜ëœ ì‹œì ì—ì„œ ëª¨ë¸ì„ êµ¬í˜„í•´ì„œ ê²°ê³¼ê°’ì„ í™•ì¸í•˜ê³ , í•´ì„ê¹Œì§€ í•˜ëŠ” ì‘ì—…ì„ í•˜ë‹ˆ êµ‰ì¥íˆ í˜ë“¤ê³  ì–´ë ¤ì› ë‹¤.\n",
    "- ìµœëŒ€í•œ ì–´ë–¤ í”Œë¡œìš°ë¡œ ì§„í–‰ë˜ëŠ”ì§€ íŒŒì•…í•œë‹¤ëŠ” ê¸°ë¶„ìœ¼ë¡œ ì§„í–‰í–ˆê³ , ì–´ë–¤ ê°œë…ì„ ê³µë¶€í•´ì•¼í• ì§€ í™•ì¸í•œë‹¤ê³  ìƒê°í•˜ë‹ˆ ë§ˆìŒì´ í•œê²° ê°€ë²¼ì›Œì¡Œë‹¤.\n",
    "- CVë„ ë°ì´í„° ì „ì²˜ë¦¬ê°€ ì¤‘ìš”í–ˆì§€ë§Œ NLPëŠ” í›¨ì”¬ ë” ë°ì´í„°ì „ì²˜ë¦¬ê°€ ì¤‘ìš”í•˜ë‹¤ê³  ëŠê»´ì¡Œê³ , ì—”ì§€ë‹ˆì–´ì˜ ì—­í• ì´ ì¤‘ìš”í•œê²ƒì²˜ëŸ¼ ëŠê»´ì§„ë‹¤.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# KPT\n",
    "\n",
    "**[KEEP]**\n",
    "- ì´ˆë°˜ì— ìˆ˜ì¹˜ê°’ì´ ë§ì´ ë‚˜ì™€ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ë¥´ë¥´ ë§ì´ ë°›ì•˜ê³ , ë„ˆë¬´ ìƒì†Œí•œ ë‚´ìš©ë“¤ì´ë¼ ì–´ë ¤ì› ëŠ”ë° ë§ˆì¸ë“œì»¨íŠ¸ë¡¤ì„ í•˜ë©° í•™ìŠµí–ˆë‹¤.\n",
    "\n",
    "\n",
    "**[PROBLEM]**\n",
    "- ë°ì´í„°í”„ë ˆì„ í™œìš©í•˜ëŠ” ë°©ë²•ì„ ë§ì´ ìŠì–´ì„œ ì–´ë–»ê²Œ ë°ì´í„°ë¥¼ ë‹¤ë¤„ì•¼í•˜ëŠ”ì§€ ì¢€ í—¤ë§¸ë‹¤. \n",
    "- í‰ê°€ì§€í‘œì— ëŒ€í•œ ì •ë¦¬ê°€ ì•ˆë˜ì–´ìˆì–´ì„œ ROUGE ê°’ì´ í¬ë©´ ì¢‹ì€ê±´ì§€, ì‘ìœ¼ë©´ ì¢‹ì€ê±´ì§€ í•´ì„í•˜ëŠ”ê²Œ ì–´ë ¤ì› ë‹¤.\n",
    "- ìˆ«ì ë°ì´í„°ê°€ ë§ì´ ë‚˜ì™”ëŠ”ë° CVì™€ ë‹¤ë¥´ê²Œ ì œëŒ€ë¡œ ë‚˜ì˜¨ê±´ì§€ í™•ì¸í• ìˆ˜ê°€ ì—†ì–´ì„œ ìì‹ ì´ ì—†ì—ˆë‹¤.\n",
    "\n",
    "\n",
    "**[TRY]**\n",
    "- í‹ˆí‹ˆì´ íŒë‹¤ìŠ¤ ë°ì´í„°í”„ë ˆì„ ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤.\n",
    "- ì´í›„ ë…¸ë“œì—ì„œ ë‚˜ì˜¤ëŠ” NLPë¶€ë¶„ì—ì„œëŠ” ê´€ë ¨ ìë£Œë„ í•¨ê»˜ ì½ì–´ë³´ê³  ë” ê¼¼ê¼¼í•˜ê²Œ ê³µë¶€í•´ë³¸ë‹¤\n",
    "- í‰ê°€ì§€í‘œ ë¶€ë¶„ì—ì„œ ì°¾ì•„ë‘” ë¸”ë¡œê·¸ì™€ ê´€ë ¨ ìë£Œë¥¼ ì½ì–´ë³´ë©° ë‚´ìš©ì„ ì •ë¦¬í•œë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16916c7c",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "ğŸ’¡\n",
    "# Transformer ëª¨ë¸ ì‹¤í—˜\n",
    "- ê´€ë ¨ ì§€ì‹ í•˜ë‚˜ë„ ì—†ì–´ì„œ ëª¨ë¸ì„ ì§ì ‘ êµ¬í˜„í•˜ëŠ”ê±´ ì–´ë ¤ìš¸ê²ƒ ê°™ê³ , ë‹¤í–‰íˆ [ìœ„í‚¤ë…ìŠ¤ ìë£Œ](https://wikidocs.net/31379)ì—ì„œ íŠ¸ëœìŠ¤í¬ë¨¸ ì„¤ëª…ì„ ì°¾ì•˜ë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³¸ë‹¤\n",
    "- í•´ë³´ë ¤ê³ í–ˆëŠ”ë° ë„ˆë¬´ ì–´ë ¤ìš´ ë‚´ìš©ì´ë¼ [Hugging Face](https://icedhotchoco.tistory.com/entry/DAY-83)ì—ì„œ íŠ¸ëœìŠ¤í¬ë¨¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê°€ì ¸ì™€ì„œ ì‹¤ìŠµí•´ë³´ëŠ” ìë£Œë¥¼ ì°¾ì•˜ë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤í—˜\n",
    "    - [Hugging face - Transformer quicktour](https://huggingface.co/docs/transformers/quicktour)\n",
    "    - [SummarizationPipeline](https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/pipelines#transformers.SummarizationPipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "09b712d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load transformer pipeline \n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d0a471a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13370    Sushmita Sen is dating model Rohman Shawl whom...\n",
       "24057    Micro-blogging site Twitter on Friday revealed...\n",
       "42500    The Centre on Wednesday cleared a plan to set ...\n",
       "67384    A Chandigarh court has rejected a surrender pl...\n",
       "9404     A selfie has saved a US man from a possible pr...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 40 texts\n",
    "random_sample = data_for_summa.sample(n=40, random_state=1004)\n",
    "\n",
    "random_sample['text'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3153128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002b44927773426b982046794bccc85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c98f510e6204c90addd8d86b23d94b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6081b69183644fb1aa9211c0c907055c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d3a8be7ab04e3789df86f85a3e82f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d118a653864727a974c2a2f9c3f8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make summarization pipeline\n",
    "summarizer = pipeline('summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "484d06ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([13370, 24057, 42500, 67384,  9404, 81670, 96525, 30846, 73029,\n",
       "            52230,  9834, 22931, 19631, 76864, 92696, 46321, 23420, 39753,\n",
       "            48225, 92872, 28942, 94481, 44515, 77671, 69310,  1877,  5656,\n",
       "            43402, 91277, 33170, 81495, 15288, 95623, 95814, 73421, 95798,\n",
       "            17371,  8258, 66810, 70001],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original index ì–»ê¸°\n",
    "random_sample_idx = random_sample['text'].index\n",
    "random_sample_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9bfe6c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- original_text: The text you want to summarize\n",
    "- max_length: Maximum number of words in the generated summary\n",
    "- min_length: Minimum number of words in the generated summary\n",
    "- length_penalty: A factor influencing the length of the summary\n",
    "- num_beams: The number of different ways to explore possible summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "756820a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 13370\n",
      "Original Text: Sushmita Sen is dating model Rohman Shawl whom she had met at a fashion event in August, as per reports. Rohman was spotted cheering for Sushmita at Neeta Lulla's fashion show a few days ago where he was also seen interacting with Sushmita's daughters Renee and Alisah, reports suggested. Sushmita was earlier said to be dating hotelier Ritik Bhasin. \n",
      "Predicted Summary:  Rohman Shawl was spotted cheering for Sushmita at Neeta Lulla\n",
      "ROUGE F1 Score: 0.29999999722222226\n",
      "\n",
      "\n",
      "index: 24057\n",
      "Original Text: Micro-blogging site Twitter on Friday revealed its earnings for the second quarter of 2018 where it stated that its monthly active users dropped from 336 million in Q1 to 335 million in Q2. The company saw revenue of $711 million, up from $665 million in the last quarter. Twitter reported a net income of $100 million, its third-straight profitable quarter.\n",
      "Predicted Summary:  Twitter reported a net income of $100 million, its third-straight profitable quarter .\n",
      "ROUGE F1 Score: 0.41379310016646853\n",
      "\n",
      "\n",
      "index: 42500\n",
      "Original Text: The Centre on Wednesday cleared a plan to set up an Indian Air Force (IAF) base close to Gujarat's Deesa near India's border with Pakistan. Reportedly, the PM Narendra Modi-led Cabinet Committee on Security (CCS) cleared the plan to extend the runway, build fighter-pens, and administrative facilities, with an initial investment of around ÃƒÂ¢Ã‚Â‚Ã‚Â¹1,000 crore.\n",
      "Predicted Summary:  PM Narendra Modi-led Cabinet Committee on Security (CCS) cleared the plan to\n",
      "ROUGE F1 Score: 0.41379310016646853\n",
      "\n",
      "\n",
      "index: 67384\n",
      "Original Text: A Chandigarh court has rejected a surrender plea of former Punjab minister Sucha Langah, who is accused of raping a woman for nearly a decade. The court directed him to go to Punjab's Gurdaspur town where the rape and cheating cases were registered against him. The Punjab Police has been conducting raids across the state to arrest him.  \n",
      "Predicted Summary:  Former Punjab minister Sucha Langah is accused of raping a woman for nearly a decade\n",
      "ROUGE F1 Score: 0.393442619414136\n",
      "\n",
      "\n",
      "index: 9404\n",
      "Original Text: A selfie has saved a US man from a possible prison sentence of 99 years. Cristopher Precopia's ex-girlfriend had accused him of breaking into her home on September 20, 2017, and carving an \"X\" below her neck using a box cutter. However, the selfie taken by Precopia's mother proved he was at a hotel, 70 miles from the accuser's home.\n",
      "Predicted Summary:  Cristopher Precopia's ex-girlfriend had accused him of breaking into her home\n",
      "ROUGE F1 Score: 0.36065573474872353\n",
      "\n",
      "\n",
      "index: 81670\n",
      "Original Text: Yale researchers have identified 60 potential new \"hot Jupiters\", a class of Jupiter-like giant gas planets which complete an orbit around host star within a week due to their proximity. The discovery was made by studying reflected signals in observations of over 1,40,000 stars by NASA's Kepler spacecraft. Reflected light signals hold rich information about planets' atmospheres, researchers said.\n",
      "Predicted Summary:  Yale researchers identify 60 potential new 'hot Jupiters' class of Jupiter-\n",
      "ROUGE F1 Score: 0.21538461257278108\n",
      "\n",
      "\n",
      "index: 96525\n",
      "Original Text: The government had reportedly rejected the proposal to felicitate cricketer MS Dhoni, journalist Arnab Goswami, spiritual leader Gurmeet Ram Rahim Singh, music composer Anu Malik and others with Padma awards. NCP leader Sharad Pawar and BJP leader Murli Manohar Joshi were awarded Padma Vibhushan under the \"public affairs\" category, which falls under the government's discretion, a report said.\n",
      "Predicted Summary:  Sharad Pawar and Murli Manohar Joshi were awarded Padma V\n",
      "ROUGE F1 Score: 0.29508196447191626\n",
      "\n",
      "\n",
      "index: 30846\n",
      "Original Text: A 10-year-old girl was allegedly raped and murdered during a wedding last week in Madhya Pradesh's Umaria district, the police said on Wednesday. The minor, who was visiting her grandmother's house for a wedding, disappeared after falling off to sleep on May 13. Her body was later found strangled to death with her scarf. \n",
      "Predicted Summary:  10-year-old girl allegedly raped and murdered during a wedding in Madhya Pradesh\n",
      "ROUGE F1 Score: 0.36065573454447736\n",
      "\n",
      "\n",
      "index: 73029\n",
      "Original Text: US-based cab-hailing startup Uber launched in-app messaging feature along with multi-destination rides for users in India. The feature aims to help riders and drivers get in touch without incurring call charges or sharing their contact numbers. The in-app chat for both iOS and Android has been updated and also supports a number of local languages. \n",
      "Predicted Summary:  US-based cab-hailing startup Uber launched in-app messaging feature along with\n",
      "ROUGE F1 Score: 0.3389830480321747\n",
      "\n",
      "\n",
      "index: 52230\n",
      "Original Text: The Unique Identification Authority of India (UIDAI) on Monday announced the introduction of face authentication feature for Aadhaar users by July 1, 2018. This feature will help all elderly or others facing issues with fingerprint authentication, the UIDAI said. The feature must be combined with either fingerprint, iris scan, or OTP for successful authentication of an Aadhaar number.\n",
      "Predicted Summary:  The Unique Identification Authority of India (UIDAI) announced the introduction of face authentication feature\n",
      "ROUGE F1 Score: 0.43333332993888896\n",
      "\n",
      "\n",
      "index: 9834\n",
      "Original Text: Myntra CEO Ananth Narayanan has said all of Jabong's functions will be integrated with the company and about 10% of the combined workforce would be cut. Myntra and Jabong will operate as distinct brands but will be run by one team. Following Binny Bansal's resignation as Flipkart Group CEO, Walmart said Narayanan will report to Flipkart CEO Kalyan Krishnamurthy.\n",
      "Predicted Summary:  Myntra CEO Ananth Narayanan has said all of Jabong's functions\n",
      "ROUGE F1 Score: 0.363636360661157\n",
      "\n",
      "\n",
      "index: 22931\n",
      "Original Text: A woman in Gujarat has alleged her live-in partner forced her to remove two front teeth to avoid male attention. She added he suspected her of seeing someone else and made her sit beside him all day while he worked as an autorickshaw driver. This was discovered when she jumped out of the autorickshaw one day and passersby alerted authorities.\n",
      "Predicted Summary:  Woman claims live-in partner forced her to remove two front teeth to avoid male attention\n",
      "ROUGE F1 Score: 0.3692307658508876\n",
      "\n",
      "\n",
      "index: 19631\n",
      "Original Text: French female tennis player Alize Cornet was punished by the on-court official at the US Open 2018 for taking her top off and exposing her black bra during her mid-match 10-minute heat break. After walking back to court following her break, Cornet realised that she had worn her top backwards before taking it off to wear it properly.\n",
      "Predicted Summary:  Alize Cornet was punished by the on-court official for taking her top off\n",
      "ROUGE F1 Score: 0.43333332993888896\n",
      "\n",
      "\n",
      "index: 76864\n",
      "Original Text: A US-based study has found elements heavier than iron may have been formed by interactions between primordial black holes and neutron stars. A neutron-rich environment was needed to forge such elements, scientists said, which was formed by black holes devouring neutron stars. This finding is consistent with paucity of neutron stars in galactic centres with high black hole density.\n",
      "Predicted Summary:  Elements heavier than iron may have been formed by interactions between primordial black holes and neutron\n",
      "ROUGE F1 Score: 0.47619047240110873\n",
      "\n",
      "\n",
      "index: 92696\n",
      "Original Text: Three different coloured crater lakes at the summit of Mount Kelimutu volcano in Indonesia change their colour. It is believed that minerals in the water interact with volcanic gas to create different shades. According to a local belief, the lakes are a resting place for departed souls, and those who die are sent to different lakes depending on their merits.\n",
      "Predicted Summary:  Three different coloured crater lakes at the summit of Mount Kelimutu volcano in Indonesia\n",
      "ROUGE F1 Score: 0.45161289972944857\n",
      "\n",
      "\n",
      "index: 46321\n",
      "Original Text: In an open letter to Pakistani singer Rahat Fateh Ali Khan, Union Minister Babul Supriyo wrote, \"Maybe the time has come when...powerful...individuals like you (should) put pressure on your government to refrain from such support to terrorism.\" Supriyo added that the effort to solve tensions between India and Pakistan through art and music is a \"failed doctrine\".\n",
      "Predicted Summary:  Union Minister Babul Supriyo wrote an open letter to Pakistani singer Rahat Fate\n",
      "ROUGE F1 Score: 0.3283582058275786\n",
      "\n",
      "\n",
      "index: 23420\n",
      "Original Text: A 20-year-old 'grieving' orca whale has been continuously carrying her dead calf off the Canadian coast since it died last Tuesday shortly after birth. Scientists tracking the mother have expressed concerns over her well-being as she is now falling behind her group. The calf was the first born to its group in 3 years, of which only 75 are left.\n",
      "Predicted Summary:  A 20-year-old whale has been continuously carrying her dead calf off the Canadian\n",
      "ROUGE F1 Score: 0.388059698364892\n",
      "\n",
      "\n",
      "index: 39753\n",
      "Original Text: Assam Congress MLA Rupjyoti Kurmi recently paid for a funeral of a poor man and carried his body till the cremation site. \"As a human being and responsible for the people I represent, it's the least I could do,\" Kurmi said. Last year, Kurmi also carried 50 kg rice bag on his back and delivered it to flood relief camps.\n",
      "Predicted Summary:  Assam Congress MLA Rupjyoti Kurmi recently paid for a funeral of\n",
      "ROUGE F1 Score: 0.37288135289859237\n",
      "\n",
      "\n",
      "index: 48225\n",
      "Original Text: Congress President Rahul Gandhi was gifted a gold-coated Valmiki statue worth ÃƒÂ¢Ã‚Â‚Ã‚Â¹60 lakh by an independent MLA who joined the party at a rally in Karnataka on Saturday. A BJP MLA from Vijayanagar also formally joined the party during the rally. Meanwhile, the BJP criticised Gandhi and CM Siddaramaiah for inducting the MLAs, who are facing charges of illegal mining. \n",
      "Predicted Summary:  Congress President Rahul Gandhi gifted a gold-coated Valmiki statue worth Ãƒ\n",
      "ROUGE F1 Score: 0.33333333033888896\n",
      "\n",
      "\n",
      "index: 92872\n",
      "Original Text: Cristiano Ronaldo scored a hat-trick to help Real Madrid reach Champions League semi-finals for the seventh straight year, after claiming a 6-3 aggregate victory over Bayern Munich in the quarter-finals on Tuesday. Coming into the match with a 2-1 lead from the first leg, Real finished regulation time losing 1-2, but scored three goals in extra time to claim victory.\n",
      "Predicted Summary:  Cristiano Ronaldo scored a hat-trick to help Real Madrid reach Champions League semi\n",
      "ROUGE F1 Score: 0.38709677087929245\n",
      "\n",
      "\n",
      "index: 28942\n",
      "Original Text: Indian Air Force has joined the operation to douse a massive fire raging for 17 hours in a rubber godown in Delhi's Malviya Nagar after fire tenders failed to contain the blaze. An Mi-17 helicopter was seen pouring water on the fire, while 15 fire tenders were at the spot. The fire also spread to nearby buildings, including a school.\n",
      "Predicted Summary:  Indian Air Force has joined the operation to douse a massive fire raging for 17 hours\n",
      "ROUGE F1 Score: 0.4999999962500001\n",
      "\n",
      "\n",
      "index: 94481\n",
      "Original Text: Technology major Apple has received a patent for an anti-shock device that will protect smartphones from falls and float if the phone contacts a water surface. The patent details a spring-loaded bumper system that deploys when it detects that the phone is in free-fall. The 'bumper cushions' may also be coloured to better the appearance of smartphones, Apple added.\n",
      "Predicted Summary:  Patent details a spring-loaded bumper system that deploys when it detects that the phone\n",
      "ROUGE F1 Score: 0.38709677087929245\n",
      "\n",
      "\n",
      "index: 44515\n",
      "Original Text: While honouring late actress Madhubala, US daily The New York Times has compared her life to late American actress Marilyn Monroe. The newspaper wrote that there was a remarkable similarity in the \"soft vulnerability of their faces\", \"laughter\" and the \"incandescent glow\". In their special obituary section 'Overlooked', the newspaper paid homage to 14 other remarkable women across the world.\n",
      "Predicted Summary:  The New York Times compared Madhubala's life to late American actress Marilyn Monroe .\n",
      "ROUGE F1 Score: 0.38095237767699675\n",
      "\n",
      "\n",
      "index: 77671\n",
      "Original Text: Canada is investigating reports that Saudi Arabia has been using Canadian-made armoured vehicles against its citizens in the violence-hit Eastern Province. Videos and photos posted on social media show Saudi Arabia using Canadian equipment on Shia dissidents. Canada warned it would take action if \"it is found that Canadian exports have been used to commit serious violations of human rights\".\n",
      "Predicted Summary:  Videos and photos posted on social media show Saudi Arabia using Canadian equipment on Shia dissidents .\n",
      "ROUGE F1 Score: 0.4545454510330579\n",
      "\n",
      "\n",
      "index: 69310\n",
      "Original Text: US President Donald Trump on Tuesday called the 2015 Iran nuclear deal an \"embarrassment\" and \"a one-sided transaction\" for the US. Adding that the deal must be changed for the US to remain in it, US State Secretary Rex Tillerson said, \"Unfortunately, this is what (US) in the past did with North Korea...entered into agreements that were easily cheated on.\"\n",
      "Predicted Summary:  US President Donald Trump called the 2015 Iran nuclear deal an \"embarrassment\" and\n",
      "ROUGE F1 Score: 0.41269840942302854\n",
      "\n",
      "\n",
      "index: 1877\n",
      "Original Text: Two incidents were reported from Jammu and Kashmir in which patients had to be carried to the hospital on shoulders amid heavy snow due to lack of connectivity of roads. A video shows attendants of hospitals in Ganderbal and Uri carrying patients on their shoulders for several kilometres. One of the patients, from Uri, had suffered a stroke.\n",
      "Predicted Summary:  Two incidents were reported from Jammu and Kashmir in which patients had to be carried to\n",
      "ROUGE F1 Score: 0.4999999962500001\n",
      "\n",
      "\n",
      "index: 5656\n",
      "Original Text: A Nigerian professor has been jailed for demanding sex for marks from a student. Richard Akindele was convicted after pleading guilty to four criminal charges, including demanding gratification from a student and sexual coercion of a student. A student had come forward with a recording of Akindele demanding that she either sleep with him or fail the course.\n",
      "Predicted Summary:  Richard Akindele was convicted after pleading guilty to four criminal charges . The professor had\n",
      "ROUGE F1 Score: 0.4137930997859691\n",
      "\n",
      "\n",
      "index: 43402\n",
      "Original Text: Asserting that the BJP united the Bahujan Samaj Party and the Samajwadi Party, SP chief Akhilesh Yadav on Saturday said he will visit mandir, masjid and \"all religious places\" to maintain an alliance with BSP. In a jibe at BJP referring to its defeat in the recent Lok Sabha bypolls, he said the BJP's 'pakoda' politics was behind its loss.\n",
      "Predicted Summary:  SP chief Akhilesh Yadav says he will visit mandir, masj\n",
      "ROUGE F1 Score: 0.2666666638888889\n",
      "\n",
      "\n",
      "index: 91277\n",
      "Original Text: SS Rajamouli's Baahubali 2, the sequel to the 2015 film Baahubali, sold over 10 lakh tickets within 24 hours in advance bookings on the ticket booking platform BookMyShow. The tickets for the film were also said to be sold for as high as ÃƒÂ¢Ã‚Â‚Ã‚Â¹2,400 in certain theatres. The film released on Friday on a record 6,500 screens in India.\n",
      "Predicted Summary:  SS Rajamouli's Baahubali 2 sold over 10 lakh tickets within\n",
      "ROUGE F1 Score: 0.3333333303155008\n",
      "\n",
      "\n",
      "index: 33170\n",
      "Original Text: A 24-year-old fashion blogger has shared a video of herself creating a dress using trash bags. Amber Scholl said she undertook the \"silly\" challenge as her fans often told her she \"could make wearing a trash bag look good.\" Scholl created roses using trash bags and stuck them on a bodysuit and skirt, with the entire process taking seven hours. \n",
      "Predicted Summary:  Amber Scholl created roses using trash bags and stuck them on a bodysuit and\n",
      "ROUGE F1 Score: 0.41269840942302854\n",
      "\n",
      "\n",
      "index: 81495\n",
      "Original Text: A man says he was fired from a US Home Depot store for violating safety policy by trying to stop a suspected kidnapping. Dillon Reagan was finishing his shift when a co-worker spotted a violent dispute in the parking lot with a woman screaming, \"HeÃƒÂ¢Ã‚Â€Ã‚Â™s kidnapping my childÃƒÂ¢Ã‚Â€Ã‚Â. Reagan called 911 and gave his statement for which he was fired.\n",
      "Predicted Summary:  Dillon Reagan was finishing his shift when a co-worker spotted a violent dispute in the\n",
      "ROUGE F1 Score: 0.45161289972944857\n",
      "\n",
      "\n",
      "index: 15288\n",
      "Original Text: The Delhi Police has arrested a man who posed as a DCP to extort money from truck drivers. Sunil Tyagi was caught red-handed from Delhi's Dhaula Kuan while he was extracting money from a truck driver. Tyagi said that working as a driver he had confronted several police officers and seeing their behaviour, he decided to act like one.\n",
      "Predicted Summary:  Sunil Tyagi was caught red-handed from Delhi's Dhaula Kuan\n",
      "ROUGE F1 Score: 0.33333333055555564\n",
      "\n",
      "\n",
      "index: 95623\n",
      "Original Text: A US woman has been ordered by a judge to pay ÃƒÂ¢Ã‚Â‚Ã‚Â¹3.2 crore for a Facebook post that falsely accused an acquaintance of killing her own son. The complainant said that social media makes it \"easy\" for people to defame others. \"There are no filters to say whatever you think behind the safety of your screen,\" she said.\n",
      "Predicted Summary:  US woman ordered to pay ÃƒÂ¢Ã‚Â‚Ã‚Â¹3.2\n",
      "ROUGE F1 Score: 0.2372881335018673\n",
      "\n",
      "\n",
      "index: 95814\n",
      "Original Text: Facebook-owned VR startup Oculus Co-founder Palmer Luckey has left the company. Last year, Luckey apologised for donating $10,000 to a group spreading anti-Hillary Clinton memes ahead of the US presidential election. Luckey was also involved in a lawsuit against Facebook by Zenimax which accused Oculus of twisting its origin story by giving Luckey complete credit for inventing the technology.\n",
      "Predicted Summary:  Oculus co-founder Palmer Luckey has left the company . Luckey was involved in\n",
      "ROUGE F1 Score: 0.33333333033888896\n",
      "\n",
      "\n",
      "index: 73421\n",
      "Original Text: The Islamic State has claimed responsibility for the attack at a Shia mosque on Friday in Afghanistan's capital Kabul. A suicide bombing followed by gunfire killed at least 30 people and left several others injured. This comes after ISIS issued a warning last month, saying it would attack Shia places of worship in Afghanistan.\n",
      "Predicted Summary:  ISIS has claimed responsibility for the attack at a Shia mosque in Afghanistan's capital Kabul .\n",
      "ROUGE F1 Score: 0.46874999641113285\n",
      "\n",
      "\n",
      "index: 95798\n",
      "Original Text: Actress Shilpa Shinde, who portrayed the character 'Angoori Bhabhi' on the television serial 'Bhabhiji Ghar Par Hai', has filed a complaint of criminal defamation against the heads of three industry associations. She alleged that the associations had imposed a 'ban' on her, though they have no such power, and had warned of action against any production house which employed her. \n",
      "Predicted Summary:  Actress Shilpa Shinde has filed a complaint of criminal defamation against the heads\n",
      "ROUGE F1 Score: 0.37499999676269535\n",
      "\n",
      "\n",
      "index: 17371\n",
      "Original Text: Pakistan cricketer Shoaib Malik came and talked to former Indian captain MS Dhoni during the sides' training session in Dubai ahead of the upcoming Asia Cup 2018 tournament. Malik came and shook hands with Dhoni before talking to him, with India's stand-in captain Rohit Sharma standing nearby. India and Pakistan are set to face each other on September 19.\n",
      "Predicted Summary:  Shoaib Malik came and shook hands with MS Dhoni during training session . India\n",
      "ROUGE F1 Score: 0.4262295048427842\n",
      "\n",
      "\n",
      "index: 8258\n",
      "Original Text: Reacting to the allegations levelled against her by India Women coach Ramesh Powar, Mithali Raj tweeted it was the darkest day of her life as her patriotism has been doubted. She added that all her hard work in last 20 years of playing for India went in vain. Powar had accused Mithali of chasing \"own milestones\" during Women's World T20.\n",
      "Predicted Summary:  Mithali Raj tweets it was the darkest day of her life as her patriotism has been\n",
      "ROUGE F1 Score: 0.4242424207300276\n",
      "\n",
      "\n",
      "index: 66810\n",
      "Original Text: The Andhra Pradesh government is exploring a proposal to allot five extra marks to students of Class 9 and above who participate in the Swachh Bharat initiative by helping identify households without toilets. Andhra Pradesh government has to build 21 lakh toilets, to achieve 100% open defecation free status by March 2019 and has been encouraging students to participate.\n",
      "Predicted Summary:  Andhra Pradesh government has to build 21 lakh toilets to achieve 100% open defec\n",
      "ROUGE F1 Score: 0.39999999660555563\n",
      "\n",
      "\n",
      "index: 70001\n",
      "Original Text: NASA on Friday crashed its $3.9-billion Cassini spacecraft into Saturn's atmosphere as it was running low on fuel after a 20-year mission. The spacecraft was destroyed to avoid a collision with Saturn's moons, to protect them from Earth-based contamination, thus preserving them for future missions. Cassini had discovered oceans and organic elements suitable for life on moons, Titan and Enceladus. \n",
      "Predicted Summary:  NASA crashed its $3.9-billion Cassini spacecraft into Saturn's atmosphere on\n",
      "ROUGE F1 Score: 0.36065573474872353\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iterate through the rows and print the summarized text\n",
    "for idx, text in enumerate(random_sample['text']):\n",
    "    dict_summary = summarizer(text, min_length=5, max_length=20)\n",
    "    summary = dict_summary[0]['summary_text']\n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scores = rouge.get_scores(summary, text, avg=True)\n",
    "    \n",
    "    # Extract only the F1 score from the ROUGE scores\n",
    "    f1_score = rouge_scores['rouge-1']['f']\n",
    "    \n",
    "    # Print the summary for each text\n",
    "    print('index:', random_sample_idx[idx])\n",
    "    print('Original Text:', text)\n",
    "    print('Predicted Summary:', summary)\n",
    "    print('ROUGE F1 Score:', f1_score)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704c39d",
   "metadata": {},
   "source": [
    "- ìƒê°í•´ë³´ë‹ˆ ì´ ìš”ì•½ì—ëŠ” ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ í•˜ì§€ ì•Šì•„ì„œ íŠ¸ëœìŠ¤í¬ë¨¸ì¸ë°ë„ f1 scoreê°€ í¬ê²Œ ì¢‹ì§€ì•Šì€ê±¸ê¹Œ ì‹¶ë‹¤.\n",
    "- ë°ì´í„° ì „ì²˜ë¦¬ë„ ì™„ë£Œí•œí›„ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ë‹¤ì‹œ ì‚¬ìš©í•´ë´ì•¼ê² ë‹¤"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "343px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
